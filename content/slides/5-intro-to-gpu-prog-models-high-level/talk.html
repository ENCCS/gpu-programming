<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Ashwin Mohanan">
  <meta name="dcterms.date" content="2025-11-20">
  <title>High level language support</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^5/dist/reset.css">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^5/dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^5/dist/theme/league.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">High level language support</h1>
  <p class="subtitle"><img src="https://media.enccs.se/2022/12/ENCCS-Logo-Horizontal-Colour-low-res-323.png" width="50%" align="center"/></p>
  <p class="author">Ashwin Mohanan</p>
  <p class="institute">ENCCS/RISE</p>
  <p class="date">2025-11-20</p>
</section>

<section id="outline" class="slide level1">
<h1>Outline</h1>
<p>Introduce different libraries, show similarities and differences in
capabilities</p>
<ul>
<li><p>GPU programming with Python</p>
<p>Numba, Cupy, Jax, PyCUDA/PyOpenCL, CUDA Python / HIP Python</p></li>
<li><p>GPU programming with Julia</p>
<p>CUDA.jl / AMDGPU.jl / oneAPI.jl / Metal.jl and
KernelAbstractions</p></li>
</ul>
</section>
<section class="slide level1">

<h2 id="what-is-high-level-programming">What is high-level
programming?</h2>
<blockquote>
<p>Primer on Python and Numpy</p>
</blockquote>
<p>Either use simple data structures in Python‚Äôs standard library and
for-loops</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Element-wise sum of two &quot;arrays&quot; represented as lists</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> [random.random() <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> [random.random() <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> []</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a_i, b_i <span class="kw">in</span> <span class="bu">zip</span>(a, b):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    c.append(a_i <span class="op">+</span> math.sin(b_i))</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="what-is-high-level-programming-1">What is high-level
programming?</h2>
<blockquote>
<p>Primer on Python and Numpy</p>
</blockquote>
<p>‚Ä¶ or you use <strong>efficient data structures</strong> and
<strong>vectorized operations</strong></p>
<p>with expressive syntax!</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.random.random(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.random.random(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">+</span> np.sin(b)</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="numba">Numba</h2>
<p><img src="https://numba.pydata.org/_static/numba-blue-horizontal-rgb.svg" width="50%"/></p>
<ul>
<li><p>JIT compiler which supports a subset of Python and Numpy</p></li>
<li><p><strong>CPU</strong> execution</p>
<p>via LLVM using <code>llvmlite</code> and a C compiler</p></li>
<li><p><strong>GPU</strong> execution</p>
<p>via CUDA using <code>nvcc</code> and <code>nvrtc</code> /
<code>cudatoolkit</code></p></li>
</ul>
</section>
<section class="slide level1">

<h2 id="numba-1">Numba</h2>
<ul>
<li>Experimental AMD GPU support through <code>numba-hip</code>
extension</li>
</ul>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numba <span class="im">import</span> hip</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Use `@hip.jit` decorator, or</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Call `hip.pose_as_cuda()` and use `@cuda.jit`</span></span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="numba-ufuncs-element-wise-vectorized">Numba: ufuncs
(element-wise vectorized)</h2>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numba</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="at">@numba.vectorize</span>(</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    [numba.float64(numba.float64, numba.float64)], </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span><span class="st">&quot;cuda&quot;</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> a_plus_sin_b(a, b):</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a <span class="op">+</span> math.sin(b)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">10_000_000</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> np.random.rand(N)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>a_plus_sin_b(vec, vec)</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="numba-low-level">Numba: low-level</h2>
<p>Control execution using <code>numba.cuda.threadIdx</code>,
<code>blockDim</code>, <code>blockIdx</code>, <code>gridDim</code>
etc.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numba</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="at">@numba.cuda.jit</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> a_plus_sin_b(a, b, c):</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;GPU vectorized addition. Computes C = A + B&quot;&quot;&quot;</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># like threadIdx.x + (blockIdx.x * blockDim.x)</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    thread_id <span class="op">=</span> numba.cuda.grid(ndim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(c)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> thread_id <span class="op">&lt;</span> size:</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        c[thread_id] <span class="op">=</span> a[thread_id] <span class="op">+</span> math.sin(b[thread_id])</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">10_000_000</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> numba.cuda.to_device(np.random.random(N))</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> numba.cuda.to_device(np.random.random(N))</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> numba.cuda.device_array_like(a)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>grid_size <span class="op">=</span> <span class="bu">len</span>(a)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>a_plus_sin_b.forall(grid_size)(a, b, c)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>c.copy_to_host()</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="jax">Jax</h2>
<p><img src="https://docs.jax.dev/en/latest/_static/jax_logo_250px.png" width="20%"></p>
<ul>
<li><p>Support a subset of Python and Numpy</p></li>
<li><p>Drop-in replacement for Numpy</p>
<p><code>import jax.numpy as jnp</code></p></li>
<li><p>Interoperable, uses just-in-time XLA compiler to target CPU, GPU
(CUDA and ROCm) and TPU.</p></li>
</ul>
</section>
<section class="slide level1">

<h2 id="jax-as-drop-in-replacement-for-numpy">Jax as drop-in replacement
for Numpy</h2>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.random((<span class="dv">10</span>, <span class="dv">10_000</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>data[<span class="dv">5</span>, <span class="dv">42</span>] <span class="op">=</span> np.nan</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>data[<span class="dv">7</span>, <span class="dv">1111</span>] <span class="op">=</span> np.nan</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># compute 90th percentile ignoring NaNs, </span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># and along the rows of an array</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>np.nanpercentile(data, <span class="dv">90</span>, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>jnp.nanpercentile(data, <span class="dv">90</span>, axis<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="jax-as-jit-compiler">Jax as JIT compiler</h2>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> jax <span class="im">import</span> jit</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> a_plus_sin_b_numpy(x, y):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">+</span> np.sin(y)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="at">@jit</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> a_plus_sin_b_jax(x, y):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">+</span> jnp.sin(y)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">10_000_000</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> np.random.rand(N)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>a_plus_sin_b_numpy(vec, vec)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>a_plus_sin_b_jax(vec, vec)  <span class="co"># slightly faster on CPU</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(jax.devices())  <span class="co"># check for CUDA</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>vec_d <span class="op">=</span> jax.device_put(mx)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>a_plus_sin_b_jax(vec_d, vec_d)  <span class="co"># much faster on GPU</span></span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="cupy">CuPy</h2>
<p><img src="https://cupy.dev/images/cupy.png" width="20%"></p>
<ul>
<li>Supports a subset of Python, Numpy and Scipy</li>
<li>Precompiled wheels for CUDA and ROCm</li>
<li>Drop-in support for Numpy and Scipy
<code>python   import cupy as cp   import cupyx.scipy.fft as cufft</code></li>
<li>JIT compilation</li>
<li><a href="https://data-apis.org/array-api/2023.12/index.html">Array
API</a> support =&gt; Cupy arrays can use Numpy functions</li>
</ul>
</section>
<section class="slide level1">

<h2 id="cupy-as-drop-in-replacement-for-numpy">CuPy as drop-in
replacement for Numpy</h2>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cupy <span class="im">as</span> cp</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> cp.random.random(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> cp.random.random(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">+</span> cp.sin(b)</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="cupy-as-compiler-for-custom-kernels">CuPy as compiler for custom
kernels</h2>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>a_plus_sin_b <span class="op">=</span> cp.ElementwiseKernel(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>   <span class="st">&#39;float64 a, float64 b&#39;</span>,</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>   <span class="st">&#39;float64 c&#39;</span>,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>   <span class="st">&#39;c = a + sin(b)&#39;</span>,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>   <span class="st">&#39;a_plus_sin_b&#39;</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>a_plus_sin_b</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="libraries-for-lower-level-implementation">Libraries for lower
level implementation</h2>
<ul>
<li>CUDA Python</li>
<li>HIP Python</li>
</ul>
<p>HIP Python + <code>hip-python-as-cuda</code> makes it interoperable
with CUDA Python code</p>
<p><strong>Third-party implementations</strong></p>
<ul>
<li>PyCUDA</li>
<li>PyOpenCL</li>
</ul>
</section>
<section class="slide level1">

<h2 id="summary-of-python-libraries">Summary of Python libraries</h2>
<div class="r-fit-text">
<table>
<colgroup>
<col style="width: 29%" />
<col style="width: 7%" />
<col style="width: 4%" />
<col style="width: 6%" />
<col style="width: 26%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr>
<th>Feature</th>
<th>Numba</th>
<th>Jax</th>
<th>CuPy</th>
<th>Cuda / HIP Python</th>
<th>PyCUDA / PyOpenCL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Low level</td>
<td>‚úÖ</td>
<td>ü§∑</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
</tr>
<tr>
<td>High level</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚ùå</td>
</tr>
<tr>
<td>Numpy compat</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>ü§∑</td>
<td>ü§∑</td>
</tr>
<tr>
<td>CUDA/ROCm interoperability</td>
<td>ü§∑</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>ü§∑</td>
</tr>
<tr>
<td>Pre-compiled kernel</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚ùå</td>
</tr>
<tr>
<td>Custom kernels</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
</tr>
</tbody>
</table>
</div>
</section>
<section class="slide level1">

<section id="julia">
<h2>Julia</h2>
<p><img src="https://julialang.org/assets/infra/logo.svg" width="40%"><img src="https://cuda.juliagpu.org/dev/assets/logo.png" width="40%" align="right"></p>
<ul>
<li>Base arrays</li>
<li>JuliaGPU project</li>
<li>CUDA.jl, AMDGPU.jl, oneAPI.jl, Metal.jl</li>
<li>KernelAbstractions</li>
</ul>
</section>
</section>
<section class="slide level1">

<h2 id="about-julia">About Julia</h2>
<blockquote>
<p>Primer on Julia and the Base libary</p>
</blockquote>
<ul>
<li>First, released in 2012 and inspired by MATLAB, Lua, Lisp, Python
‚Ä¶.</li>
<li>JIT compiled with its core implemented using C and LLVM</li>
</ul>
</section>
<section class="slide level1">

<h2 id="array-programming-in-julia">Array programming in Julia</h2>
<blockquote>
<p>Primer on Julia and the Base libary</p>
</blockquote>
<div class="sourceCode" id="cb10"><pre
class="sourceCode julia"><code class="sourceCode julia"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fu">rand</span>(<span class="fl">1000</span>);</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="fu">rand</span>(<span class="fl">1000</span>);</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">.+</span> <span class="fu">sin</span>.(b)</span></code></pre></div>
<ul>
<li>Batteries included with <code>AbstractArray</code> and
Base.Array</li>
<li>Sub-types of arrays: <code>Vector</code> (1D), <code>Matrix</code>
(2D), <code>Array</code> (N-D)</li>
</ul>
</section>
<section class="slide level1">

<h2 id="cuda.jl-amdgpu.jl-oneapi.jl-metal.jl">CUDA.jl, AMDGPU.jl,
oneAPI.jl, Metal.jl</h2>
<div class="sourceCode" id="cb11"><pre
class="sourceCode julia"><code class="sourceCode julia"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">CUDA</span>  <span class="co"># or AMDGPU or oneAPI or Metal</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fu">rand</span>(<span class="fl">1000</span>);</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>a_d <span class="op">=</span> <span class="fu">CuArray</span>(a);  <span class="co"># or ROCArray, oneArray, MtlArray</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>b_d <span class="op">=</span> CUDA.<span class="fu">rand</span>(<span class="fl">1000</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Same builtin function from Base can be used</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a_d <span class="op">.+</span> <span class="fu">sin</span>.(b_d)</span></code></pre></div>
</section>
<section class="slide level1">

<div class="r-fit-text">
<h2>
KernelAbstractions for generic functions
</h2>
<div class="sourceCode" id="cb12"><pre
class="sourceCode julia"><code class="sourceCode julia"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">KernelAbstractions</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="pp">@kernel</span> <span class="kw">function</span> <span class="fu">a_plus_sin_b!</span>(C, <span class="pp">@Const</span>(A), <span class="pp">@Const</span>(B))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>     i <span class="op">=</span> <span class="pp">@index</span>(Global)  <span class="co"># get threadIdx</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>     <span class="pp">@inbounds</span> C[i] <span class="op">=</span> A[i] <span class="op">+</span> <span class="fu">sin</span>(B[i])</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code></pre></div>
<div class="sourceCode" id="cb13"><pre
class="sourceCode julia"><code class="sourceCode julia"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">CUDA</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>a_d <span class="op">=</span> CUDA.<span class="fu">rand</span>(<span class="fl">1000</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>b_d <span class="op">=</span> CUDA.<span class="fu">rand</span>(<span class="fl">1000</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>c_d <span class="op">=</span> <span class="fu">similar</span>(a_d)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>backend <span class="op">=</span> <span class="fu">get_backend</span>(a_d)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="fu">a_plus_sin_b!</span>(backend, <span class="fu">size</span>(c_d))(</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    c_d, a_d, b_d, ndrange<span class="op">=</span><span class="fu">size</span>(c_d)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
</section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@^5/dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="https://unpkg.com/reveal.js@^5/plugin/notes/notes.js"></script>
  <script src="https://unpkg.com/reveal.js@^5/plugin/search/search.js"></script>
  <script src="https://unpkg.com/reveal.js@^5/plugin/zoom/zoom.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // reveal.js plugins
        plugins: [
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
