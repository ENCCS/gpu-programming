

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Portable kernel-based models &mdash; GPU programming: why, when and how?  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_lesson.css?v=e9df6548" />
      <link rel="stylesheet" type="text/css" href="../_static/term_role_formatting.css?v=4194e21c" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_rtd_theme_ext_color_contrast.css?v=8e8ea19f" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=a5c4661c" />
      <link rel="stylesheet" type="text/css" href="../_static/overrides.css?v=eafd8254" />

  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=187304be"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=f281be69"></script>
      <script src="../_static/minipres.js?v=a0d29692"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../_static/tabs.js?v=3030b3cb"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="High-level language support" href="../9-language-support/" />
    <link rel="prev" title="Non-portable kernel-based models" href="../7-non-portable-kernel-models/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../" class="icon icon-home">
            GPU programming: why, when and how?
              <img src="../_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Prerequisites</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../0-setup/">Setup</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../1-gpu-history/">Why GPUs?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2-gpu-ecosystem/">The GPU hardware and software ecosystem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3-gpu-problems/">What problems fit to GPU?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4-gpu-concepts/">GPU programming concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5-intro-to-gpu-prog-models/">Introduction to GPU programming models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6-directive-based-models/">Directive-based models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../7-non-portable-kernel-models/">Non-portable kernel-based models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Portable kernel-based models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#c-stdpar">C++ StdPar</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#stdpar-compilation">StdPar compilation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stdpar-programming">StdPar programming</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stdpar-execution-policies">StdPar execution policies</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#kokkos">Kokkos</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#kokkos-compilation">Kokkos compilation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kokkos-programming">Kokkos programming</a></li>
<li class="toctree-l3"><a class="reference internal" href="#run-kokkos-hello-cpp-example-in-simple-steps">Run Kokkos hello.cpp example in simple steps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#opencl">OpenCL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#opencl-compilation">OpenCL compilation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#opencl-programming">OpenCL programming</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#sycl">SYCL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sycl-compilation">SYCL compilation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Intel oneAPI DPC++</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">AdaptiveCpp</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-sycl-on-lumi">Using SYCL on LUMI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sycl-programming">SYCL programming</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exercise">Exercise</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#alpaka">alpaka</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#installing-alpaka-on-your-system">Installing alpaka on your system</a></li>
<li class="toctree-l3"><a class="reference internal" href="#alpaka-compilation">alpaka Compilation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#using-alpaka-on-lumi">Using alpaka on LUMI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#alpaka-programming">alpaka Programming</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tour-of-alpaka-features">Tour of <strong>alpaka</strong> Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-alpaka3-example-in-simple-steps">Run alpaka3 Example in Simple Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="#expected-output">Expected output</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#compile-and-execute-examples">Compile and Execute Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Exercise</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#parallel-for-with-unified-memory">Parallel for with Unified Memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parallel-for-with-gpu-buffers">Parallel for with GPU buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asynchronous-parallel-for-kernels">Asynchronous parallel for kernels</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reduction">Reduction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pros-and-cons-of-cross-platform-portability-ecosystems">Pros and cons of cross-platform portability ecosystems</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#general-observations">General observations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lambda-based-kernel-models-kokkos-sycl">Lambda-based kernel models (Kokkos, SYCL)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#functor-based-kernel-model-alpaka">Functor-based kernel model (alpaka)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#separate-source-kernel-models-opencl">Separate-source kernel models (OpenCL)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#c-standard-parallelism-stdpar-pstl">C++ Standard Parallelism (StdPar, PSTL)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../9-language-support/">High-level language support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-multiple_gpu/">Multiple GPU programming with MPI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11-gpu-porting/">Preparing code for GPU porting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../12-recommendations/">Recommendations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13-examples/">GPU programming example: stencil computation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick-reference/">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary/">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/">Instructor’s guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://enccs.se/lessons/">All lessons</a></li>
<li class="toctree-l1"><a class="reference external" href="https://enccs.se/">ENCCS</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../">GPU programming: why, when and how?</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Portable kernel-based models</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/gpu-programming/blob/main/content/8-portable-kernel-models.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="portable-kernel-based-models">
<span id="portable-kernel-models"></span><h1>Portable kernel-based models<a class="headerlink" href="#portable-kernel-based-models" title="Link to this heading"></a></h1>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>How to program GPUs with alpaka, C++ StdPar, Kokkos, OpenCL, and SYCL?</p></li>
<li><p>What are the differences between these programming models.</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Be able to use portable kernel-based models to write simple codes</p></li>
<li><p>Understand how different approaches to memory and synchronization in Kokkos and SYCL work</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>60 min teaching</p></li>
<li><p>30 min exercises</p></li>
</ul>
</div>
<p>The goal of the cross-platform portability ecosystems is to allow the same code to run on multiple architectures, therefore reducing code duplication. They are usually based on C++, and use function objects/lambda functions to define the loop body (i.e., the kernel), which can run on multiple architectures like CPU, GPU, and FPGA from different vendors. An exception to this is OpenCL, which originally offered only a C API (although currently also C++ API is available), and uses a separate-source model for the kernel code. However, unlike in many conventional CUDA or HIP implementations, the portability ecosystems require kernels to be written only once if one prefers to run it on CPU and GPU for example. Some notable cross-platform portability ecosystems are alpaka, Kokkos, OpenCL, RAJA, and SYCL. Kokkos, alpaka, and RAJA are individual projects whereas OpenCL and SYCL are standards followed by several projects implementing (and extending) them. For example, some notable SYCL implementations include <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html">Intel oneAPI DPC++</a>, <a class="reference external" href="https://github.com/AdaptiveCpp/AdaptiveCpp/">AdaptiveCpp</a> (previously known as hipSYCL or Open SYCL), <a class="reference external" href="https://github.com/triSYCL/triSYCL">triSYCL</a>, and <a class="reference external" href="https://developer.codeplay.com/products/computecpp/ce/home/">ComputeCPP</a>.</p>
<section id="c-stdpar">
<h2>C++ StdPar<a class="headerlink" href="#c-stdpar" title="Link to this heading"></a></h2>
<p>In C++17, the initial support for parallel execution of standard algorithms has been introduced.
Most algorithms available via the standard <code class="docutils literal notranslate"><span class="pre">&lt;algorithms&gt;</span></code> header were given an overload accepting with an <a class="reference external" href="https://en.cppreference.com/w/cpp/algorithm">*execution policy*</a> argument which allows the programmer to request parallel execution of the standard library function.
While the main goal was to allow low-effort, high-level interface to run existing algorithms like <code class="docutils literal notranslate"><span class="pre">std::sort</span></code> on many CPU cores, implementations are allowed to use other hardware, and functions like <code class="docutils literal notranslate"><span class="pre">std::for_each</span></code> or <code class="docutils literal notranslate"><span class="pre">std::transform</span></code> offer great flexibility in writing the algorithm.</p>
<p>C++ StdPar, also called Parallel STL or PSTL, could be considered similar to directive-based models, as it is very high-level and does not give the programmer fine-grained control over data movement or any access to hardware-specific features like shared (local) memory.
Even the GPU to run on is selected automatically, since standard C++ does not have the concept of a <em>device</em> (but there are vendor extensions allowing the programmer more control)
However, for applications that already relies on algorithms from C++ standard library, StdPar can be a good way to reap the performance benefits of both CPUs and GPUs with minimal code modifications.</p>
<p>For GPU programming, all three vendors offer their implementations of StdPar with the ability to offload code to the GPU: NVIDIA has <code class="docutils literal notranslate"><span class="pre">nvc++</span></code>, AMD has experimental <a class="reference external" href="https://github.com/ROCm/roc-stdpar">roc-stdpar</a>, and Intel offers StdPar offload with their oneAPI compiler. <a class="reference external" href="https://github.com/AdaptiveCpp/AdaptiveCpp/">AdaptiveCpp</a> offers an independent StdPar implementation, able to target devices from all three vendors. While being a part of the C++ standard, the level of support and the maturity of StdPar implementations varies a lot between different compilers: not all compilers support all algorithms, and different heuristics for mapping the algorithm to hardware and for managing data movement can have effect on performance.</p>
<section id="stdpar-compilation">
<h3>StdPar compilation<a class="headerlink" href="#stdpar-compilation" title="Link to this heading"></a></h3>
<p>The build process depends a lot on the used compiler:</p>
<ul class="simple">
<li><p>AdaptiveCpp: Add <code class="docutils literal notranslate"><span class="pre">--acpp-stdpar</span></code> flag when calling <code class="docutils literal notranslate"><span class="pre">acpp</span></code>.</p></li>
<li><p>Intel oneAPI: Add <code class="docutils literal notranslate"><span class="pre">-fsycl</span> <span class="pre">-fsycl-pstl-offload=gpu</span></code> flags when calling <code class="docutils literal notranslate"><span class="pre">icpx</span></code>.</p></li>
<li><p>NVIDIA NVC++: Add <code class="docutils literal notranslate"><span class="pre">-stdpar</span></code> flag when calling <code class="docutils literal notranslate"><span class="pre">nvc++</span></code> (not supported with plain <code class="docutils literal notranslate"><span class="pre">nvcc</span></code>).</p></li>
</ul>
</section>
<section id="stdpar-programming">
<h3>StdPar programming<a class="headerlink" href="#stdpar-programming" title="Link to this heading"></a></h3>
<p>In its simplest form, using C++ standard parallelism requires including an additional <code class="docutils literal notranslate"><span class="pre">&lt;execution&gt;</span></code> header and adding one argument to a supported standard library function.</p>
<p>For example, let’s look at the following sequential code sorting a vector:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To make it run sorting on the GPU, only a minor modification is needed:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span><span class="c1"> // To get std::execution</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par_unseq</span><span class="p">,</span><span class="w"> </span><span class="c1">// This algorithm can be run in parallel</span>
<span class="w">      </span><span class="n">a</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">end</span><span class="p">()</span>
<span class="w">    </span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Now, when compiled with one of the supported compilers, the code will run the sorting on a GPU.</p>
<p>While the can initially seem very limiting, many standard algorithms, such as <code class="docutils literal notranslate"><span class="pre">std::transform</span></code>, <code class="docutils literal notranslate"><span class="pre">std::accumulate</span></code>, <code class="docutils literal notranslate"><span class="pre">std::transform_reduce</span></code>, and <code class="docutils literal notranslate"><span class="pre">std::for_each</span></code> can run custom functions over an array, thus allowing one to offload an arbitrary algorithm, as long as it does not violate typical limitations of GPU kernels, such as not throwing any exceptions and not doing system calls.</p>
</section>
<section id="stdpar-execution-policies">
<h3>StdPar execution policies<a class="headerlink" href="#stdpar-execution-policies" title="Link to this heading"></a></h3>
<p>In C++, there are four different execution policies to choose from:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">std::execution::seq</span></code>: run algorithm serially, don’t parallelize it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">std::execution::par</span></code>: allow parallelizing the algorithm (as if using multiple threads),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">std::execution::unseq</span></code>: allow vectorizing the algorithm (as if using SIMD),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">std::execution::par_unseq</span></code>: allow both vectorizing and parallelizing the algorithm.</p></li>
</ul>
<p>The main difference between <code class="docutils literal notranslate"><span class="pre">par</span></code> and <code class="docutils literal notranslate"><span class="pre">unseq</span></code> is related to thread progress and locks: using <code class="docutils literal notranslate"><span class="pre">unseq</span></code> or <code class="docutils literal notranslate"><span class="pre">par_unseq</span></code> requires that the algorithms does not contain mutexes and other locks between the processes, while <code class="docutils literal notranslate"><span class="pre">par</span></code> does not have this limitation.</p>
<p>For GPU, the optimal choice is <code class="docutils literal notranslate"><span class="pre">par_unseq</span></code>, since this places the least requirement on the compiler in terms of operation ordering.
While <code class="docutils literal notranslate"><span class="pre">par</span></code> is also supported in some cases, it is best avoided, both due to limited compiler support and as an indication that the algorithm is likely a poor fit for the hardware.</p>
</section>
</section>
<section id="kokkos">
<h2>Kokkos<a class="headerlink" href="#kokkos" title="Link to this heading"></a></h2>
<p>Kokkos is an open-source performance portability ecosystem for parallelization on large heterogeneous hardware architectures of which development has mostly taken place on Sandia National Laboratories. The project started in 2011 as a parallel C++ programming model, but have since expanded into a more broad ecosystem including Kokkos Core (the programming model), Kokkos Kernels (math library), and Kokkos Tools (debugging, profiling and tuning tools). By preparing proposals for the C++ standard committee, the project also aims to influence the ISO/C++ language standard such that, eventually, Kokkos capabilities will become native to the language standard. A more detailed introduction is found <a class="reference external" href="https://www.sandia.gov/news/publications/hpc-annual-reports/article/kokkos/">HERE</a>.</p>
<p>The Kokkos library provides an abstraction layer for a variety of different parallel programming models, currently CUDA, HIP, SYCL, HPX, OpenMP, and C++ threads. Therefore, it allows better portability across different hardware manufactured by different vendors, but introduces an additional dependency to the software stack. For example, when using CUDA, only CUDA installation is required, but when using Kokkos with NVIDIA GPUs, Kokkos and CUDA installation are both required. Kokkos is not a very popular choice for parallel programming, and therefore, learning and using Kokkos can be more difficult compared to more established programming models such as CUDA, for which a much larger amount of search results and Stack Overflow discussions can be found.</p>
<section id="kokkos-compilation">
<h3>Kokkos compilation<a class="headerlink" href="#kokkos-compilation" title="Link to this heading"></a></h3>
<p>Furthermore, one challenge with some cross-platform portability libraries is that even on the same system, different projects may require different combinations of compilation settings for the portability library. For example, in Kokkos, one project may wish the default execution space to be a CUDA device, whereas another requires a CPU. Even if the projects prefer the same execution space, one project may desire the Unified Memory to be the default memory space and the other may wish to use pinned GPU memory. It may be burdensome to maintain a large number of library instances on a single system.</p>
<p>However, Kokkos offers a simple way to compile Kokkos library simultaneously with the user project. This is achieved by specifying Kokkos compilation settings (see <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html">HERE</a>) and including the Kokkos Makefile in the user Makefile. CMake is also supported. This way, the user application and Kokkos library are compiled together. The following is an example Makefile for a single-file Kokkos project (hello.cpp) that uses CUDA (Volta architecture) as the backend (default execution space) and Unified Memory as the default memory space:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Makefile for hello.cpp</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-makefile notranslate"><div class="highlight"><pre><span></span><span class="nf">default</span><span class="o">:</span><span class="w"> </span><span class="n">build</span>

<span class="c"># Set compiler</span>
<span class="nv">KOKKOS_PATH</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">$(</span>shell<span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>/kokkos
<span class="nv">CXX</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>hipcc
<span class="c"># CXX = ${KOKKOS_PATH}/bin/nvcc_wrapper</span>

<span class="c"># Variables for the Makefile.kokkos</span>
<span class="nv">KOKKOS_DEVICES</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;HIP&quot;</span>
<span class="c"># KOKKOS_DEVICES = &quot;Cuda&quot;</span>
<span class="nv">KOKKOS_ARCH</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;VEGA90A&quot;</span>
<span class="c"># KOKKOS_ARCH = &quot;Volta70&quot;</span>
<span class="nv">KOKKOS_CUDA_OPTIONS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;enable_lambda,force_uvm&quot;</span>

<span class="c"># Include Makefile.kokkos</span>
<span class="cp">include $(KOKKOS_PATH)/Makefile.kokkos</span>

<span class="nf">build</span><span class="o">:</span><span class="w"> </span><span class="k">$(</span><span class="nv">KOKKOS_LINK_DEPENDS</span><span class="k">)</span> <span class="k">$(</span><span class="nv">KOKKOS_CPP_DEPENDS</span><span class="k">)</span> <span class="n">hello</span>.<span class="n">cpp</span>
<span class="w"> </span><span class="k">$(</span>CXX<span class="k">)</span><span class="w"> </span><span class="k">$(</span>KOKKOS_CPPFLAGS<span class="k">)</span><span class="w"> </span><span class="k">$(</span>KOKKOS_CXXFLAGS<span class="k">)</span><span class="w"> </span><span class="k">$(</span>KOKKOS_LDFLAGS<span class="k">)</span><span class="w"> </span>hello.cpp<span class="w"> </span><span class="k">$(</span>KOKKOS_LIBS<span class="k">)</span><span class="w"> </span>-o<span class="w"> </span>hello
</pre></div>
</div>
</div></div>
<p>To build a <strong>hello.cpp</strong> project with the above Makefile, no steps other than cloning the Kokkos project into the current directory is required.</p>
</section>
<section id="kokkos-programming">
<h3>Kokkos programming<a class="headerlink" href="#kokkos-programming" title="Link to this heading"></a></h3>
<p>When starting to write a project using Kokkos, the first step is understand Kokkos initialization and finalization. Kokkos must be initialized by calling <code class="docutils literal notranslate"><span class="pre">Kokkos::initialize(int&amp;</span> <span class="pre">argc,</span> <span class="pre">char*</span> <span class="pre">argv[])</span></code> and finalized by calling <code class="docutils literal notranslate"><span class="pre">Kokkos::finalize()</span></code>. More details are given in <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html">HERE</a>.</p>
<p>Kokkos uses an execution space model to abstract the details of parallel hardware. The execution space instances map to the available backend options such as CUDA, OpenMP, HIP, or SYCL. If the execution space is not explicitly chosen by the programmer in the source code, the default execution space <code class="docutils literal notranslate"><span class="pre">Kokkos::DefaultExecutionSpace</span></code> is used. This is chosen when the Kokkos library is compiled. The Kokkos execution space model is described in more detail in <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces">HERE</a>.</p>
<p>Similarly, Kokkos uses a memory space model for different types of memory, such as host memory or device memory. If not defined explicitly, Kokkos uses the default memory space specified during Kokkos compilation as described <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces">HERE</a>.</p>
<p>The following is an example of a Kokkos program that initializes Kokkos and prints the execution space and memory space instances:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">hello.cpp</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Execution Space: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span>
<span class="w">    </span><span class="k">typeid</span><span class="p">(</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">DefaultExecutionSpace</span><span class="p">).</span><span class="n">name</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Memory Space: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span>
<span class="w">    </span><span class="k">typeid</span><span class="p">(</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">DefaultExecutionSpace</span><span class="o">::</span><span class="n">memory_space</span><span class="p">).</span><span class="n">name</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>With Kokkos, the data can be accessed either through raw pointers or through Kokkos Views. With raw pointers, the memory allocation into the default memory space can be done using <code class="docutils literal notranslate"><span class="pre">Kokkos::kokkos_malloc(n</span> <span class="pre">*</span> <span class="pre">sizeof(int))</span></code>. Kokkos Views are a data type that provides a way to access data more efficiently in memory corresponding to a certain Kokkos memory space, such as host memory or device memory. A 1-dimensional view of type int* can be created by <code class="docutils literal notranslate"><span class="pre">Kokkos::View&lt;int*&gt;</span> <span class="pre">a(&quot;a&quot;,</span> <span class="pre">n)</span></code>, where <code class="docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code> is a label, and <code class="docutils literal notranslate"><span class="pre">n</span></code> is the size of the allocation in the number of integers. Kokkos determines the optimal layout for the data at compile time for best overall performance as a function of the computer architecture. Furthermore, Kokkos handles the deallocation of such memory automatically. More details about Kokkos Views are found <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html">HERE</a>.</p>
<p>Finally, Kokkos provides three different parallel operations: <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code>, <code class="docutils literal notranslate"><span class="pre">parallel_reduce</span></code>, and <code class="docutils literal notranslate"><span class="pre">parallel_scan</span></code>. The <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> operation is used to execute a loop in parallel. The <code class="docutils literal notranslate"><span class="pre">parallel_reduce</span></code> operation is used to execute a loop in parallel and reduce the results to a single value. The <code class="docutils literal notranslate"><span class="pre">parallel_scan</span></code> operation implements a prefix scan. The usage of <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> and <code class="docutils literal notranslate"><span class="pre">parallel_reduce</span></code> are demonstrated in the examples later in this chapter. More detail about the parallel operations are found <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html">HERE</a>.</p>
</section>
<section id="run-kokkos-hello-cpp-example-in-simple-steps">
<h3>Run Kokkos hello.cpp example in simple steps<a class="headerlink" href="#run-kokkos-hello-cpp-example-in-simple-steps" title="Link to this heading"></a></h3>
<p>The following should work on AMD VEGA90A devices straight out of the box (needs ROCm installation). On NVIDIA Volta V100 devices (needs CUDA installation), use the variables commented out on the Makefile.</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://github.com/kokkos/kokkos.git</span></code></p></li>
<li><p>Copy the above Makefile into the current folder (make sure the indentation of the last line is tab, and not space)</p></li>
<li><p>Copy the above hello.cpp file into the current folder</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">make</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">./hello</span></code></p></li>
</ol>
</section>
</section>
<section id="opencl">
<h2>OpenCL<a class="headerlink" href="#opencl" title="Link to this heading"></a></h2>
<p>OpenCL is a cross-platform, open-standard API for writing parallel programs that execute across heterogeneous platforms consisting of CPUs, GPUs, FPGAs and other devices. The first version of OpenCL (1.0) was released in December 2008, and the latest version of OpenCL (3.0) was released in September 2020. OpenCL is supported by a number of vendors, including AMD, ARM, Intel, NVIDIA, and Qualcomm. It is a royalty-free standard, and the OpenCL specification is maintained by the Khronos Group. OpenCL provides a low-level programming interface initially based on C, but more recently also a C++ interface has become available.</p>
<section id="opencl-compilation">
<h3>OpenCL compilation<a class="headerlink" href="#opencl-compilation" title="Link to this heading"></a></h3>
<p>OpenCL supports two modes for compiling the programs: online and offline. Online compilation occurs at runtime, when the host program calls a function to compile the source code. Online mode allows dynamic generation and loading of kernels, but may incur some overhead due to compilation time and possible errors. Offline compilation occurs before runtime, when the source code of a kernel is compiled into a binary format that can be loaded by the host program. This mode allows faster execution and better optimization of kernels, but may limit the portability of the program, because the binary can only run on the architectures it was compiled for.</p>
<p>OpenCL comes bundled with several parallel programming ecosystems, such as NVIDIA CUDA and Intel oneAPI. For example, after successfully installing such packages and setting up the environment, one may simply compile an OpenCL program by the commands such as <code class="docutils literal notranslate"><span class="pre">icx</span> <span class="pre">cl_devices.c</span> <span class="pre">-lOpenCL</span></code> (Intel oneAPI) or <code class="docutils literal notranslate"><span class="pre">nvcc</span> <span class="pre">cl_devices.c</span> <span class="pre">-lOpenCL</span></code> (NVIDIA CUDA), where <code class="docutils literal notranslate"><span class="pre">cl_devices.c</span></code> is the compiled file. Unlike most other programming models, OpenCL stores kernels as text and compiles them for the device in runtime (JIT-compilation), and thus does not require any special compiler support: one can compile the code using simply <code class="docutils literal notranslate"><span class="pre">gcc</span> <span class="pre">cl_devices.c</span> <span class="pre">-lOpenCL</span></code> (or <code class="docutils literal notranslate"><span class="pre">g++</span></code> when using C++ API), as long as the required libraries and headers are installed in a standard locations.</p>
<p>The AMD compiler installed on LUMI supports both OpenCL C and C++ API, the latter with some limitations.
To compile a program, you can use the AMD compilers on a GPU partition:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>PrgEnv-cray-amd
<span class="gp">$ </span>CC<span class="w"> </span>program.cpp<span class="w"> </span>-lOpenCL<span class="w"> </span>-o<span class="w"> </span>program<span class="w"> </span><span class="c1"># C++ program</span>
<span class="gp">$ </span>cc<span class="w"> </span>program.c<span class="w"> </span>-lOpenCL<span class="w"> </span>-o<span class="w"> </span>program<span class="w"> </span><span class="c1"># C program</span>
</pre></div>
</div>
</section>
<section id="opencl-programming">
<h3>OpenCL programming<a class="headerlink" href="#opencl-programming" title="Link to this heading"></a></h3>
<p>OpenCL programs consist of two parts: a host program that runs on the host device (usually a CPU) and one or more kernels that run on compute devices (such as GPUs). The host program is responsible for the tasks such as managing the devices for the selected platform, allocating memory objects, building and enqueueing kernels, and managing memory objects.</p>
<p>The first steps when writing an OpenCL program are to initialize the OpenCL environment by selecting the platform and devices, creating a context or contexts associated with the selected device(s), and creating a command queue for each device. A simple example of selecting the default device, creating a context and a queue associated with the device is show below.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">OpenCL initialization (C++ API)</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">OpenCL initialization (C API)</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Initialize OpenCL</span>
<span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="o">::</span><span class="n">getDefault</span><span class="p">();</span>
<span class="n">cl</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="nf">context</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
<span class="n">cl</span><span class="o">::</span><span class="n">CommandQueue</span><span class="w"> </span><span class="nf">queue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="c1">// Initialize OpenCL</span>
<span class="n">cl_int</span><span class="w"> </span><span class="n">err</span><span class="p">;</span><span class="w"> </span><span class="c1">// Error code returned by API calls</span>
<span class="n">cl_platform_id</span><span class="w"> </span><span class="n">platform</span><span class="p">;</span>
<span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clGetPlatformIDs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="n">assert</span><span class="p">(</span><span class="n">err</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">CL_SUCCESS</span><span class="p">);</span><span class="w"> </span><span class="c1">// Checking error codes is skipped later for brevity</span>
<span class="n">cl_device_id</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clGetDeviceIDs</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_TYPE_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="n">cl_context</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateContext</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">err</span><span class="p">);</span>
<span class="n">cl_command_queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateCommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">err</span><span class="p">);</span>
</pre></div>
</div>
</div></div>
<p>OpenCL provides two main programming models to manage the memory hierarchy of host and accelerator devices: buffers and shared virtual memory (SVM). Buffers are the traditional memory model of OpenCL, where the host and the devices have separate address spaces and the programmer has to explicitly specify the memory allocations and how and where the memory is accessed. This can be done with class <code class="docutils literal notranslate"><span class="pre">cl::Buffer</span></code> and functions such as <code class="docutils literal notranslate"><span class="pre">cl::CommandQueue::enqueueReadBuffer()</span></code>. Buffers are supported since early versions of OpenCL, and work well across different architectures. Buffers can also take advantage of device-specific memory features, such as constant or local memory.</p>
<p>SVM is a newer memory model of OpenCL, introduced in version 2.0, where the host and the devices share a single virtual address space. Thus, the programmer can use the same pointers to access the data from host and devices simplifying the programming effort. In OpenCL, SVM comes in different levels such as coarse-grained buffer SVM, fine-grained buffer SVM, and fine-grained system SVM. All levels allow using the same pointers across a host and devices, but they differ in their granularity and synchronization requirements for the memory regions. Furthermore, the support for SVM is not universal across all OpenCL platforms and devices, and for example, GPUs such as NVIDIA V100 and A100 only support the coarse-grained SVM buffer. This level requires explicit synchronization for memory accesses from a host and devices (using functions such as <code class="docutils literal notranslate"><span class="pre">cl::CommandQueue::enqueueMapSVM()</span></code> and <code class="docutils literal notranslate"><span class="pre">cl::CommandQueue::enqueueUnmapSVM()</span></code>), making the usage of SVM less convenient. It is further noted that this is unlike the regular Unified Memory offered by CUDA, which is closer to the fine-grained system SVM level in OpenCL.</p>
<p>OpenCL uses a separate-source kernel model where the kernel code is often kept in separate files that may be compiled during runtime. The model allows the kernel source code to be passed as a string to the OpenCL driver after which the program object can be executed on a specific device. Although referred to as the separate-source kernel model, the kernels can still be defined as a string in the host program compilation units as well, which may be a more convenient approach in some cases.</p>
<p>The online compilation with the separate-source kernel model has several advantages over the binary model, which requires offline compilation of kernels into device-specific binaries that can are loaded by the application at runtime. Online compilation preserves the portability and flexibility of OpenCL, as the same kernel source code can run on any supported device. Furthermore, dynamic optimization of kernels based on runtime information, such as input size, work-group size, or device capabilities, is possible. An example of an OpenCL kernel, defined by a string in the host compilation unit, and assigning the global thread index into a global device memory is shown below.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">OpenCL kernel example</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sa">R</span><span class="s">&quot;</span><span class="dl">(</span>
<span class="s">  __kernel void dot(__global int *a) {</span>
<span class="s">    int i = get_global_id(0);</span>
<span class="s">    a[i] = i;</span>
<span class="s">  }</span>
<span class="dl">)</span><span class="s">&quot;</span><span class="p">;</span>
</pre></div>
</div>
</div></div>
<p>The above kernel named <code class="docutils literal notranslate"><span class="pre">dot</span></code> and stored in the string <code class="docutils literal notranslate"><span class="pre">kernel_source</span></code> can be set to build in the host code as follows:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">OpenCL kernel build example (C++ API)</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1">OpenCL kernel build example (C API)</button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">cl</span><span class="o">::</span><span class="n">Program</span><span class="w"> </span><span class="nf">program</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_source</span><span class="p">);</span>
<span class="n">program</span><span class="p">.</span><span class="n">build</span><span class="p">({</span><span class="n">device</span><span class="p">});</span>
<span class="n">cl</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="n">kernel_dot</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;dot&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">cl_int</span><span class="w"> </span><span class="n">err</span><span class="p">;</span>
<span class="n">cl_program</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateProgramWithSource</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernel_source</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">err</span><span class="p">);</span>
<span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clBuildProgram</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="n">cl_kernel</span><span class="w"> </span><span class="n">kernel_dot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateKernel</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;vector_add&quot;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">err</span><span class="p">);</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="sycl">
<h2>SYCL<a class="headerlink" href="#sycl" title="Link to this heading"></a></h2>
<p><a class="reference external" href="https://www.khronos.org/sycl/">SYCL</a> is a royalty-free, open-standard C++ programming model for multi-device programming. It provides a high-level, single-source programming model for heterogeneous systems, including GPUs. There are several implementations of the standard. For GPU programming, <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html">Intel oneAPI DPC++</a> and <a class="reference external" href="https://github.com/AdaptiveCpp/AdaptiveCpp/">AdaptiveCpp</a> (also known as hipSYCL) are the most popular for desktop and HPC GPUs; <a class="reference external" href="https://developer.codeplay.com/products/computecpp/ce/home/">ComputeCPP</a> is a good choice for embedded devices. The same standard-compliant SYCL code should work with any implementation, but they are not binary-compatible.</p>
<p>The most recent version of the SYCL standard is SYCL 2020, and it is the version we will be using in this course.</p>
<section id="sycl-compilation">
<h3>SYCL compilation<a class="headerlink" href="#sycl-compilation" title="Link to this heading"></a></h3>
<section id="id1">
<h4>Intel oneAPI DPC++<a class="headerlink" href="#id1" title="Link to this heading"></a></h4>
<p>For targeting Intel GPUs, it is enough to install <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html">Intel oneAPI Base Toolkit</a>. Then, the compilation is as simple as <code class="docutils literal notranslate"><span class="pre">icpx</span> <span class="pre">-fsycl</span> <span class="pre">file.cpp</span></code>.</p>
<p>It is also possible to use oneAPI for NVIDIA and AMD GPUs. In addition to oneAPI Base Toolkit, the vendor-provided runtime (CUDA or HIP) and the corresponding <a class="reference external" href="https://codeplay.com/solutions/oneapi/">Codeplay oneAPI plugin</a> must be installed.
Then, the code can be compiled using Intel LLVM compiler bundled with oneAPI:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">clang++</span> <span class="pre">-fsycl</span> <span class="pre">-fsycl-targets=nvidia_gpu_sm_86</span> <span class="pre">file.cpp</span></code> for targeting CUDA 8.6 NVIDIA GPU,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clang++</span> <span class="pre">-fsycl</span> <span class="pre">-fsycl-targets=amd_gpu_gfx90a</span></code> for targeting GFX90a AMD GPU.</p></li>
</ul>
</section>
<section id="id2">
<h4>AdaptiveCpp<a class="headerlink" href="#id2" title="Link to this heading"></a></h4>
<p>Using AdaptiveCpp for NVIDIA or AMD GPUs also requires having CUDA or HIP installed first. Then <code class="docutils literal notranslate"><span class="pre">acpp</span></code> can be used for compiling the code, specifying the target devices. For example, here is how to compile the program supporting an AMD and an NVIDIA device:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">acpp</span> <span class="pre">--acpp-targets='hip:gfx90a;cuda:sm_70'</span> <span class="pre">file.cpp</span></code></p></li>
</ul>
</section>
<section id="using-sycl-on-lumi">
<h4>Using SYCL on LUMI<a class="headerlink" href="#using-sycl-on-lumi" title="Link to this heading"></a></h4>
<p>LUMI does not have a system-wide installation of any SYCL framework, but a recent AdaptiveCpp installation is
available in CSC modules:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3
<span class="gp">$ </span>module<span class="w"> </span>use<span class="w"> </span>/appl/local/csc/modulefiles
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>acpp/24.06.0
</pre></div>
</div>
<p>The default compilation target is preset to MI250 GPUs, so to compile a single C++ file it is enough to call <code class="docutils literal notranslate"><span class="pre">acpp</span> <span class="pre">-O2</span> <span class="pre">file.cpp</span></code>.</p>
<p>When running applications built with AdaptiveCpp, one can often see the warning “dag_direct_scheduler: Detected a requirement that is neither of discard access mode”, reflecting the lack of an optimization hint when using buffer-accessor model. The warning is harmless and can be ignored.</p>
</section>
</section>
<section id="sycl-programming">
<h3>SYCL programming<a class="headerlink" href="#sycl-programming" title="Link to this heading"></a></h3>
<p>SYCL is, in many aspects, similar to OpenCL, but uses, like Kokkos, a single-source model with kernel lambdas.</p>
<p>To submit a task to device, first a <cite>sycl::queue</cite> must be created, which is used as a way to manage the
task scheduling and execution. In the simplest case, that’s all the initialization one needs:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Create an out-of-order queue on the default device:</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// Now we can submit tasks to q!</span>
<span class="p">}</span>
</pre></div>
</div>
<p>If one wants more control, the device can be explicitly specified, or additional properties can be passed to
a queue:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Iterate over all available devices</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">get_devices</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Print the device name</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Creating a queue on &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">name</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// Create an in-order queue for the current device</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="nf">q</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">in_order</span><span class="p">()});</span>
<span class="w">  </span><span class="c1">// Now we can submit tasks to q!</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Memory management can be done in two different ways: <em>buffer-accessor</em> model and <em>unified shared memory</em> (USM).
The choice of the memory management models also influences how the GPU tasks are synchronized.</p>
<p>In the <em>buffer-accessor</em> model, a <code class="docutils literal notranslate"><span class="pre">sycl::buffer</span></code> objects are used to represent arrays of data. A buffer is
not mapped to any single one memory space, and can be migrated between the GPU and the CPU memory
transparently. The data in <code class="docutils literal notranslate"><span class="pre">sycl::buffer</span></code> cannot be read or written directly, an accessor must be created.
<code class="docutils literal notranslate"><span class="pre">sycl::accessor</span></code> objects specify the location of data access (host or a certain GPU kernel) and the access
mode (read-only, write-only, read-write).
Such approach allows optimizing task scheduling by building a directed acyclic graph (DAG) of data dependencies:
if kernel <em>A</em> creates a write-only accessor to a buffer, and then kernel <em>B</em> is submitted with a read-only
accessor to the same buffer, and then a host-side read-only accessor is requested, then it can be deduced that
<em>A</em> must complete before <em>B</em> is launched and also that the results must be copied to the host
before the host task can proceed, but the host task can run in parallel with kernel <em>B</em>.
Since the dependencies between tasks can be built automatically, by default SYCL uses <em>out-of-order queues</em>:
when two tasks are submitted to the same <code class="docutils literal notranslate"><span class="pre">sycl::queue</span></code>, it is not guaranteed that the second one will launch
only after the first one completes.
When launching a kernel, accessors must be created:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create a buffer of n integers</span>
<span class="k">auto</span><span class="w"> </span><span class="n">buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">));</span>
<span class="c1">// Submit a kernel into a queue; cgh is a helper object</span>
<span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Create write-only accessor for buf</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">write</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">  </span><span class="c1">// Define a kernel: n threads execute the following lambda</span>
<span class="w">  </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">KernelName</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="c1">// The data is written to the buffer via acc</span>
<span class="w">      </span><span class="n">acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/*...*/</span>
<span class="w">  </span><span class="p">});</span>
<span class="p">});</span>
<span class="cm">/* If we now submit another kernel with accessor to buf, it will not</span>
<span class="cm"> * start running until the kernel above is done */</span>
</pre></div>
</div>
<p>Buffer-accessor model simplifies many aspects of heterogeneous programming and prevents many synchronization-related
bugs, but it only allows very coarse control of data movement and kernel execution.</p>
<p>The <em>USM</em> model is similar to how NVIDIA CUDA or AMD HIP manage memory. The programmer has to explicitly allocate
the memory on the device (<code class="docutils literal notranslate"><span class="pre">sycl::malloc_device</span></code>), on the host (<code class="docutils literal notranslate"><span class="pre">sycl::malloc_host</span></code>), or in the shared memory
space (<code class="docutils literal notranslate"><span class="pre">sycl::malloc_shared</span></code>). Despite its name, unified shared memory, and the similarity to OpenCL’s SVM, not
all USM allocations are shared: for example, a memory allocated by <code class="docutils literal notranslate"><span class="pre">sycl::malloc_device</span></code> cannot be accessed
from the host. The allocation functions return memory pointers that can be used directly, without accessors.
This means that the programmer have to ensure the correct synchronization between host and device tasks to avoid
data races. With USM, it is often convenient to use <em>in-order queues</em> with USM, instead of the default <em>out-of-order</em> queues.
More information on USM can be found in the <a class="reference external" href="https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm">Section 4.8 of SYCL 2020 specification</a>.</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create a shared (migratable) allocation of n integers</span>
<span class="c1">// Unlike with buffers, we need to specify a queue (or, explicitly, a device and a context)</span>
<span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="c1">// Submit a kernel into a queue; cgh is a helper object</span>
<span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Define a kernel: n threads execute the following lambda</span>
<span class="w">  </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">KernelName</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="c1">// The data is directly written to v</span>
<span class="w">      </span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/*...*/</span>
<span class="w">  </span><span class="p">});</span>
<span class="p">});</span>
<span class="c1">// If we want to access v, we have to ensure that the kernel has finished</span>
<span class="n">q</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>
<span class="c1">// After we&#39;re done, the memory must be deallocated</span>
<span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="exercise">
<h3>Exercise<a class="headerlink" href="#exercise" title="Link to this heading"></a></h3>
<div class="admonition-exercise-implement-saxpy-in-sycl exercise important admonition" id="exercise-0">
<p class="admonition-title">Exercise: Implement SAXPY in SYCL</p>
<p>In this exercise we would like to write (fill-in-the-blanks) a simple code doing SAXPY (vector addition).</p>
<p>To compile and run the code interactively, first make an allocation and load the AdaptiveCpp module:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>salloc<span class="w"> </span>-A<span class="w"> </span>project_465002387<span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>-t<span class="w"> </span><span class="m">1</span>:00:00<span class="w"> </span>-p<span class="w"> </span>standard-g<span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">1</span>
<span class="go">....</span>
<span class="go">salloc: Granted job allocation 123456</span>

<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>use<span class="w"> </span>/appl/local/csc/modulefiles
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3<span class="w"> </span>acpp/24.06.0
</pre></div>
</div>
<p>Now you can run a simple device-detection utility to check that a GPU is available (note <code class="docutils literal notranslate"><span class="pre">srun</span></code>):</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>acpp-info<span class="w"> </span>-l
<span class="go">=================Backend information===================</span>
<span class="go">Loaded backend 0: HIP</span>
<span class="go">  Found device: AMD Instinct MI250X</span>
<span class="go">Loaded backend 1: OpenMP</span>
<span class="go">  Found device: hipSYCL OpenMP host device</span>
</pre></div>
</div>
</div></blockquote>
<p>If you have not done it already, clone the repository using <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://github.com/ENCCS/gpu-programming.git</span></code> or <strong>update it</strong> using <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">pull</span> <span class="pre">origin</span> <span class="pre">main</span></code>.</p>
<p>Now, let’s look at the example code in <code class="docutils literal notranslate"><span class="pre">content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp</span></code>:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Create an in-order queue</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">{</span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">in_order</span><span class="p">()};</span>
<span class="w">  </span><span class="c1">// Print the device name, just for fun</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Running on &quot;</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">q</span><span class="p">.</span><span class="n">get_device</span><span class="p">().</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">name</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1024</span><span class="p">;</span><span class="w"> </span><span class="c1">// Vector size</span>

<span class="w">  </span><span class="c1">// Allocate device and host memory for the first input vector</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_host</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="hll"><span class="w">  </span><span class="c1">// Bonus question: Can we use `std::vector` here instead of `malloc_host`?</span>
</span><span class="hll"><span class="w">  </span><span class="c1">// TODO: Allocate second input vector on device and host, d_y and h_y</span>
</span><span class="w">  </span><span class="c1">// Allocate device and host memory for the output vector</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_host</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">h_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="hll"><span class="w">    </span><span class="c1">// TODO: Initialize h_y somehow</span>
</span><span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.42f</span><span class="p">;</span>

<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">h_x</span><span class="p">,</span><span class="w"> </span><span class="n">d_x</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="hll"><span class="w">  </span><span class="c1">// TODO: Copy h_y to d_y</span>
</span><span class="hll"><span class="w">  </span><span class="c1">// Bonus question: Why don&#39;t we need to wait before using the data?</span>
</span>
<span class="w">  </span><span class="c1">// Run the kernel</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="hll"><span class="w">    </span><span class="c1">// TODO: Modify the code to compute z[i] = alpha * x[i] + y[i]</span>
</span><span class="w">    </span><span class="n">d_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">d_x</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">});</span>

<span class="hll"><span class="w">  </span><span class="c1">// TODO: Copy d_z to h_z</span>
</span><span class="hll"><span class="w">  </span><span class="c1">// TODO: Wait for the copy to complete</span>
</span>
<span class="w">  </span><span class="c1">// Check the results</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">ok</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">ref</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">h_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">h_y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"> </span><span class="c1">// Reference value</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">tol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-5</span><span class="p">;</span><span class="w">                    </span><span class="c1">// Relative tolerance</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">abs</span><span class="p">((</span><span class="n">h_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">ref</span><span class="p">))</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tol</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">abs</span><span class="p">(</span><span class="n">ref</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">h_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">h_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">h_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">                </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">      </span><span class="n">ok</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">      </span><span class="k">break</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ok</span><span class="p">)</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Results are correct!&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">else</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Results are NOT correct!&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Free allocated memory</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">d_x</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">h_x</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="hll"><span class="w">  </span><span class="c1">// TODO: Free d_y, h_y.</span>
</span><span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">d_y</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">h_y</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To compile and run the code, use the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>acpp<span class="w"> </span>-O3<span class="w"> </span>exercise-sycl-saxpy.cpp<span class="w"> </span>-o<span class="w"> </span>exercise-sycl-saxpy
<span class="gp">$ </span>srun<span class="w"> </span>./exercise-sycl-saxpy
<span class="go">Running on AMD Instinct MI250X</span>
<span class="go">Results are correct!</span>
</pre></div>
</div>
<p>The code will not compile as-is!
Your task is to fill in missing bits indicated by <code class="docutils literal notranslate"><span class="pre">TODO</span></code> comments.
You can also test your understanding using the “Bonus questions” in the code.</p>
<p>If you feel stuck, take a look at the <code class="docutils literal notranslate"><span class="pre">exercise-sycl-saxpy-solution.cpp</span></code> file.</p>
</div>
</section>
</section>
<section id="alpaka">
<h2>alpaka<a class="headerlink" href="#alpaka" title="Link to this heading"></a></h2>
<p>The <a class="reference external" href="https://github.com/alpaka-group/alpaka3">alpaka</a> library is an open-source header-only C++20 abstraction library for accelerator development.</p>
<p>Its aim is to provide performance portability across accelerators by abstracting the underlying levels of parallelism. The project provides a single-source C++ API that enables developers to write parallel code once and run it on different hardware architectures without modification.
The name “alpaka” comes from <strong>A</strong>bstractions for <strong>L</strong>evels of <strong>P</strong>arallelism, <strong>A</strong>lgorithms, and <strong>K</strong>ernels for <strong>A</strong>ccelerators.
The library is platform-independent and supports the concurrent and cooperative use of multiple devices, including host CPUs (x86, ARM, and RISC-V) and GPUs from different vendors (NVIDIA, AMD, and Intel).
A variety of accelerator backends, CUDA, HIP, SYCL, OpenMP, and serial execution, are available and can be selected based on the target device.
Only a single implementation of a user kernel is required, expressed as a function object with a standardized interface.
This eliminates the need to write specialized CUDA, HIP, SYCL, OpenMP, Intel TBB or threading code.
Moreover, multiple accelerator backends can be combined to target different vendor hardware within a single system and even within a single application.</p>
<p>The abstraction is based on a virtual index domain decomposed into equally sized chunks called frames.
<strong>alpaka</strong> provides a uniform abstraction to traverse these frames, independent of the underlying hardware.
Algorithms to be parallelized map the chunked index domain and native worker threads onto the data, expressing the computation as kernels that are executed in parallel threads (SIMT), thereby also leveraging SIMD units.
Unlike native parallelism models such as CUDA, HIP, and SYCL, <strong>alpaka</strong> kernels are not restricted to three dimensions.
Explicit caching of data within a frame via shared memory allows developers to fully unleash the performance of the compute device.
Additionally, <strong>alpaka</strong> offers primitive functions such as iota, transform, transform-reduce, reduce, and concurrent, simplifying the development of portable high-performance applications.
Host, device, mapped, and managed multi-dimensional views provide a natural way to operate on data.</p>
<p>Here we demonstrate the usage of <strong>alpaka3</strong>, which is a complete rewrite of <a class="reference external" href="https://github.com/alpaka-group/alpaka">alpaka</a>.
It is planned to merge this separate codebase back into the mainline alpaka repository before the first release in Q2/Q3 of 2026.
Nevertheless, the code is well-tested and can be used for development today.</p>
<section id="installing-alpaka-on-your-system">
<h3>Installing alpaka on your system<a class="headerlink" href="#installing-alpaka-on-your-system" title="Link to this heading"></a></h3>
<p>For ease of use, we recommend installing alpaka using CMake as described below. For other ways to use alpaka in your projects, see the <a class="reference external" href="https://alpaka3.readthedocs.io/en/latest/basic/install.html">alpaka3 documentation</a>.</p>
<ol class="arabic">
<li><p><strong>Clone the repository</strong></p>
<p>Clone the alpaka source code from GitHub to a directory of your choice:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/alpaka-group/alpaka3.git
<span class="nb">cd</span><span class="w"> </span>alpaka
</pre></div>
</div>
</li>
<li><p><strong>Set installation directory</strong></p>
<p>Set the <code class="docutils literal notranslate"><span class="pre">ALPAKA_DIR</span></code> environment variable to the directory where you want to install alpaka. This can be any directory you choose where you have write access.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">ALPAKA_DIR</span><span class="o">=</span>/path/to/your/alpaka/install/dir
</pre></div>
</div>
</li>
<li><p><strong>Build and install</strong></p>
<p>Create a build directory and use CMake to build and install alpaka. We use <code class="docutils literal notranslate"><span class="pre">CMAKE_INSTALL_PREFIX</span></code> to tell CMake where to install the library.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>build
cmake<span class="w"> </span>-B<span class="w"> </span>build<span class="w"> </span>-S<span class="w"> </span>.<span class="w"> </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span><span class="nv">$ALPAKA_DIR</span>
cmake<span class="w"> </span>--build<span class="w"> </span>build<span class="w"> </span>--parallel
</pre></div>
</div>
</li>
<li><p><strong>Update environment</strong></p>
<p>To make sure that other projects can find your alpaka installation, you should add the installation directory to your <code class="docutils literal notranslate"><span class="pre">CMAKE_PREFIX_PATH</span></code>. You can do this by adding the following line to your shell configuration file (e.g. <code class="docutils literal notranslate"><span class="pre">~/.bashrc</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">CMAKE_PREFIX_PATH</span><span class="o">=</span><span class="nv">$ALPAKA_DIR</span>:<span class="nv">$CMAKE_PREFIX_PATH</span>
</pre></div>
</div>
<p>You will need to source your shell configuration file or open a new terminal for the changes to take effect.</p>
</li>
</ol>
</section>
<section id="alpaka-compilation">
<h3>alpaka Compilation<a class="headerlink" href="#alpaka-compilation" title="Link to this heading"></a></h3>
<p>We recommend building your projects which use alpaka using CMake. A variety of strategies can be used to deal with building your application for a specific device or set of devices. Here we show a minimal way to get started, but this is by no means the only way to set up your projects.
Please refer to the <a class="reference external" href="https://alpaka3.readthedocs.io/en/latest/basic/install.html">alpaka3 documentation</a> for alternative ways to use alpaka in your project, including a way to make your source code agnostic to the accelerator being targeted by defining a device specification in CMake.</p>
<p>The following example demonstrates a <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> for a single-file project using alpaka3 (<code class="docutils literal notranslate"><span class="pre">main.cpp</span></code> which is presented in the section below):</p>
<blockquote>
<div><div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span><span class="w"> </span><span class="s">3.25</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">myAlpakaApp</span><span class="w"> </span><span class="s">VERSION</span><span class="w"> </span><span class="s">1.0</span><span class="p">)</span>

<span class="c"># Find installed alpaka</span>
<span class="nb">find_package</span><span class="p">(</span><span class="s">alpaka</span><span class="w"> </span><span class="s">REQUIRED</span><span class="p">)</span>

<span class="c"># Build the executable</span>
<span class="nb">add_executable</span><span class="p">(</span><span class="s">myAlpakaApp</span><span class="w"> </span><span class="s">main.cpp</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">myAlpakaApp</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s">alpaka::alpaka</span><span class="p">)</span>
<span class="nb">alpaka_finalize</span><span class="p">(</span><span class="s">myAlpakaApp</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<section id="using-alpaka-on-lumi">
<h4>Using alpaka on LUMI<a class="headerlink" href="#using-alpaka-on-lumi" title="Link to this heading"></a></h4>
<p>To load the environment for using the AMD GPUs on LUMI with HIP, one can use the following modules -</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>buildtools/24.03
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>PrgEnv-amd
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>craype-accel-amd-gfx90a
<span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">CXX</span><span class="o">=</span>hipcc
</pre></div>
</div>
</section>
</section>
<section id="alpaka-programming">
<h3>alpaka Programming<a class="headerlink" href="#alpaka-programming" title="Link to this heading"></a></h3>
<p>When starting with alpaka3, the first step is understanding the <strong>device selection model</strong>. Unlike frameworks that require explicit initialization calls, alpaka3 uses a device specification to determine which backend and hardware to use. The device specification consists of two components:</p>
<ul class="simple">
<li><p><strong>API</strong>: The parallel programming interface (host, cuda, hip, oneApi)</p></li>
<li><p><strong>Device Kind</strong>: The type of hardware (cpu, nvidiaGpu, amdGpu, intelGpu)</p></li>
</ul>
<p>Here we specify and use these at runtime to select and initialize devices. The device selection process is described in detail in the alpaka3 documentation.</p>
<p>alpaka3 uses an <strong>execution space model</strong> to abstract parallel hardware details. A device selector is created using <code class="docutils literal notranslate"><span class="pre">alpaka::onHost::makeDeviceSelector(devSpec)</span></code>, which returns an object that can query available devices and create device instances for the selected backend.</p>
<p>The following example demonstrates a basic alpaka program that initializes a device and prints information about it:</p>
<blockquote>
<div><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdlib&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">getDeviceSpec</span><span class="p">()</span>
<span class="p">{</span>
<span class="w">    </span><span class="cm">/* Select a device, possible combinations of api+deviceKind:</span>
<span class="cm">     * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">     * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">     */</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">DeviceSpec</span><span class="p">{</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">};</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="o">**</span><span class="w"> </span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Initialize device specification and selector</span>
<span class="w">    </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">DeviceSpec</span><span class="w"> </span><span class="n">devSpec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getDeviceSpec</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">deviceSelector</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">devSpec</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Query available devices</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">num_devices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">deviceSelector</span><span class="p">.</span><span class="n">getDeviceCount</span><span class="p">();</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Number of available devices: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">num_devices</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">num_devices</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;No devices found for the selected backend</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Select and initialize the first device</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">deviceSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Using device: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">getName</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">EXIT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
<p>alpaka3 provides memory management abstractions through buffers and views. Memory can be allocated on host or device using <code class="docutils literal notranslate"><span class="pre">alpaka::allocBuf&lt;T,</span> <span class="pre">Idx&gt;(device,</span> <span class="pre">extent)</span></code>. Data transfers between host and device are handled through <code class="docutils literal notranslate"><span class="pre">alpaka::memcpy(queue,</span> <span class="pre">dst,</span> <span class="pre">src)</span></code>. The library automatically manages memory layouts for optimal performance on different architectures.</p>
<p>For parallel execution, alpaka3 provides kernel abstractions. Kernels are defined as functors or lambda functions and executed using work division specifications that define the parallelization strategy. The framework supports various parallel patterns including element-wise operations, reductions, and scans.</p>
<section id="tour-of-alpaka-features">
<h4>Tour of <strong>alpaka</strong> Features<a class="headerlink" href="#tour-of-alpaka-features" title="Link to this heading"></a></h4>
<p>Now we will quickly explore the most commonly used features of alpaka and go over some basic usage. A quick reference of commonly used alpaka features is available <a class="reference external" href="https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html">here.</a></p>
<p><strong>General setup</strong>: Include the consolidated header once and you are ready to start using alpaka.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">myProject</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// Your code here</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Accelerator, platform, and device management</strong>: Select devices by combining the desired API with the appropriate hardware kind using the device selector.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">devSelector</span><span class="p">.</span><span class="n">getDeviceCount</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">throw</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">runtime_error</span><span class="p">(</span><span class="s">&quot;No device found!&quot;</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">auto</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</pre></div>
</div>
<p><strong>Queues and events</strong>: Create blocking or non-blocking queues per device, record events, and synchronize work as needed.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">nonBlockingQueue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">nonBlocking</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">blockingQueue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">event</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">makeEvent</span><span class="p">();</span>
<span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">event</span><span class="p">);</span>
<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">wait</span><span class="p">(</span><span class="n">event</span><span class="p">);</span>
<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">wait</span><span class="p">(</span><span class="n">queue</span><span class="p">);</span>
</pre></div>
</div>
<p><strong>Memory management</strong>: Allocate host, device, mapped, unified, or deferred buffers, create non-owning views, and move data portably with <cite>memcpy</cite>, <cite>memset</cite>, and <cite>fill</cite>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">hostBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHost</span><span class="o">&lt;</span><span class="n">DataType</span><span class="o">&gt;</span><span class="p">(</span><span class="n">extent3D</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">devBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">alloc</span><span class="o">&lt;</span><span class="n">DataType</span><span class="o">&gt;</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">extentMd</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">devMappedBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocMapped</span><span class="o">&lt;</span><span class="n">DataType</span><span class="o">&gt;</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">extentMd</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">hostView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">makeView</span><span class="p">(</span><span class="n">api</span><span class="o">::</span><span class="n">host</span><span class="p">,</span><span class="w"> </span><span class="n">externPtr</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">Vec</span><span class="p">{</span><span class="n">numElements</span><span class="p">});</span>
<span class="k">auto</span><span class="w"> </span><span class="n">devNonOwningView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devBuffer</span><span class="p">.</span><span class="n">getView</span><span class="p">();</span>

<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memset</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">devBuffer</span><span class="p">,</span><span class="w"> </span><span class="kt">uint8_t</span><span class="p">{</span><span class="mi">0</span><span class="p">});</span>
<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">devBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">hostBuffer</span><span class="p">);</span>
<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">fill</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">devBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">DataType</span><span class="p">{</span><span class="mi">42</span><span class="p">});</span>
</pre></div>
</div>
<p><strong>Kernel execution</strong>: Build a <cite>FrameSpec</cite> manually or request one tuned for your data type, then enqueue kernels with automatic or explicit executors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">constexpr</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2u</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">IdxType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">size_t</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">DataType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">int</span><span class="p">;</span>

<span class="n">IdxType</span><span class="w"> </span><span class="n">valueX</span><span class="p">,</span><span class="w"> </span><span class="n">valueY</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">extentMD</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">Vec</span><span class="p">{</span><span class="n">valueY</span><span class="p">,</span><span class="w"> </span><span class="n">valueX</span><span class="p">};</span>

<span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">FrameSpec</span><span class="p">{</span><span class="n">numFramesMd</span><span class="p">,</span><span class="w"> </span><span class="n">frameExtentMd</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tunedSpec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">getFrameSpec</span><span class="o">&lt;</span><span class="n">DataType</span><span class="o">&gt;</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">extentMd</span><span class="p">);</span>

<span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">tunedSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="n">kernelArgs</span><span class="p">...});</span>

<span class="k">auto</span><span class="w"> </span><span class="n">executor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">exec</span><span class="o">::</span><span class="n">cpuSerial</span><span class="p">;</span>
<span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span><span class="w"> </span><span class="n">tunedSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="n">kernelArgs</span><span class="p">...});</span>
</pre></div>
</div>
<p><strong>Kernel implementation</strong>: Write kernels as functors annotated with <cite>ALPAKA_FN_ACC</cite>, use shared memory, synchronization, atomics, and math helpers directly inside the kernel body.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">MyKernel</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">ALPAKA_FN_ACC</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="k">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="o">&amp;</span><span class="w"> </span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="k">auto</span><span class="p">...</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="k">const</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">idxMd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc</span><span class="p">.</span><span class="n">getIdxWithin</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">origin</span><span class="o">::</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">unit</span><span class="o">::</span><span class="n">blocks</span><span class="p">);</span>

<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">sharedMdArray</span><span class="w"> </span><span class="o">=</span>
<span class="w">            </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">declareSharedMdArray</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">uniqueId</span><span class="p">()</span><span class="o">&gt;</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">CVec</span><span class="o">&lt;</span><span class="kt">uint32_t</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="o">&gt;</span><span class="p">{});</span>

<span class="w">        </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">syncBlockThreads</span><span class="p">(</span><span class="n">acc</span><span class="p">);</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">old</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">onAcc</span><span class="o">::</span><span class="n">atomicAdd</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="p">...);</span>
<span class="w">        </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">memFence</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">scope</span><span class="o">::</span><span class="n">block</span><span class="p">);</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">sinValue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">math</span><span class="o">::</span><span class="n">sin</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="run-alpaka3-example-in-simple-steps">
<h4>Run alpaka3 Example in Simple Steps<a class="headerlink" href="#run-alpaka3-example-in-simple-steps" title="Link to this heading"></a></h4>
<p>The following example works on systems with CMake 3.25+ and an appropriate C++ compiler. For GPU execution, ensure the corresponding runtime (CUDA, ROCm, or oneAPI) is installed.</p>
<ol class="arabic">
<li><p>Create a directory for your project:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>my_alpaka_project<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>my_alpaka_project
</pre></div>
</div>
</li>
<li><p>Copy the CMakeLists.txt from above into the current folder</p></li>
<li><p>Copy the main.cpp file into the current folder</p></li>
<li><p>Configure and build:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cmake<span class="w"> </span>-B<span class="w"> </span>build<span class="w"> </span>-S<span class="w"> </span>.<span class="w"> </span>-Dalpaka_DEP_HIP<span class="o">=</span>ON
cmake<span class="w"> </span>--build<span class="w"> </span>build<span class="w"> </span>--parallel
</pre></div>
</div>
</li>
<li><p>Run the executable:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/myAlpakaApp
</pre></div>
</div>
</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The device specification system allows you to select the target device at CMake configuration time. The format is <code class="docutils literal notranslate"><span class="pre">&quot;api:deviceKind&quot;</span></code>, where:</p>
<ul class="simple">
<li><p><strong>api</strong>: The parallel programming interface (<code class="docutils literal notranslate"><span class="pre">host</span></code>, <code class="docutils literal notranslate"><span class="pre">cuda</span></code>, <code class="docutils literal notranslate"><span class="pre">hip</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi</span></code>)</p></li>
<li><p><strong>deviceKind</strong>: The type of device (<code class="docutils literal notranslate"><span class="pre">cpu</span></code>, <code class="docutils literal notranslate"><span class="pre">nvidiaGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">amdGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">intelGpu</span></code>)</p></li>
</ul>
<p>Available combinations are: <code class="docutils literal notranslate"><span class="pre">host:cpu</span></code>, <code class="docutils literal notranslate"><span class="pre">cuda:nvidiaGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">hip:amdGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi:cpu</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi:intelGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi:nvidiaGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi:amdGpu</span></code></p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The CUDA, HIP, or Intel backends only work if the CUDA SDK, HIP SDK, or OneAPI SDK are available respectively</p>
</div>
</section>
<section id="expected-output">
<h4>Expected output<a class="headerlink" href="#expected-output" title="Link to this heading"></a></h4>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of available devices: 1
Using device: [Device Name]
</pre></div>
</div>
<p>The device name will vary depending on your hardware (e.g., “NVIDIA A100”, “AMD MI250X”, or your CPU model).</p>
</section>
</section>
<section id="compile-and-execute-examples">
<h3>Compile and Execute Examples<a class="headerlink" href="#compile-and-execute-examples" title="Link to this heading"></a></h3>
<p>You can test the <strong>alpaka</strong> provided examples from the <a class="reference external" href="#examples">example section</a>.
The examples have hard coded the usage of the AMD ROCm platform required on LUMI.
To switch to CPU usage only you can simply replace <code class="docutils literal notranslate"><span class="pre">ap::onHost::makeDeviceSelector(ap::api::hip,</span> <span class="pre">ap::deviceKind::amdGpu);</span></code> with <code class="docutils literal notranslate"><span class="pre">ap::onHost::makeDeviceSelector(ap::api::host,</span> <span class="pre">ap::deviceKind::cpu);</span></code></p>
<p>The following steps assume you have downloaded alpaka already and the path to the <strong>alapka</strong> source code is stored in the environment variable <code class="docutils literal notranslate"><span class="pre">ALPAKA_DIR</span></code>.
To test the example copy the code into a file <code class="docutils literal notranslate"><span class="pre">main.cpp</span></code></p>
<p>Alternatively, <a class="reference external" href="https://godbolt.org/z/69exnG4xb">click here</a> to try the first example using in the godbolt compiler explorer.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-5-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-5-5-0" name="5-0" role="tab" tabindex="0">HIP for AMD GPUs</button><button aria-controls="panel-5-5-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-1" name="5-1" role="tab" tabindex="-1">Host compiler for CPU</button><button aria-controls="panel-5-5-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-2" name="5-2" role="tab" tabindex="-1">CUDA for NVIDIA GPUs</button><button aria-controls="panel-5-5-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-3" name="5-3" role="tab" tabindex="-1">oneAPI SYCL for CPU</button><button aria-controls="panel-5-5-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-4" name="5-4" role="tab" tabindex="-1">oneAPI SYCL for Intel GPUs</button><button aria-controls="panel-5-5-5" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-5" name="5-5" role="tab" tabindex="-1">oneAPI SYCL for AMD GPUs</button><button aria-controls="panel-5-5-6" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-6" name="5-6" role="tab" tabindex="-1">oneAPI SYCL for NVIDIA GPUs</button></div><div aria-labelledby="tab-5-5-0" class="sphinx-tabs-panel" id="panel-5-5-0" name="5-0" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::hip, ap::deviceKind::amdGpu);</span>
<span class="c1"># We use CC to refer to the compiler to work smoothly with the LUMI environment</span>
CC<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-x<span class="w"> </span>hip<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-1" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-1" name="5-1" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::host, ap::deviceKind::cpu);</span>
<span class="c1"># We use CC to refer to the compiler to work smoothly with the LUMI environment</span>
CC<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-2" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-2" name="5-2" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::cuda, ap::deviceKind::nvidiaGpu);</span>
nvcc<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>--expt-relaxed-constexpr<span class="w"> </span>-x<span class="w"> </span>cuda<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-3" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-3" name="5-3" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::oneApi, ap::deviceKind::cpu);</span>
icpx<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>spir64_x86_64<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-4" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-4" name="5-4" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::oneApi, ap::deviceKind::intelGpu);</span>
icpx<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>spir64<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-5" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-5" name="5-5" role="tabpanel" tabindex="0"><div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding Codeplay oneAPI plugin as described <a class="reference external" href="https://codeplay.com/solutions/oneapi/plugins/">here</a>.</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::oneApi, ap::deviceKind::amdGpu);</span>
icpx<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>amd_gpu_gfx90a<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-6" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-6" name="5-6" role="tabpanel" tabindex="0"><div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding Codeplay oneAPI plugin as described <a class="reference external" href="https://codeplay.com/solutions/oneapi/plugins/">here</a>.</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::oneApi, ap::deviceKind::nvidiaGpu);</span>
icpx<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>nvptx64-nvidia-cuda<span class="w"> </span>-Xsycl-target-backend<span class="o">=</span>nvptx64-nvidia-cuda<span class="w"> </span>--offload-arch<span class="o">=</span>sm_80<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div></div>
</section>
<section id="id3">
<h3>Exercise<a class="headerlink" href="#id3" title="Link to this heading"></a></h3>
<div class="admonition-exercise-write-a-vector-add-kernel-in-alpaka exercise important admonition" id="exercise-1">
<p class="admonition-title">Exercise: Write a vector add kernel in alpaka</p>
<p>In this exercise we would like to write (fill-in-the-blanks) a simple kernel to add two vectors.</p>
<p>To compile and run the code interactively, first we first need to get an allocation on a GPU node and load the modules for alpaka:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>-p<span class="w"> </span>dev-g<span class="w"> </span>--gpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>--time<span class="o">=</span><span class="m">00</span>:20:00<span class="w"> </span>--account<span class="o">=</span>project_465002387<span class="w"> </span>--pty<span class="w"> </span>bash
<span class="go">....</span>
<span class="go">srun: job 1234 queued and waiting for resources</span>
<span class="go">srun: job 1234 has been allocated resources</span>

<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>buildtools/24.03
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>PrgEnv-amd
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>craype-accel-amd-gfx90a
<span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">CXX</span><span class="o">=</span>hipcc
</pre></div>
</div>
<p>Now you can run a simple device-detection utility to check that a GPU is available (note <code class="docutils literal notranslate"><span class="pre">srun</span></code>):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>rocm-smi

<span class="go">======================================= ROCm System Management Interface =======================================</span>
<span class="go">================================================= Concise Info =================================================</span>
<span class="go">Device  [Model : Revision]    Temp    Power  Partitions      SCLK    MCLK     Fan  Perf    PwrCap  VRAM%  GPU%</span>
<span class="go">        Name (20 chars)       (Edge)  (Avg)  (Mem, Compute)</span>
<span class="go">================================================================================================================</span>
<span class="go">0       [0x0b0c : 0x00]       45.0°C  N/A    N/A, N/A        800Mhz  1600Mhz  0%   manual  0.0W      0%   0%</span>
<span class="go">        AMD INSTINCT MI200 (</span>
<span class="go">================================================================================================================</span>
<span class="go">============================================= End of ROCm SMI Log ==============================================</span>
</pre></div>
</div>
<p>Now, let’s look at the code to set up the exercise:</p>
<p>Below we use fetch content with our CMake to get started with alpaka quickly.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">CMakeLists.txt</span><a class="headerlink" href="#id4" title="Link to this code"></a></div>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span><span class="w"> </span><span class="s">3.25</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">vectorAdd</span><span class="w"> </span><span class="s">LANGUAGES</span><span class="w"> </span><span class="s">CXX</span><span class="w"> </span><span class="s">VERSION</span><span class="w"> </span><span class="s">1.0</span><span class="p">)</span>
<span class="c">#Use CMake&#39;s FetchContent to download and integrate alpaka3 directly from GitHub</span>
<span class="nb">include</span><span class="p">(</span><span class="s">FetchContent</span><span class="p">)</span>
<span class="c">#Declare where to fetch alpaka3 from</span>
<span class="c">#This will download the library at configure time</span>
<span class="nb">FetchContent_Declare</span><span class="p">(</span><span class="s">alpaka3</span><span class="w"> </span><span class="s">GIT_REPOSITORY</span><span class="w"> </span><span class="s">https://github.com/alpaka-group/alpaka3.git</span><span class="w"> </span><span class="s">GIT_TAG</span><span class="w"> </span><span class="s">dev</span><span class="p">)</span>
<span class="c">#Make alpaka3 available for use in this project</span>
<span class="c">#This downloads, configures, and makes the library targets available</span>
<span class="nb">FetchContent_MakeAvailable</span><span class="p">(</span><span class="s">alpaka3</span><span class="p">)</span>
<span class="c">#Finalize the alpaka FetchContent setup</span>
<span class="hll"><span class="nb">alpaka_FetchContent_Finalize</span><span class="p">()</span>
</span><span class="c">#Create the executable target from the source file</span>
<span class="nb">add_executable</span><span class="p">(</span><span class="s">vectorAdd</span><span class="w"> </span><span class="s">main.cpp</span><span class="p">)</span>
<span class="c">#Link the alpaka library to the executable</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">vectorAdd</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s">alpaka::alpaka</span><span class="p">)</span>
<span class="c">#Finalize the alpaka configuration for this target</span>
<span class="c">#This sets up backend - specific compiler flags and dependencies</span>
<span class="hll"><span class="nb">alpaka_finalize</span><span class="p">(</span><span class="s">vectorAdd</span><span class="p">)</span>
</span></pre></div>
</div>
</div>
<p>Below we have the main alpaka code doing a vector addition on device using a high level transform function</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">main.cpp</span><a class="headerlink" href="#id5" title="Link to this code"></a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>

<span class="w">  </span><span class="c1">// auto devSelector = ap::onHost::makeDeviceSelector(ap::api::host,</span>
<span class="w">  </span><span class="c1">// ap::deviceKind::cpu);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run element-wise vector addition on device</span>
<span class="hll"><span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="p">{},</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>
</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<p>To set up our project, we create a folder and place our CMakeLists.txt and main.cpp in there.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mkdir<span class="w"> </span>alpakaExercise<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>alpakaExercise
<span class="gp">$ </span>vim<span class="w"> </span>CMakeLists.txt
<span class="go">and now paste the CMakeLsits here (Press i, followed by Ctrl+Shift+V)</span>
<span class="go">Press esc and then :wq to exit vim</span>
<span class="gp">$ </span>vim<span class="w"> </span>main.cpp
<span class="go">Similarly, paste the C++ code here</span>
</pre></div>
</div>
<p>To compile and run the code, use the following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">configure step, we additionaly specify that HIP is available</span>
<span class="gp">$ </span>cmake<span class="w"> </span>-B<span class="w"> </span>build<span class="w"> </span>-S<span class="w"> </span>.<span class="w"> </span>-Dalpaka_DEP_HIP<span class="o">=</span>ON
<span class="go">build</span>
<span class="gp">$ </span>cmake<span class="w"> </span>--build<span class="w"> </span>build<span class="w"> </span>--parallel
<span class="go">run</span>
<span class="gp">$ </span>./build/vectorAdd
<span class="go">Using alpaka device: AMD Instinct MI250X id=0</span>
<span class="go">c[0] = 1</span>
<span class="go">c[1] = 2</span>
<span class="go">c[2] = 3</span>
<span class="go">c[3] = 4</span>
<span class="go">c[4] = 5</span>
</pre></div>
</div>
<p>Now your task will be to write and launch your first alpaka kernel.
This kernel will do the vector addition and we will use this instead of the transform helper.</p>
<div class="admonition-writing-the-vector-add-kernel solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Writing the vector add kernel</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="hll"><span class="k">struct</span><span class="w"> </span><span class="nc">AddKernel</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="n">acc</span><span class="p">,</span>
</span><span class="hll"><span class="w">                            </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="p">,</span>
</span><span class="hll"><span class="w">                            </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">a</span><span class="p">,</span>
</span><span class="hll"><span class="w">                            </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">makeIdxMap</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">worker</span><span class="o">::</span><span class="n">threadsInGrid</span><span class="p">,</span>
</span><span class="hll"><span class="w">                                          </span><span class="n">ap</span><span class="o">::</span><span class="n">IdxRange</span><span class="p">{</span><span class="n">c</span><span class="p">.</span><span class="n">getExtents</span><span class="p">()}))</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">      </span><span class="n">c</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
</span><span class="hll"><span class="w">    </span><span class="p">}</span>
</span><span class="hll"><span class="w">  </span><span class="p">}</span>
</span><span class="hll"><span class="p">};</span>
</span>
<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>

<span class="w">  </span><span class="c1">// auto devSelector = ap::onHost::makeDeviceSelector(ap::api::host,</span>
<span class="w">  </span><span class="c1">// ap::deviceKind::cpu);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="hll"><span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">getFrameSpec</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">getExtents</span><span class="p">());</span>
</span>
<span class="hll"><span class="w">  </span><span class="c1">// Call the element-wise addition kernel on device</span>
</span><span class="hll"><span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">frameSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">AddKernel</span><span class="p">{},</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">});</span>
</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h2>
<section id="parallel-for-with-unified-memory">
<h3>Parallel for with Unified Memory<a class="headerlink" href="#parallel-for-with-unified-memory" title="Link to this heading"></a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-6-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-6-6-0" name="6-0" role="tab" tabindex="0">StdPar</button><button aria-controls="panel-6-6-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-1" name="6-1" role="tab" tabindex="-1">Kokkos</button><button aria-controls="panel-6-6-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-2" name="6-2" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-6-6-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-3" name="6-3" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-6-6-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-4" name="6-4" role="tab" tabindex="-1">alpaka-algorithms</button><button aria-controls="panel-6-6-5" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-5" name="6-5" role="tab" tabindex="-1">alpaka</button></div><div aria-labelledby="tab-6-6-0" class="sphinx-tabs-panel" id="panel-6-6-0" name="6-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdio&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate arrays</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">b</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">c</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par_unseq</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
<span class="w">                 </span><span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="p">[](</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">j</span><span class="p">;</span><span class="w"> </span><span class="p">});</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-1" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-1" name="6-1" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate on Kokkos default memory space (Unified Memory)</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

<span class="w">    </span><span class="c1">// Initialize values on host</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">      </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">KOKKOS_LAMBDA</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"> </span><span class="p">});</span>

<span class="w">    </span><span class="c1">// Kokkos synchronization</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">fence</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">    </span><span class="c1">// Free Kokkos allocation (Unified Memory)</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_free</span><span class="p">(</span><span class="n">b</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_free</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Finalize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-2" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-2" name="6-2" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using OpenCL C API here, since SVM support in C++ API is unstable on</span>
<span class="c1">// ROCm</span>
<span class="cp">#define CL_TARGET_OPENCL_VERSION 220</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="c1">// For larger kernels, we can store source in a separate file</span>
<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="s">&quot;                                                 \</span>
<span class="s">           __kernel void dot(__global const int *a, __global const int *b, __global int *c) { \</span>
<span class="s">             int i = get_global_id(0);                                                        \</span>
<span class="s">             c[i] = a[i] * b[i];                                                              \</span>
<span class="s">           }                                                                                  \</span>
<span class="s">         &quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize OpenCL</span>
<span class="w">  </span><span class="n">cl_platform_id</span><span class="w"> </span><span class="n">platform</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetPlatformIDs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_device_id</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetDeviceIDs</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_TYPE_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_context</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateContext</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_command_queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateCommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Compile OpenCL program for found device.</span>
<span class="w">  </span><span class="n">cl_program</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">clCreateProgramWithSource</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernel_source</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clBuildProgram</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_kernel</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateKernel</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;dot&quot;</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Set problem dimensions</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Create SVM buffer objects on host side</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clSVMAlloc</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clSVMAlloc</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clSVMAlloc</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_WRITE_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Pass arguments to device kernel</span>
<span class="w">  </span><span class="n">clSetKernelArgSVMPointer</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSetKernelArgSVMPointer</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSetKernelArgSVMPointer</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Create mappings for host and initialize values</span>
<span class="w">  </span><span class="n">clEnqueueSVMMap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MAP_WRITE</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                  </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clEnqueueSVMMap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MAP_WRITE</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                  </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">clEnqueueSVMUnmap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clEnqueueSVMUnmap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">globalSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">;</span>
<span class="w">  </span><span class="n">clEnqueueNDRangeKernel</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">globalSize</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                         </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Create mapping for host and print results</span>
<span class="w">  </span><span class="n">clEnqueueSVMMap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MAP_READ</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                  </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">clEnqueueSVMUnmap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Free SVM buffers</span>
<span class="w">  </span><span class="n">clSVMFree</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSVMFree</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSVMFree</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-3" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-3" name="6-3" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate shared memory (Unified Shared Memory)</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">   </span><span class="p">}).</span><span class="n">wait</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Free shared memory allocation (Unified Memory)</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-4" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-4" name="6-4" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">multiplies</span><span class="p">{},</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-5" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-5" name="6-5" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">MulKernel</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="o">&amp;</span><span class="w"> </span><span class="n">acc</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">a</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">makeIdxMap</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">worker</span><span class="o">::</span><span class="n">threadsInGrid</span><span class="p">,</span>
<span class="w">             </span><span class="n">ap</span><span class="o">::</span><span class="n">IdxRange</span><span class="p">{</span><span class="n">c</span><span class="p">.</span><span class="n">getExtents</span><span class="p">()}))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">c</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">frameExtent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32u</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">FrameSpec</span><span class="p">{</span><span class="n">ap</span><span class="o">::</span><span class="n">divExZero</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">),</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">};</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">frameSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">MulKernel</span><span class="p">{},</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">});</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</section>
<section id="parallel-for-with-gpu-buffers">
<h3>Parallel for with GPU buffers<a class="headerlink" href="#parallel-for-with-gpu-buffers" title="Link to this heading"></a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-7-7-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-7-7-0" name="7-0" role="tab" tabindex="0">Kokkos</button><button aria-controls="panel-7-7-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-1" name="7-1" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-7-7-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-2" name="7-2" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-7-7-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-3" name="7-3" role="tab" tabindex="-1">alpaka-algorithms</button><button aria-controls="panel-7-7-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-4" name="7-4" role="tab" tabindex="-1">alpaka</button></div><div aria-labelledby="tab-7-7-0" class="sphinx-tabs-panel" id="panel-7-7-0" name="7-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate space for 5 ints on Kokkos host memory space</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">HostSpace</span><span class="o">&gt;</span><span class="w"> </span><span class="n">h_a</span><span class="p">(</span><span class="s">&quot;h_a&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">HostSpace</span><span class="o">&gt;</span><span class="w"> </span><span class="n">h_b</span><span class="p">(</span><span class="s">&quot;h_b&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">HostSpace</span><span class="o">&gt;</span><span class="w"> </span><span class="n">h_c</span><span class="p">(</span><span class="s">&quot;h_c&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Allocate space for 5 ints on Kokkos default memory space (eg, GPU memory)</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="s">&quot;a&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">(</span><span class="s">&quot;b&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">c</span><span class="p">(</span><span class="s">&quot;c&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Initialize values on host</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">      </span><span class="n">h_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Copy from host to device</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">deep_copy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">deep_copy</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">h_b</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">KOKKOS_LAMBDA</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"> </span><span class="p">});</span>

<span class="w">    </span><span class="c1">// Copy from device to host</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">deep_copy</span><span class="p">(</span><span class="n">h_c</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Finalize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-1" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-1" name="7-1" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using OpenCL C++ API here; there is also C API in &lt;CL/cl.h&gt;</span>
<span class="cp">#define CL_TARGET_OPENCL_VERSION 110</span>
<span class="cp">#define CL_HPP_TARGET_OPENCL_VERSION 110</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.hpp&gt;</span>

<span class="c1">// For larger kernels, we can store source in a separate file</span>
<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sa">R</span><span class="s">&quot;</span><span class="dl">(</span>
<span class="s">            __kernel void dot(__global const int *a, __global const int *b, __global int *c) {</span>
<span class="s">              int i = get_global_id(0);</span>
<span class="s">              c[i] = a[i] * b[i];</span>
<span class="s">            }</span>
<span class="s">          </span><span class="dl">)</span><span class="s">&quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize OpenCL</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="o">::</span><span class="n">getDefault</span><span class="p">();</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="n">context</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">CommandQueue</span><span class="w"> </span><span class="n">queue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Compile OpenCL program for found device.</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Program</span><span class="w"> </span><span class="n">program</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_source</span><span class="p">);</span>
<span class="w">  </span><span class="n">program</span><span class="p">.</span><span class="n">build</span><span class="p">({</span><span class="n">device</span><span class="p">});</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="n">kernel_dot</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;dot&quot;</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Set problem dimensions</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">b</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">c</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Initialize values on host</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">      </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Create buffers and copy input data to device.</span>
<span class="w">    </span><span class="n">cl</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="n">dev_a</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">CL_MEM_COPY_HOST_PTR</span><span class="p">,</span>
<span class="w">                     </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
<span class="w">    </span><span class="n">cl</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="n">dev_b</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">CL_MEM_COPY_HOST_PTR</span><span class="p">,</span>
<span class="w">                     </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
<span class="w">    </span><span class="n">cl</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="n">dev_c</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_WRITE_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

<span class="w">    </span><span class="c1">// Pass arguments to device kernel</span>
<span class="w">    </span><span class="n">kernel_dot</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">dev_a</span><span class="p">);</span>
<span class="w">    </span><span class="n">kernel_dot</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">dev_b</span><span class="p">);</span>
<span class="w">    </span><span class="n">kernel_dot</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">dev_c</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// We don&#39;t need to apply any offset to thread IDs</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueueNDRangeKernel</span><span class="p">(</span><span class="n">kernel_dot</span><span class="p">,</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">,</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NDRange</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
<span class="w">                               </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Read result</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueueReadBuffer</span><span class="p">(</span><span class="n">dev_c</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-2" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-2" name="7-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate space for 5 ints</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a_buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">));</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b_buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">));</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c_buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// Initialize values</span>
<span class="w">  </span><span class="c1">// We should use curly braces to limit host accessors&#39; lifetime</span>
<span class="w">  </span><span class="c1">//    and indicate when we&#39;re done working with them:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">a_host_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a_buf</span><span class="p">.</span><span class="n">get_host_access</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">b_host_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b_buf</span><span class="p">.</span><span class="n">get_host_access</span><span class="p">();</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">a_host_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">      </span><span class="n">b_host_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Submit a SYCL kernel into a queue</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Create read accessors over a_buf and b_buf</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">a_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">read</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">b_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">read</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// Create write accesor over c_buf</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">c_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">write</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">    </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">vec_add</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">c_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b_acc</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">  </span><span class="p">});</span>

<span class="w">  </span><span class="c1">// No need to synchronize, creating the accessor for c_buf will do it</span>
<span class="w">  </span><span class="c1">// automatically</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">c_host_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c_buf</span><span class="p">.</span><span class="n">get_host_access</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c_host_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-3" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-3" name="7-3" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate memory that is accessible on host</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHost</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHostLike</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHostLike</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate memory on the device and inherit the extents from h_a</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">h_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Copy host memory element wise to the device memory</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">h_b</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">multiplies</span><span class="p">{},</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Copy the device result back to host memory</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-4" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-4" name="7-4" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">MulKernel</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="o">&amp;</span><span class="w"> </span><span class="n">acc</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">a</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">makeIdxMap</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">worker</span><span class="o">::</span><span class="n">threadsInGrid</span><span class="p">,</span>
<span class="w">             </span><span class="n">ap</span><span class="o">::</span><span class="n">IdxRange</span><span class="p">{</span><span class="n">c</span><span class="p">.</span><span class="n">getExtents</span><span class="p">()}))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">c</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate memory that is accessible on host</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHost</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHostLike</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHostLike</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// allocate memory on the device and inherit the extents from a</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">h_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Copy host memory element wise to the device memory</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">h_b</span><span class="p">);</span>

<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">frameExtent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32u</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">FrameSpec</span><span class="p">{</span><span class="n">ap</span><span class="o">::</span><span class="n">divExZero</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">),</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">};</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">frameSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">MulKernel</span><span class="p">{},</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">});</span>

<span class="w">  </span><span class="c1">// Copy the device result back to host memory</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</section>
<section id="asynchronous-parallel-for-kernels">
<h3>Asynchronous parallel for kernels<a class="headerlink" href="#asynchronous-parallel-for-kernels" title="Link to this heading"></a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-8-8-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-8-8-0" name="8-0" role="tab" tabindex="0">Kokkos</button><button aria-controls="panel-8-8-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-1" name="8-1" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-8-8-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-2" name="8-2" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-8-8-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-3" name="8-3" role="tab" tabindex="-1">alpaka-algorithms</button><button aria-controls="panel-8-8-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-4" name="8-4" role="tab" tabindex="-1">alpaka</button></div><div aria-labelledby="tab-8-8-0" class="sphinx-tabs-panel" id="panel-8-8-0" name="8-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate on Kokkos default memory space (Unified Memory)</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_malloc</span><span class="p">(</span><span class="n">nx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

<span class="w">    </span><span class="c1">// Create &#39;n&#39; execution space instances (maps to streams in CUDA/HIP)</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">ex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">Experimental</span><span class="o">::</span><span class="n">partition_space</span><span class="p">(</span>
<span class="w">        </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">DefaultExecutionSpace</span><span class="p">(),</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Launch &#39;n&#39; potentially asynchronous kernels</span>
<span class="w">    </span><span class="c1">// Each kernel has their own execution space instances</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">parallel_for</span><span class="p">(</span>
<span class="w">          </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">RangePolicy</span><span class="o">&lt;</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">DefaultExecutionSpace</span><span class="o">&gt;</span><span class="p">(</span>
<span class="w">              </span><span class="n">ex</span><span class="p">[</span><span class="n">region</span><span class="p">],</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">region</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)),</span>
<span class="w">          </span><span class="n">KOKKOS_LAMBDA</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span><span class="w"> </span><span class="p">});</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Sync execution space instances (maps to streams in CUDA/HIP)</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">ex</span><span class="p">[</span><span class="n">region</span><span class="p">].</span><span class="n">fence</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">    </span><span class="c1">// Free Kokkos allocation (Unified Memory)</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Finalize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-1" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-1" name="8-1" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using OpenCL C API here, since SVM support in C++ API is unstable on</span>
<span class="c1">// ROCm</span>
<span class="cp">#define CL_TARGET_OPENCL_VERSION 200</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="c1">// For larger kernels, we can store source in a separate file</span>
<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;              \</span>
<span class="s">                    __kernel void async(__global int *a) { \</span>
<span class="s">                      int i = get_global_id(0);            \</span>
<span class="s">                      int region = i / get_global_size(0); \</span>
<span class="s">                      a[i] = region + i;                   \</span>
<span class="s">                    }                                      \</span>
<span class="s">         &quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Initialize OpenCL</span>
<span class="w">  </span><span class="n">cl_platform_id</span><span class="w"> </span><span class="n">platform</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetPlatformIDs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_device_id</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetDeviceIDs</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_TYPE_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_context</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateContext</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_command_queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateCommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Compile OpenCL program for found device.</span>
<span class="w">  </span><span class="n">cl_program</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">clCreateProgramWithSource</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernel_source</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clBuildProgram</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_kernel</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateKernel</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;async&quot;</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Set problem dimensions</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Create SVM buffer objects on host side</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clSVMAlloc</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_WRITE_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Pass arguments to device kernel</span>
<span class="w">  </span><span class="n">clSetKernelArgSVMPointer</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Launch multiple potentially asynchronous kernels on different parts of the</span>
<span class="w">  </span><span class="c1">// array</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">;</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="p">;</span>
<span class="w">    </span><span class="n">clEnqueueNDRangeKernel</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                           </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Create mapping for host and print results</span>
<span class="w">  </span><span class="n">clEnqueueSVMMap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MAP_READ</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                  </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">clEnqueueSVMUnmap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Free SVM buffers</span>
<span class="w">  </span><span class="n">clSVMFree</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-2" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-2" name="8-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate shared memory (Unified Shared Memory)</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Launch multiple potentially asynchronous kernels on different parts of the</span>
<span class="w">  </span><span class="c1">// array</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">q</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">iShifted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">;</span>
<span class="w">      </span><span class="n">a</span><span class="p">[</span><span class="n">iShifted</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">iShifted</span><span class="p">;</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Synchronize</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Free shared memory allocation (Unified Memory)</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-3" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-3" name="8-3" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Non-blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">QueueType</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="o">&lt;</span><span class="n">ALPAKA_TYPEOF</span><span class="p">(</span><span class="n">devAcc</span><span class="p">),</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">NonBlocking</span><span class="o">&gt;</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">QueueType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">queues</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">queues</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">nonBlocking</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nPerRegion</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="p">;</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">regionOffset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nPerRegion</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">;</span>
<span class="w">    </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">iota</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">queues</span><span class="p">[</span><span class="n">region</span><span class="p">],</span><span class="w"> </span><span class="n">regionOffset</span><span class="p">,</span>
<span class="w">        </span><span class="n">a</span><span class="p">.</span><span class="n">getSubView</span><span class="p">(</span><span class="n">regionOffset</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">regionOffset</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Wait for the device, includes all queues</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">wait</span><span class="p">(</span><span class="n">devAcc</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-4" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-4" name="8-4" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">IdxAssignKernel</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="o">&amp;</span><span class="w"> </span><span class="n">acc</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="p">,</span>
<span class="w">      </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="p">,</span>
<span class="w">      </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nPerRegion</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">getExtents</span><span class="p">().</span><span class="n">x</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="p">;</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">regionOffset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nPerRegion</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">:</span>
<span class="w">        </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">makeIdxMap</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">worker</span><span class="o">::</span><span class="n">threadsInGrid</span><span class="p">,</span>
<span class="w">            </span><span class="n">ap</span><span class="o">::</span><span class="n">IdxRange</span><span class="p">{</span><span class="n">regionOffset</span><span class="p">,</span><span class="w"> </span><span class="n">regionOffset</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">nPerRegion</span><span class="p">}))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">a</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Non-blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">QueueType</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="o">&lt;</span><span class="n">ALPAKA_TYPEOF</span><span class="p">(</span><span class="n">devAcc</span><span class="p">),</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">NonBlocking</span><span class="o">&gt;</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">QueueType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">queues</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">queues</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">nonBlocking</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="p">);</span>

<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">frameExtent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32u</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">FrameSpec</span><span class="p">{</span><span class="n">ap</span><span class="o">::</span><span class="n">divExZero</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">),</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">};</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">queues</span><span class="p">[</span><span class="n">region</span><span class="p">].</span><span class="n">enqueue</span><span class="p">(</span>
<span class="w">        </span><span class="n">frameSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">IdxAssignKernel</span><span class="p">{},</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">region</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Wait for the device, includes all queues</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">wait</span><span class="p">(</span><span class="n">devAcc</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</section>
<section id="reduction">
<h3>Reduction<a class="headerlink" href="#reduction" title="Link to this heading"></a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-9-9-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-9-9-0" name="9-0" role="tab" tabindex="0">StdPar</button><button aria-controls="panel-9-9-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-1" name="9-1" role="tab" tabindex="-1">Kokkos</button><button aria-controls="panel-9-9-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-2" name="9-2" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-9-9-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-3" name="9-3" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-9-9-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-4" name="9-4" role="tab" tabindex="-1">alpaka-algorithms</button></div><div aria-labelledby="tab-9-9-0" class="sphinx-tabs-panel" id="panel-9-9-0" name="9-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdio&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;numeric&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">iota</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="c1">// Fill the array</span>

<span class="w">  </span><span class="c1">// Run reduction on the device</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par_unseq</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">cbegin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">cend</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">                        </span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">{});</span>

<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-1" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-1" name="9-1" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Initialize sum variable</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Run sum reduction kernel</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">parallel_reduce</span><span class="p">(</span>
<span class="w">        </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">KOKKOS_LAMBDA</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lsum</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">lsum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span><span class="w"> </span><span class="p">},</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Kokkos synchronization</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">fence</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Finalize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-2" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-2" name="9-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using OpenCL C++ API here; there is also C API in &lt;CL/cl.h&gt;</span>
<span class="cp">#define CL_TARGET_OPENCL_VERSION 110</span>
<span class="cp">#define CL_HPP_TARGET_OPENCL_VERSION 110</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.hpp&gt;</span>

<span class="c1">// For larger kernels, we can store source in a separate file</span>
<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sa">R</span><span class="s">&quot;</span><span class="dl">(</span>
<span class="s">           __kernel void reduce(__global int* sum, __local int* local_mem) {</span>
<span class="s">             </span>
<span class="s">             // Get work group and work item information</span>
<span class="s">             int gsize = get_global_size(0); // global work size</span>
<span class="s">             int gid = get_global_id(0); // global work item index</span>
<span class="s">             int lsize = get_local_size(0); // local work size</span>
<span class="s">             int lid = get_local_id(0); // local work item index</span>
<span class="s">             </span>
<span class="s">             // Store reduced item into local memory</span>
<span class="s">             local_mem[lid] = gid; // initialize local memory</span>
<span class="s">             barrier(CLK_LOCAL_MEM_FENCE); // synchronize local memory</span>
<span class="s">             </span>
<span class="s">             // Perform reduction across the local work group</span>
<span class="s">             for (int s = 1; s &lt; lsize; s *= 2) { // loop over local memory with stride doubling each iteration</span>
<span class="s">               if (lid % (2 * s) == 0 &amp;&amp; (lid + s) &lt; lsize) {</span>
<span class="s">                 local_mem[lid] += local_mem[lid + s];</span>
<span class="s">               }</span>
<span class="s">               barrier(CLK_LOCAL_MEM_FENCE); // synchronize local memory</span>
<span class="s">             }</span>
<span class="s">             </span>
<span class="s">             if (lid == 0) { // only one work item per work group</span>
<span class="s">               atomic_add(sum, local_mem[0]); // add partial sum to global sum atomically</span>
<span class="s">             }</span>
<span class="s">           }</span>
<span class="s">         </span><span class="dl">)</span><span class="s">&quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize OpenCL</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="o">::</span><span class="n">getDefault</span><span class="p">();</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="n">context</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">CommandQueue</span><span class="w"> </span><span class="n">queue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Compile OpenCL program for found device</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Program</span><span class="w"> </span><span class="n">program</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_source</span><span class="p">);</span>
<span class="w">  </span><span class="n">program</span><span class="p">.</span><span class="n">build</span><span class="p">({</span><span class="n">device</span><span class="p">});</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="n">kernel_reduce</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;reduce&quot;</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Set problem dimensions</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Initialize sum variable</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Create buffer for sum</span>
<span class="w">    </span><span class="n">cl</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="n">buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_WRITE</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">CL_MEM_COPY_HOST_PTR</span><span class="p">,</span>
<span class="w">                      </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">sum</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Pass arguments to device kernel</span>
<span class="w">    </span><span class="n">kernel_reduce</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">buffer</span><span class="p">);</span><span class="w">            </span><span class="c1">// pass buffer to device</span>
<span class="w">    </span><span class="n">kernel_reduce</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span><span class="w"> </span><span class="c1">// allocate local memory</span>

<span class="w">    </span><span class="c1">// Enqueue kernel</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueueNDRangeKernel</span><span class="p">(</span><span class="n">kernel_reduce</span><span class="p">,</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">,</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NDRange</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
<span class="w">                               </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Read result</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueueReadBuffer</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">sum</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Print result</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-3" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-3" name="9-3" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// We use built-in sycl::reduction mechanism in this example.</span>
<span class="c1">// The manual implementation of the reduction kernel can be found in</span>
<span class="c1">// the &quot;Non-portable kernel models&quot; chapter.</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Initialize sum</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Create a buffer for sum to get the reduction results</span>
<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sum_buf</span><span class="p">{</span><span class="o">&amp;</span><span class="n">sum</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">};</span>

<span class="w">    </span><span class="c1">// Submit a SYCL kernel into a queue</span>
<span class="w">    </span><span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="c1">// Create temporary object describing variables with reduction semantics</span>
<span class="w">       </span><span class="k">auto</span><span class="w"> </span><span class="n">sum_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">read_write</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">       </span><span class="c1">// We can use built-in reduction primitive</span>
<span class="w">       </span><span class="k">auto</span><span class="w"> </span><span class="n">sum_reduction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">reduction</span><span class="p">(</span><span class="n">sum_acc</span><span class="p">,</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">());</span>

<span class="w">       </span><span class="c1">// A reference to the reducer is passed to the lambda</span>
<span class="w">       </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span>
<span class="w">           </span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="n">sum_reduction</span><span class="p">,</span>
<span class="w">           </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">idx</span><span class="p">,</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">reducer</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">reducer</span><span class="p">.</span><span class="n">combine</span><span class="p">(</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span><span class="w"> </span><span class="p">});</span>
<span class="w">     </span><span class="p">}).</span><span class="n">wait</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// The contents of sum_buf are copied back to sum by the destructor of</span>
<span class="w">    </span><span class="c1">// sum_buf</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-4" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-4" name="9-4" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="p">{},</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">LinearizedIdxGenerator</span><span class="p">{</span><span class="n">n</span><span class="p">});</span>

<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="pros-and-cons-of-cross-platform-portability-ecosystems">
<h2>Pros and cons of cross-platform portability ecosystems<a class="headerlink" href="#pros-and-cons-of-cross-platform-portability-ecosystems" title="Link to this heading"></a></h2>
<section id="general-observations">
<h3>General observations<a class="headerlink" href="#general-observations" title="Link to this heading"></a></h3>
<blockquote>
<div><ul class="simple">
<li><p>The amount of code duplication is minimized.</p></li>
<li><p>The same code can be compiled to multiple architectures from different vendors.</p></li>
<li><p>Limited learning resources compared to CUDA (Stack Overflow, course material, documentation).</p></li>
</ul>
</div></blockquote>
</section>
<section id="lambda-based-kernel-models-kokkos-sycl">
<h3>Lambda-based kernel models (Kokkos, SYCL)<a class="headerlink" href="#lambda-based-kernel-models-kokkos-sycl" title="Link to this heading"></a></h3>
<blockquote>
<div><ul class="simple">
<li><p>Higher level of abstraction.</p></li>
<li><p>Less knowledge of the underlying architecture is needed for initial porting.</p></li>
<li><p>Very nice and readable source code (C++ API).</p></li>
<li><p>The models are relatively new and not very popular yet.</p></li>
</ul>
</div></blockquote>
</section>
<section id="functor-based-kernel-model-alpaka">
<h3>Functor-based kernel model (alpaka)<a class="headerlink" href="#functor-based-kernel-model-alpaka" title="Link to this heading"></a></h3>
<blockquote>
<div><ul class="simple">
<li><p>Very good portability.</p></li>
<li><p>Higher level of abstraction.</p></li>
<li><p>Low-level API always awailable which gives more control and allows fine tuning.</p></li>
<li><p>User friendly C++ API for both the host and kernel code.</p></li>
<li><p>Small community and ecosystem.</p></li>
</ul>
</div></blockquote>
</section>
<section id="separate-source-kernel-models-opencl">
<h3>Separate-source kernel models (OpenCL)<a class="headerlink" href="#separate-source-kernel-models-opencl" title="Link to this heading"></a></h3>
<blockquote>
<div><ul class="simple">
<li><p>Very good portability.</p></li>
<li><p>Mature ecosystem.</p></li>
<li><p>Limited number of vendor-provided libraries.</p></li>
<li><p>Low-level API gives more control and allows fine tuning.</p></li>
<li><p>Both C and C++ APIs available (C++ API is less well supported).</p></li>
<li><p>The low-level API and separate-source kernel model are less user friendly.</p></li>
</ul>
</div></blockquote>
</section>
<section id="c-standard-parallelism-stdpar-pstl">
<h3>C++ Standard Parallelism (StdPar, PSTL)<a class="headerlink" href="#c-standard-parallelism-stdpar-pstl" title="Link to this heading"></a></h3>
<blockquote>
<div><ul class="simple">
<li><p>Very high level of abstraction.</p></li>
<li><p>Easy to speed up code which already relying on STL algorithms.</p></li>
<li><p>Very little control over hardware.</p></li>
<li><p>Support by compilers is improving, but is far from mature.</p></li>
</ul>
</div></blockquote>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>General code organization is similar to non-portable kernel-based models.</p></li>
<li><p>As long as no vendor-specific functionality is used, the same code can run on any GPU.</p></li>
</ul>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../7-non-portable-kernel-models/" class="btn btn-neutral float-left" title="Non-portable kernel-based models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../9-language-support/" class="btn btn-neutral float-right" title="High-level language support" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, The contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>