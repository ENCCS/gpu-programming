

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GPU programming: why, when and how? documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
      <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
      <link rel="stylesheet" type="text/css" href="_static/sphinx_lesson.css" />
      <link rel="stylesheet" type="text/css" href="_static/term_role_formatting.css" />
      <link rel="stylesheet" type="text/css" href="_static/sphinx_rtd_theme_ext_color_contrast.css" />
      <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
      <link rel="stylesheet" type="text/css" href="_static/overrides.css" />

  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js"></script>
      <script src="_static/doctools.js"></script>
      <script src="_static/sphinx_highlight.js"></script>
      <script src="_static/clipboard.min.js"></script>
      <script src="_static/copybutton.js"></script>
      <script src="_static/minipres.js"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="_static/togglebutton.js"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="_static/tabs.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            GPU programming: why, when and how?
              <img src="_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Prerequisites</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-0-setup">Setup</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-1-gpu-history">Why GPUs?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-2-gpu-ecosystem">The GPU hardware and software ecosystem</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-3-gpu-problems">What problems fit to GPU?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-4-gpu-concepts">GPU programming concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-5-intro-to-gpu-prog-models">Introduction to GPU programming models</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-6-directive-based-models">Directive-based models</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-7-non-portable-kernel-models">Non-portable kernel-based models</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-8-portable-kernel-models">Portable kernel-based models</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-9-language-support">High-level language support</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-10-multiple_gpu">Multiple GPU programming with MPI</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-11-gpu-porting">Preparing code for GPU porting</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-12-recommendations">Recommendations</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-13-examples">GPU programming example: stencil computation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-quick-reference">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-glossary">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-guide">Instructor’s guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://enccs.se/lessons/">All lessons</a></li>
<li class="toctree-l1"><a class="reference external" href="https://enccs.se/">ENCCS</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">GPU programming: why, when and how?</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">GPU programming: why, when and how?  documentation</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/gpu-programming/blob/main/content/index" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="gpu-programming-when-why-and-how">
<h1>GPU Programming: When, Why and How?<a class="headerlink" href="#gpu-programming-when-why-and-how" title="Link to this heading"></a></h1>
<p>Graphical processing units (GPUs) are the workhorse of many high performance
computing (HPC) systems around the world. The number of GPU-enabled supercomputers
on the <a class="reference external" href="https://www.top500.org/">Top500</a> has been steadily increasing in recent years
and this development is expected to continue. In the near future, the majority of HPC
computing power available to researchers and engineers is likely to be provided by GPUs
or other types of accelerators. Programming GPUs and other accelerators is thus crucial
to developers of software run on HPC systems.</p>
<p>However, the landscape of GPU hardware, software and programming environments is complicated.
Multiple vendors compete in the high-end GPU market, with each vendor providing its own software
stack and development toolkits, and even beyond that, there is a proliferation of tools,
languages and frameworks that can be used to write code for GPUs.
It can thus be difficult for individual developers and project owners to know how to
navigate across this landscape and select the most appropriate GPU programming framework for their
projects based on the requirements of a given project and technical requirements of any
existing code.</p>
<p>This material is meant to help both software developers and decision makers navigate the
GPU programming landscape and make more informed decisions on which languages or frameworks
to learn and use for their projects. Specifically, you will:</p>
<ul class="simple">
<li><p>Understand why and when to use GPUs.</p></li>
<li><p>Become comfortable with key concepts in GPU programming.</p></li>
<li><p>Acquire a comprehensive overview of different software frameworks, what levels they operate at, and which to use when.</p></li>
<li><p>Learn the fundamentals in at least one framework to a level which will enable you to quickly become a productive GPU programmer.</p></li>
</ul>
<div class="admonition-prerequisites prerequisites admonition" id="prerequisites-0">
<p class="admonition-title">Prerequisites</p>
<p>Familiarity with one or more programming languages like C/C++, Fortran, Python or
Julia is recommended.</p>
</div>
<div class="toctree-wrapper compound">
<span id="document-0-setup"></span><section id="setup">
<span id="id1"></span><h2>Setup<a class="headerlink" href="#setup" title="Link to this heading"></a></h2>
<section id="local-installation">
<h3>Local installation<a class="headerlink" href="#local-installation" title="Link to this heading"></a></h3>
<p>Since this lesson is taught using an HPC cluster, no software installation on your own computer is needed.</p>
</section>
<section id="running-on-lumi">
<h3>Running on LUMI<a class="headerlink" href="#running-on-lumi" title="Link to this heading"></a></h3>
<p>Interactive job, 1 node, 1 GPU, 1 hour:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>salloc<span class="w"> </span>-A<span class="w"> </span>project_465002387<span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>-t<span class="w"> </span><span class="m">1</span>:00:00<span class="w"> </span>-p<span class="w"> </span>standard-g<span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">1</span>
<span class="gp">$ </span>srun<span class="w"> </span>&lt;some-command&gt;
</pre></div>
</div>
<p>Exit interactive allocation with <code class="docutils literal notranslate"><span class="pre">exit</span></code>.</p>
<p>Interacive terminal session on compute node:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>--account<span class="o">=</span>project_465002387<span class="w"> </span>--partition<span class="o">=</span>standard-g<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--time<span class="o">=</span><span class="m">1</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>bash
<span class="gp">$ </span>&lt;some-command&gt;
</pre></div>
</div>
<p>Corresponding batch script <code class="docutils literal notranslate"><span class="pre">submit.sh</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash -l</span>
<span class="c1">#SBATCH --account=project_465002387</span>
<span class="c1">#SBATCH --job-name=example-job</span>
<span class="c1">#SBATCH --output=examplejob.o%j</span>
<span class="c1">#SBATCH --error=examplejob.e%j</span>
<span class="c1">#SBATCH --partition=standard-g</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --gpus-per-node=1</span>
<span class="c1">#SBATCH --ntasks-per-node=1</span>
<span class="c1">#SBATCH --time=1:00:00</span>

srun<span class="w"> </span>&lt;some_command&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>Submit the job: <code class="docutils literal notranslate"><span class="pre">sbatch</span> <span class="pre">submit.sh</span></code></p></li>
<li><p>Monitor your job: <code class="docutils literal notranslate"><span class="pre">squeue</span> <span class="pre">--me</span></code></p></li>
<li><p>Kill job: <code class="docutils literal notranslate"><span class="pre">scancel</span> <span class="pre">&lt;JOB_ID&gt;</span></code></p></li>
</ul>
<section id="running-julia-on-lumi">
<h4>Running Julia on LUMI<a class="headerlink" href="#running-julia-on-lumi" title="Link to this heading"></a></h4>
<p>In order to run Julia with <code class="docutils literal notranslate"><span class="pre">AMDGPU.jl</span></code> on LUMI, we use the following directory structure and assume it is our working directory.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">.</span>
<span class="go">├── Project.toml  # Julia environment</span>
<span class="go">├── script.jl     # Julia script</span>
<span class="go">└── submit.sh     # Slurm batch script</span>
</pre></div>
</div>
<p>An example of a <code class="docutils literal notranslate"><span class="pre">Project.toml</span></code> project file.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[deps]</span>
<span class="go">AMDGPU = &quot;21141c5a-9bdb-4563-92ae-f87d6854732e&quot;</span>
</pre></div>
</div>
<p>For the <code class="docutils literal notranslate"><span class="pre">submit.sh</span></code> batch script, include additional content to the batch script mentioned above.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#SBATCH --cpus-per-task=2</span>
<span class="c1">#SBATCH --mem-per-cpu=1750</span>

module<span class="w"> </span>use<span class="w"> </span>/appl/local/csc/modulefiles

module<span class="w"> </span>load<span class="w"> </span>julia
module<span class="w"> </span>load<span class="w"> </span>julia-amdgpu

julia<span class="w"> </span>--project<span class="o">=</span>.<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;using Pkg; Pkg.instantiate()&#39;</span>
julia<span class="w"> </span>--project<span class="o">=</span>.<span class="w"> </span>script.jl
</pre></div>
</div>
<p>An example of the <code class="docutils literal notranslate"><span class="pre">script.jl</span></code> code is provided below.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">AMDGPU</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">B_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A_d</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">A_d</span>

<span class="n">println</span><span class="p">(</span><span class="s">&quot;----EOF----&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="running-on-google-colab">
<h3>Running on Google Colab<a class="headerlink" href="#running-on-google-colab" title="Link to this heading"></a></h3>
<p>Google Colaboratory, commonly referred to as “Colab”, is a cloud-based Jupyter notebook environment which runs in your web browser. Using it requires login with a Google account.</p>
<p>This is how you can get access to NVIDIA GPUs on Colab:</p>
<ul class="simple">
<li><p>Visit <a class="reference external" href="https://colab.research.google.com/">https://colab.research.google.com/</a> and sign in to your Google account</p></li>
<li><p>In the menu in front of you, click “New notebook” in the bottom right corner</p></li>
<li><p>After the notebook loads, go to the “Runtime” menu at the top and select “Change runtime type”</p></li>
<li><p>Select “GPU” under “Hardware accelerator” and choose an available type of NVIDIA GPU (e.g. T4)</p></li>
<li><p>Click “Save”. The runtime takes a few seconds to load - you can see the status in the top right corner</p></li>
<li><p>After the runtime has loaded, you can type <code class="docutils literal notranslate"><span class="pre">!nvidia-smi</span></code> to see information about the GPU.</p></li>
<li><p>You can now write Python code that runs on GPUs through e.g. the numba library.</p></li>
</ul>
</section>
<section id="access-to-code-examples">
<h3>Access to code examples<a class="headerlink" href="#access-to-code-examples" title="Link to this heading"></a></h3>
<p>Some exercises in this lesson rely on source code that you should download and modify in your own home directory on the cluster. All code examples are available in the same GitHub repository as this lesson itself. To download it you should use Git:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/gpu-programming.git
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>gpu-programming/content/examples/
<span class="gp">$ </span>ls
</pre></div>
</div>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-1-gpu-history"></span><section id="why-gpus">
<span id="gpu-history"></span><h2>Why GPUs?<a class="headerlink" href="#why-gpus" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What is Moore’s law?</p></li>
<li><p>What problems do GPUs solve?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Explain the historical development of microprocessors and how GPUs enable
continued scaling in computational power</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>15 min teaching</p></li>
<li><p>0 min exercises</p></li>
</ul>
</div>
<section id="moore-s-law">
<h3>Moore’s law<a class="headerlink" href="#moore-s-law" title="Link to this heading"></a></h3>
<p>It states that the number of transistors in a dense integrated circuit doubles about every two years.
More transistors means smaller size of a single element, so higher core frequency can be achieved.
However, power consumption scales with frequency to the third power, therefore the growth in the core frequency has slowed down significantly.
Higher performance of a single node has to rely on its more complicated structure and can still be achieved with SIMD (single instruction multiple data), branch prediction, etc.</p>
<figure class="align-center" id="id2">
<img alt="_images/microprocessor-trend-data.png" src="_images/microprocessor-trend-data.png" />
<figcaption>
<p><span class="caption-text">The evolution of microprocessors.
The number of transistors per chip doubles roughly every 2 years.
However, it can no longer be explored by the core frequency due to the power consumption limits.
Before 2000, the increase in the single core clock frequency was the major source of the
increase in the performance. Mid 2000 mark a transition towards multi-core processors.</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Increasing performance has been sustained with two main strategies over the years:</p>
<blockquote>
<div><ul class="simple">
<li><p>Increase the single processor performance:</p></li>
<li><p>More recently, increase the number of physical cores.</p></li>
</ul>
</div></blockquote>
</section>
<section id="computing-in-parallel">
<h3>Computing in parallel<a class="headerlink" href="#computing-in-parallel" title="Link to this heading"></a></h3>
<p>The underlying idea of parallel computing is to split a computational problem into smaller
subtasks. Many subtasks can then be solved <em>simultaneously</em> by multiple processing units.</p>
<figure class="align-center" id="id3">
<img alt="_images/compp.png" src="_images/compp.png" />
<figcaption>
<p><span class="caption-text">Computing in parallel.</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>How a problem is split into smaller subtasks strongly depends on the problem.
There are various paradigms and programming approaches to do this.</p>
</section>
<section id="graphics-processing-units">
<h3>Graphics processing units<a class="headerlink" href="#graphics-processing-units" title="Link to this heading"></a></h3>
<p>Graphics processing units (GPU) have been the most common accelerators during the last few years, the term GPU sometimes is used interchangeably with the term <em>accelerator</em>.
GPUs were initially developed for highly-parallel tasks of graphic processing.
But over the years, they were used more and more in high-performance computing (HPC).</p>
<p>GPUs are a specialized parallel hardware for floating point operations.
They are basically co-processors (helpers) for traditional CPUs: a CPU still controls the work flow
but it delegates highly parallel tasks to the GPU.
GPUs are based on highly parallel architectures, which allows taking advantage of the
increasing number of transistors.</p>
<p>Using GPUs allows one to achieve extreme performance per node.
As a result, a single GPU-equipped workstation can outperform small CPU-based clusters
for some types of computational tasks. The drawback is: usually major rewrites of programs are required
with an accompanying change in the programming paradigm.</p>
<div class="admonition-host-vs-device callout admonition" id="callout-0">
<p class="admonition-title">Host vs device</p>
<p>GPU-enabled systems require a heterogeneous programming model that involves both
CPU and GPU, where the CPU and its memory are referred to as the host,
and the GPU and its memory as the device.</p>
</div>
<figure class="align-center" id="id4">
<img alt="_images/CPU_and_GPU_separated.png" src="_images/CPU_and_GPU_separated.png" />
<figcaption>
<p><span class="caption-text">Figure adapted from the Carpentry <a class="reference external" href="https://carpentries-incubator.github.io/lesson-gpu-programming/">GPU Programming lesson</a>.</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="a-look-at-the-top500-list">
<h3>A look at the TOP500 list<a class="headerlink" href="#a-look-at-the-top500-list" title="Link to this heading"></a></h3>
<p>The <a class="reference external" href="https://www.top500.org/">TOP500 project</a> ranks and details the 500 most powerful non-distributed computer systems in the world. The project was started in 1993 and publishes an updated list of the supercomputers twice a year. The snapshot below shows the top-5 HPC systems as of June 2025, where the columns show:</p>
<ul class="simple">
<li><p><strong>Cores</strong> - Number of processors</p></li>
<li><p><strong>Rmax</strong> - Maximal LINPACK performance achieved</p></li>
<li><p><strong>Rpeak</strong> - Theoretical peak performance</p></li>
<li><p><strong>Power</strong> - Power consumption</p></li>
</ul>
<figure class="align-center" id="id5">
<img alt="_images/top-5.png" src="_images/top-5.png" />
<figcaption>
<p><span class="caption-text">Snapshot from the <a class="reference external" href="https://www.top500.org/lists/top500/2024/05/">TOP500 list from June, 2025</a>.</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>All systems in the top-5 positions contain GPUs from AMD, Intel, or NVIDIA.</p>
</section>
<section id="id1">
<h3>Why GPUs?<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Speed</strong>: GPU computing can significantly accelerate many types of scientific workloads.</p></li>
<li><p><strong>Improved energy efficiency</strong>: Compared to CPUs, GPUs can perform more calculations per watt of power consumed,
which can result in significant energy savings. This is indeed evident from the <a class="reference external" href="https://www.top500.org/lists/green500/2025/06/">GREEN500 list</a>.</p></li>
<li><p><strong>Cost-effectiveness</strong>: GPUs can be more cost-effective than traditional CPU-based systems for certain workloads.</p></li>
</ul>
</section>
<section id="limitations-and-drawbacks">
<h3>Limitations and drawbacks<a class="headerlink" href="#limitations-and-drawbacks" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Only for certain workloads</strong>: Not all workloads can be efficiently parallelized and accelerated on GPUs. Certain types of workloads, such as those with irregular data access patterns or high branching behavior, may not see significant performance improvements on GPUs.</p></li>
<li><p><strong>Steeper learning curve</strong>: Depending on the GPU programming API that you choose, GPU computing could require specialized skills in GPU programming and knowledge of GPU architecture, leading to a steeper learning curve compared to CPU programming. Fortunately, if you study this training material closely you will become productive with GPU programming quickly!</p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>GPUs are accelerators for some types of tasks</p></li>
<li><p>Highly parallelizable compute-intensive tasks are suitable for GPUs</p></li>
<li><p>GPU-based systems dominate the top spots of the TOP500 list</p></li>
<li><p>New programming skills are needed to use GPUs efficiently</p></li>
</ul>
</div>
</section>
</section>
<span id="document-2-gpu-ecosystem"></span><section id="the-gpu-hardware-and-software-ecosystem">
<span id="gpu-ecosystem"></span><h2>The GPU hardware and software ecosystem<a class="headerlink" href="#the-gpu-hardware-and-software-ecosystem" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What are the differences between GPUs and CPUs?</p></li>
<li><p>What GPU software stacks are available? What do they provide?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand the fundamental differences between GPUs and CPUs</p></li>
<li><p>Explore the major GPU software suites available, such as CUDA, ROCm, and oneAPI, and gain a basic understanding of them</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>20 min teaching</p></li>
<li><p>0 min exercises</p></li>
</ul>
</div>
<section id="overview-of-gpu-hardware">
<h3>Overview of GPU hardware<a class="headerlink" href="#overview-of-gpu-hardware" title="Link to this heading"></a></h3>
<figure class="align-center" id="id1">
<img alt="_images/CPUAndGPU.png" src="_images/CPUAndGPU.png" />
<figcaption>
<p><span class="caption-text">A comparison of the CPU and GPU architecture.
CPU (left) has complex core structure and pack several cores on a single chip.
GPU cores are very simple in comparison, they also share data and control between each other.
This allows to pack more cores on a single chip, thus achieving very high compute density.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<div class="dropdown admonition">
<p class="admonition-title">In short</p>
<ul class="simple">
<li><p>Accelerators offer high performance due to their scalability and high density of compute elements.</p></li>
<li><p>They have separate circuit boards connected to CPUs via PCIe bus, with their own memory.</p></li>
<li><p>CPUs copy data from their own memory to the GPU memory, execute the program, and copy the results back.</p></li>
<li><p>GPUs run thousands of threads simultaneously, quickly switching between them to hide memory operations.</p></li>
<li><p>Effective data management and access pattern is critical on the GPU to avoid running out of memory.</p></li>
</ul>
</div>
<p>Accelerators are a separate main circuit board with the processor, memory, power management, etc.
It is connected to the motherboard with CPUs via PCIe bus.
Having its own memory means that the data has to be copied to and from it (not neceseraly true anymore).
CPU acts as a main processor, controlling the execution workflow.
It copies the data from its own memory to the GPU memory, executes the program and copies the results back.
GPUs runs tens of thousands of threads simultaneously on thousands of cores and does not do much of the data management.
With many cores trying to access the memory simultaneously and with little cache available, the accelerator can run out of memory very quickly.
This makes the data management and its access pattern is essential on the GPU.
Accelerators like to be overloaded with the number of threads, because they can switch between threads very quickly.
This allows to hide the memory operations: while some threads wait, others can compute.</p>
<p>A very important feature of  the accelerators  is their scalability.
Computational cores on accelerators are usually grouped into multiprocessors.
The multiprocessors share the data and logical elements.
This allows to achieve a very high density of compute elements on a GPU.
This also allows the scaling: more multiprocessors means more raw performance and this is very easy to achieve with more transistors available.</p>
</section>
<section id="how-do-gpus-differ-from-cpus">
<h3>How do GPUs differ from CPUs?<a class="headerlink" href="#how-do-gpus-differ-from-cpus" title="Link to this heading"></a></h3>
<p>CPUs and GPUs were designed with different goals in mind. While the CPU
is designed to excel at executing a sequence of operations, called a thread,
as fast as possible and can execute a few tens of these threads in parallel,
the GPU is designed to excel at executing many thousands of them in parallel.
GPUs were initially developed for highly-parallel task of graphic processing
and therefore designed such that more transistors are devoted to data processing
rather than data caching and flow control. More transistors dedicated to
data processing is beneficial for highly parallel computations; the GPU can
hide memory access latencies with computation, instead of relying on large data caches
and complex flow control to avoid long memory access latencies,
both of which are expensive in terms of transistors.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>CPU</p></th>
<th class="head"><p>GPU</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>General purpose</p></td>
<td><p>Highly specialized for parallelism</p></td>
</tr>
<tr class="row-odd"><td><p>Good for serial processing</p></td>
<td><p>Good for parallel processing</p></td>
</tr>
<tr class="row-even"><td><p>Great for task parallelism</p></td>
<td><p>Great for data parallelism</p></td>
</tr>
<tr class="row-odd"><td><p>Low latency per thread</p></td>
<td><p>High-throughput</p></td>
</tr>
<tr class="row-even"><td><p>Large area dedicated cache and control</p></td>
<td><p>Hundreds of floating-point execution units</p></td>
</tr>
</tbody>
</table>
</section>
<section id="gpu-platforms">
<h3>GPU platforms<a class="headerlink" href="#gpu-platforms" title="Link to this heading"></a></h3>
<p>GPUs come together with software stacks or APIs that work in conjunction with the hardware and give a standard way for the software to interact with the GPU hardware. They are used by software developers to write code that can take advantage of the parallel processing power of the GPU, and they provide a standard way for software to interact with the GPU hardware. Typically, they provide access to low-level functionality, such as memory management, data transfer between the CPU and the GPU, and the scheduling and execution of parallel processing tasks on the GPU. They may also provide higher level functions and libraries optimized for specific HPC workloads, like linear algebra or fast Fourier transforms. Finally, in order to facilitate the developers to optimize and write correct codes, debugging and profiling tools are also included.</p>
<p><em>NVIDIA</em>, <em>AMD</em>, and <em>Intel</em> are the major companies which design and produces GPUs for HPC providing each its own suite <strong>CUDA</strong>, <strong>ROCm</strong>, and respectively <strong>oneAPI</strong>. This way they can offer optimization, differentiation (offering unique features tailored to their devices), vendor lock-in, licensing, and royalty fees, which can result in better performance, profitability, and customer loyalty.
There are also cross-platform APIs such <strong>DirectCompute</strong> (only for Windows operating system), <strong>OpenCL</strong>, and <strong>SYCL</strong>.</p>
<div class="dropdown admonition">
<p class="admonition-title">CUDA - In short</p>
<ul class="simple">
<li><dl class="simple">
<dt>CUDA: NVIDIA’s parallel computing platform</dt><dd><ul>
<li><p>Components: CUDA Toolkit &amp; CUDA driver</p></li>
<li><p>Supports C, C++, and Fortran languages</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CUDA API Libraries: cuBLAS, cuFFT, cuRAND, cuSPARSE</dt><dd><ul>
<li><p>Accelerate complex computations on GPUs</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Compilers: nvcc, nvc, nvc++, nvfortran</dt><dd><ul>
<li><p>Support GPU and multicore CPU programming</p></li>
<li><p>Compatible with OpenACC and OpenMP</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Debugging tools: cuda-gdb, compute-sanitizer</dt><dd><ul>
<li><p>Debug GPU and CPU code simultaneously</p></li>
<li><p>Identify memory access issues</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Performance analysis tools: NVIDIA Nsight Systems, NVIDIA Nsight Compute</dt><dd><ul>
<li><p>Analyze system-wide and kernel-level performance</p></li>
<li><p>Optimize CPU and GPU usage, memory bandwidth, instruction throughput</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Comprehensive CUDA ecosystem with extensive tools and features</p></li>
</ul>
</div>
<div class="dropdown admonition">
<p class="admonition-title">ROCm - In short</p>
<ul class="simple">
<li><dl class="simple">
<dt>ROCm: Open software platform for AMD accelerators</dt><dd><ul>
<li><p>Built for open portability across multiple vendors and architectures</p></li>
<li><p>Offers libraries, compilers, and development tools for AMD GPUs</p></li>
<li><p>Supports C, C++, and Fortran languages</p></li>
<li><p>Support GPU and multicore CPU programming</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Debugging: <code class="docutils literal notranslate"><span class="pre">roc-gdb</span></code> command line tool</dt><dd><ul>
<li><p>Facilitates debugging of GPU programs</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Performance analysis: <code class="docutils literal notranslate"><span class="pre">rocprof</span></code> and <code class="docutils literal notranslate"><span class="pre">roctracer</span></code> tools</dt><dd><ul>
<li><p>Analyze and optimize program performance</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Supports various heterogeneous programming models such as <strong>HIP</strong>, <strong>OpenMP</strong>, and <strong>OpenCL</strong></p></li>
<li><dl class="simple">
<dt>Heterogeneous-Computing Interface for Portability (HIP)</dt><dd><ul>
<li><p>Enables source portability for NVIDIA and AMD platforms, Intel in plan</p></li>
<li><p>Provides <code class="docutils literal notranslate"><span class="pre">hipcc</span></code> compiler driver and runtime libraries</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Libraries: Prefixed with <code class="docutils literal notranslate"><span class="pre">roc</span></code> for AMD platforms</dt><dd><ul>
<li><p>Can be called directly from HIP</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hip</span></code>-prefixed wrappers ensure portability with no performance cost</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="dropdown admonition">
<p class="admonition-title">oneAPI - In short</p>
<ul class="simple">
<li><dl class="simple">
<dt>Intel oneAPI: Unified software toolkit for optimizing and deploying applications across various architectures</dt><dd><ul>
<li><p>Supports CPUs, GPUs, and FPGAs</p></li>
<li><p>Enables code reusability and performance portability</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Intel oneAPI Base Toolkit: Core set of tools and libraries for high-performance, data-centric applications</dt><dd><ul>
<li><p>Includes C++ compiler with SYCL support</p></li>
<li><p>Features Collective Communications Library, Data Analytics Library, Deep Neural Networks Library, and more</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Additional toolkits: Intel oneAPI HPC Toolkit</dt><dd><ul>
<li><p>Contains compilers, debugging tools, MPI library, and performance analysis tool</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Multiple programming models and languages supported:</dt><dd><ul>
<li><p>OpenMP, Classic Fortran, C++, SYCL</p></li>
<li><p>Unless custom Intel libraries are used, the code is portable to other OpenMP and SYCL frameworks</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>DPC++ Compiler: Supports Intel, NVIDIA, and AMD GPUs</dt><dd><ul>
<li><p>Targets Intel GPUs using oneAPI Level Zero interface</p></li>
<li><p>Added support for NVIDIA GPUs with CUDA and AMD GPUs with ROCm</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Debugging and performance analysis tools: Intel Adviser, Intel Vtune Profiler, Cluster Checker, Inspector, Intel Trace Analyzer and Collector, Intel Distribution for GDB</p></li>
<li><dl class="simple">
<dt>Comprehensive and unified approach to heterogeneous computing</dt><dd><ul>
<li><p>Abstracts complexities and provides consistent programming interface</p></li>
<li><p>Promotes code reusability, productivity, and performance portability</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<section id="cuda">
<h4>CUDA<a class="headerlink" href="#cuda" title="Link to this heading"></a></h4>
<p><strong>Compute Unified Device Architecture</strong> is the parallel computing platform from NVIDIA. The CUDA API provides a comprehensive set of functions and tools for developing high-performance applications that run on NVIDIA GPUs. It consists of two main components: the CUDA Toolkit and the CUDA driver. The toolkit provides a set of libraries, compilers, and development tools for programming and optimizing CUDA applications, while the driver is responsible for communication between the host CPU and the device GPU. CUDA is designed to work with programming languages such as C, C++, and Fortran.</p>
<p>CUDA API provides many highly optimize libraries such as: <strong>cuBLAS</strong> (for linear algebra operations, such a dense matrix multiplication), <strong>cuFFT</strong> (for performing fast Fourier transforms), <strong>cuRAND</strong> (for generating pseudo-random numbers), <strong>cuSPARSE</strong> (for sparse matrices operations). Using these libraries, developers can quickly and easily accelerate complex computations on NVIDIA GPUs without having to write low-level GPU code themselves.</p>
<p>There are several compilers that can be used for developing and executing code on NVIDIA GPUs: <strong>nvcc</strong>. The latest versions are based on the widely used LLVM (low level virtual machine) open source compiler infrastructure. nvcc produces optimized code for NVIDIA GPUs and drives a supported host compiler for AMD, Intel, OpenPOWER, and Arm CPUs.</p>
<p>In addition to this are provided <strong>nvc</strong> (C11 compiler), <strong>nvc++</strong> (C++17 compiler), and  <strong>nvfortran</strong> (ISO Fortran 2003 compiler). These compilers can as well create code for execution on the NVIDIA GPUs, and also support GPU and multicore CPU programming with parallel language features, OpeanACC and OpenMP.</p>
<p>When programming mistakes are inevitable they have to be fixed as soon as possible. The CUDA toolkit includes the command line tool <strong>cuda-gdb</strong> which can be used to find errors in the code. It is an extension to GDB, the GNU Project debugger.  The existing GDB debugging features are inherently present for debugging the host code, and additional features have been provided to support debugging CUDA device code, allowing simultaneous debugging of both GPU and CPU code within the same application. The tool provides developers with a mechanism for debugging CUDA applications running on actual hardware. This enables developers to debug applications without the potential variations introduced by simulation and emulation environments.</p>
<p>In addition to this the command line tool <strong>compute-sanitizer</strong> can be used to look exclusively for memory access problems: unallocated buffers, out of bounds accesses, race conditions, and uninitialized variables.</p>
<p>Finally, in order to utilize the GPUs at maximum some performance analysis tools. NVIDIA provides NVIDIA Nsight Systems and NVIDIA Nsight Compute tools for helping the developers to optimize their applications. The former, NVIDIA Nsight Systems, is a system-wide performance analysis tool that provides detailed metrics on both CPU and GPU usage, memory bandwidth, and other system-level metrics. The latter, NVIDIA Nsight Compute, is a kernel-level performance analysis tool that allows developers to analyze the performance of individual CUDA kernels. It provides detailed metrics on kernel execution, including memory usage, instruction throughput, and occupancy. These tools have graphical which can be used for all steps of the performance analysis, however on supercomputers it is recommended to use the command line interface for collecting the information needed and then visualize and analyse the results using the graphical interface on personal computers.</p>
<p>Apart from what was presented above there are many others tools and features provided by NVIDIA. The CUDA ecosystem is very well developed.</p>
</section>
<section id="rocm">
<h4>ROCm<a class="headerlink" href="#rocm" title="Link to this heading"></a></h4>
<p>ROCm is an open software platform allowing researchers to tap the power of AMD accelerators.
The ROCm platform is built on the foundation of open portability, supporting environments across multiple
accelerator vendors and architectures. In some way it is very similar to CUDA API.
It contains libraries, compilers, and development tools for programming and optimizing programs for AMD GPUs.
For debugging, it provides the command line tool <code class="docutils literal notranslate"><span class="pre">rocgdb</span></code>, while for performance analysis <code class="docutils literal notranslate"><span class="pre">rocprof</span></code> and <code class="docutils literal notranslate"><span class="pre">roctracer</span></code>.
In order to produce code for the AMD GPUs, one can use the Heterogeneous-Computing Interface for Portability (HIP).
HIP is a C++ runtime API and a set of tools that allows developers to write portable GPU-accelerated code for both NVIDIA and AMD platforms.
It provides the <code class="docutils literal notranslate"><span class="pre">hipcc</span></code> compiler driver, which will call the appropriate toolchain depending on the desired platform.
On the AMD ROCm platform, HIP provides a header and runtime library built on top of the HIP-Clang (ROCm compiler).
On an NVIDIA platform, HIP provides a header file which translates from the HIP runtime APIs to CUDA runtime APIs.
The header file contains mostly inlined functions and thus has very low overhead.
The code is then compiled with <code class="docutils literal notranslate"><span class="pre">nvcc</span></code>, the standard C++ compiler provided with CUDA.
On AMD platforms, libraries are prefixed by <code class="docutils literal notranslate"><span class="pre">roc</span></code>, which can be called directly from HIP. In order to make portable calls,
one can call the libraries using <code class="docutils literal notranslate"><span class="pre">hip</span></code>-prefixed wrappers. These wrappers can be used at no performance cost and ensure that
HIP code can be used on other platforms with no changes. Libraries included in the ROCm, are almost one-to-one equivalent to the ones supplied with CUDA.</p>
<p>ROCm also integrates with popular machine learning frameworks such as TensorFlow and PyTorch and provides optimized libraries and drivers to accelerate machine learning workloads on AMD GPUs enabling the researchers to leverage the power of ROCm and AMD accelerators to train and deploy machine learning models efficiently.</p>
</section>
<section id="oneapi">
<h4>oneAPI<a class="headerlink" href="#oneapi" title="Link to this heading"></a></h4>
<p><strong>Intel oneAPI</strong> is a unified software toolkit developed by Intel that allows developers to optimize and deploy applications across a variety of architectures, including CPUs, GPUs, and FPGAs. It provides a comprehensive set of tools, libraries, and frameworks, enabling developers to leverage the full potential of heterogeneous computing environments. With oneAPI, the developers can write code once and deploy it across different hardware targets without the need for significant modifications or rewriting. This approach promotes code reusability, productivity, and performance portability, as it abstracts the complexities of heterogeneous computing and provides a consistent programming interface based on open standards.</p>
<p>The core of suite is <strong>Intel oneAPI Base Toolkit</strong>, a set of tools and libraries for developing high-performance, data-centric applications across diverse architectures. It features an industry-leading C++ compiler that implements SYCL, an evolution of C++ for heterogeneous computing. It includes the <strong>Collective Communications Library</strong>, the <strong>Data Analytics Library</strong>, the <strong>Deep Neural Networks Library</strong>, the <strong>DPC++/C++ Compiler</strong>, the <strong>DPC++ Library</strong>, the <strong>Math Kernel Library</strong>, the <strong>Threading Building Blocks</strong>, debugging tool <strong>Intel Distribution for GDB</strong>, performance analysis tools <strong>Intel Adviser</strong> and <strong>Intel Vtune Profiler</strong>, the <strong>Video Processing Library</strong>, <strong>Intel Distribution for Python</strong>, the <strong>DPC++ Compatibility Tool</strong>, the <strong>FPGA Add-on for oneAPI Base Toolkit</strong>, the <strong>Integrated Performance Primitives</strong>.
This can be complemented with additional toolkits. The <strong>Intel oneAPI HPC Toolkit</strong> contains <strong>DPC++/C++ Compiler</strong>, <strong>Fortran</strong> and <strong>C++</strong> Compiler Classic, debugging tools <strong>Cluster Checker</strong> and <strong>Inspector</strong>, <strong>Intel MPI Library</strong>, and performance analysis tool <strong>Intel Trace Analyzer and Collector</strong>.</p>
<p>oneAPI supports multiple programming models and programming languages. It enables developers to write <strong>OpenMP</strong> codes targeting multi-core CPUs and Intel GPUs using the Classic Fortran and C++ compilers and as well <strong>SYCL</strong> programs for GPUs and FPGAs using the <strong>DPC++</strong> compiler. Initially, the <strong>DPC++</strong> compiler only targeted Intel GPUs using the <strong>oneAPI Level Zero</strong> low-level programming interface, but now support for NVIDIA GPUs (using  CUDA) and AMD GPUs (using ROCm) has been added.
Overall, Intel oneAPI offers a comprehensive and unified approach to heterogeneous computing, empowering developers to optimize and deploy applications across different architectures with ease. By abstracting the complexities and providing a consistent programming interface, oneAPI promotes code reusability, productivity, and performance portability, making it an invaluable toolkit for developers in the era of diverse computing platforms.</p>
</section>
<section id="differences-and-similarities">
<h4>Differences and similarities<a class="headerlink" href="#differences-and-similarities" title="Link to this heading"></a></h4>
<p>GPUs in general support different features, even among the same producer. In general newer cards come with extra
features and sometimes old features are not supported anymore. It is important when compiling to create binaries
targeting the specific architecture when compiling. A binary built for a newer card will not run on older devices,
while a binary build for older devices might not run efficiently on newer architectures. In CUDA the compute
capability which is targeted is specified by the <code class="docutils literal notranslate"><span class="pre">-arch=sm_XY</span></code>, where <code class="docutils literal notranslate"><span class="pre">X</span></code> specifies the major architecture and it is between 1 and 9, and <code class="docutils literal notranslate"><span class="pre">Y</span></code> the minor. When using HIP on NVIDIA platforms one needs to use compiling option <code class="docutils literal notranslate"><span class="pre">--gpu-architecture=sm_XY</span></code>, while on AMD platforms  <code class="docutils literal notranslate"><span class="pre">--offload-arch=gfxabc</span></code> ( where <code class="docutils literal notranslate"><span class="pre">abc</span></code> is the architecture code such as <code class="docutils literal notranslate"><span class="pre">90a</span></code> for the MI200 series or <code class="docutils literal notranslate"><span class="pre">908</span></code> for MI100 series).
Note that in the case of portable (single source) programs one would specify <code class="docutils literal notranslate"><span class="pre">openmp</span></code> as well as target for
compilation, enabling to run the same code on multicore CPU.</p>
</section>
<section id="terminology">
<h4>Terminology<a class="headerlink" href="#terminology" title="Link to this heading"></a></h4>
<table class="docutils align-default" id="id2">
<caption><span class="caption-text">Hardware</span><a class="headerlink" href="#id2" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>NVIDIA</p></th>
<th class="head"><p>AMD</p></th>
<th class="head"><p>Intel</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Streaming processor/streaming core</p></td>
<td><p>SIMD lane</p></td>
<td><p>Processing element</p></td>
</tr>
<tr class="row-odd"><td><p>SIMT unit</p></td>
<td><p>SIMD unit</p></td>
<td><p>Vector engine (XVE)</p></td>
</tr>
<tr class="row-even"><td><p>Streaming Multiprocessor (SM)</p></td>
<td><p>Computing Unit (CU)</p></td>
<td><p>Xe-core / Execution unit (EU)</p></td>
</tr>
<tr class="row-odd"><td><p>GPU processing clusters (GPC)</p></td>
<td><p>Compute Engine</p></td>
<td><p>Xe-slice</p></td>
</tr>
</tbody>
</table>
<p>Please keep in mind, that this table is only a rough approximation.
Each GPU architecture is different, and it’s impossible to make a 1-to-1 mapping between terms used by different vendors.</p>
</section>
</section>
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>GPUs are designed to execute thousands of threads simultaneously, making them highly parallel processors. In contrast, CPUs excel at executing a smaller number of threads in parallel.</p></li>
<li><p>GPUs allocate a larger portion of transistors to data processing rather than data caching and flow control. This prioritization of data processing enables GPUs to effectively handle parallel computations and hide memory access latencies through computation.</p></li>
<li><p>GPU producers provide comprehensive toolkits, libraries, and compilers for developing high-performance applications that leverage the parallel processing power of GPUs. Examples include CUDA (NVIDIA), ROCm (AMD), and oneAPI (Intel).</p></li>
<li><p>These platforms offer debugging tools (e.g., <code class="docutils literal notranslate"><span class="pre">cuda-gdb</span></code>, <code class="docutils literal notranslate"><span class="pre">rocgdb</span></code>) and performance analysis tools (e.g., NVIDIA Nsight Systems, NVIDIA Nsight Compute, <code class="docutils literal notranslate"><span class="pre">rocprof</span></code>, <code class="docutils literal notranslate"><span class="pre">roctracer</span></code>) to facilitate code optimization and ensure efficient utilization of GPU resources.</p></li>
</ul>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-gpus-and-memory exercise important admonition" id="exercise-0">
<p class="admonition-title">GPUs and memory</p>
<p>Which statement about the relationship between GPUs and memory is true?</p>
<ul class="simple">
<li><ol class="upperalpha simple">
<li><p>GPUs are not affected by memory access latencies.</p></li>
</ol>
</li>
<li><ol class="upperalpha simple" start="2">
<li><p>GPUs can run out of memory quickly with many cores trying to access the memory simultaneously.</p></li>
</ol>
</li>
<li><ol class="upperalpha simple" start="3">
<li><p>GPUs have an unlimited cache size.</p></li>
</ol>
</li>
<li><ol class="upperalpha simple" start="4">
<li><p>GPUs prefer to run with a minimal number of threads to manage memory effectively.</p></li>
</ol>
</li>
</ul>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<p>The correct answer is B). This is true because GPUs run many threads simultaneously on thousands of
cores, and with limited cache available, this can lead to the GPU running out of memory quickly if many
cores are trying to access the memory simultaneously. This is why data management and access patterns
are essential in GPU computing.</p>
</div>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>GPUs vs. CPUs, key differences between them</p></li>
<li><p>GPU software suites, support specific GPU features, programming models, compatibility</p></li>
<li><p>Applications of GPUs</p></li>
</ul>
</div>
</section>
</section>
<span id="document-3-gpu-problems"></span><section id="what-problems-fit-to-gpu">
<span id="gpu-problems"></span><h2>What problems fit to GPU?<a class="headerlink" href="#what-problems-fit-to-gpu" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What are the strengths and weaknesses of GPUs?</p></li>
<li><p>What makes a particular problem suitable for GPU-porting?</p></li>
<li><p>Why are GPUs so ubiquitous in machine learning applications?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Get a feeling for the type of use cases that GPUs excel at.</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>10 min teaching</p></li>
<li><p>10 min exercises</p></li>
</ul>
</div>
<section id="what-are-gpus-good-for">
<h3>What are GPUs good for?<a class="headerlink" href="#what-are-gpus-good-for" title="Link to this heading"></a></h3>
<p>Answer from <a class="reference external" href="https://scicomp.stackexchange.com/questions/943/what-kinds-of-problems-lend-themselves-well-to-gpu-computing">Stack Exchange</a>:</p>
<blockquote>
<div><p><em>From a metaphorical point of view, the GPU can be seen as a person lying on a bed
of nails. The person lying on top is the data and in the base of each nail there
is a processor, so the nail is actually an arrow pointing from processor to memory.
All nails are in a regular pattern, like a grid. If the body is well spread,
it feels good (performance is good), if the body only touches some spots of the
nail bed, then the pain is bad (bad performance).</em></p>
</div></blockquote>
<p>GPU computing is well-suited to problems that involve large amounts of data parallelism.
Specifically, you can expect good performance on GPUs for:</p>
<ul class="simple">
<li><p><strong>Large-scale matrix and vector operations</strong>: Common in machine learning, scientific computing, and image processing.</p></li>
<li><p><strong>Fourier transforms</strong>: Also common in machine learning, scientific computing, and image processing.</p></li>
<li><p><strong>Monte Carlo simulations</strong>: Used across finance, physics, and other fields to simulate complex systems.</p></li>
<li><p><strong>Molecular dynamics simulations</strong>: Used in chemistry, biochemistry and physics.</p></li>
<li><p><strong>Computational fluid dynamics</strong>: Used in engineering, physics, and other fields.</p></li>
<li><p><strong>Convolutional neural networks</strong> and <strong>computer vision algorithms</strong>.</p></li>
<li><p><strong>Big data analytics</strong>: Clustering, classification, regression, etc.</p></li>
<li><p><strong>Graphics rendering</strong>: Original use-case for GPUs.</p></li>
</ul>
</section>
<section id="what-are-gpus-not-good-for">
<h3>What are GPUs not good for?<a class="headerlink" href="#what-are-gpus-not-good-for" title="Link to this heading"></a></h3>
<p>Not all programming problems can efficiently leverage the parallelism offered by GPUs.
Some types of problems that do not fit well on a GPU include:</p>
<ul class="simple">
<li><p><strong>Sequential tasks</strong>: Problems that require a series of dependent steps,
where each step relies on the outcome of the previous step, are not well-suited
for parallel processing. Examples include recursive algorithms, certain dynamic
programming problems, and some graph traversal algorithms.</p></li>
<li><p><strong>Fine-grained branching</strong>: GPUs perform best when the code being executed across
different threads follows a similar control flow. When there is extensive
branching (i.e., many <code class="docutils literal notranslate"><span class="pre">if</span></code> statements) within a kernel or algorithm, performance
may suffer due to the divergence in execution paths among the GPU threads.</p></li>
<li><p><strong>Low arithmetic intensity</strong>: GPUs excel at performing a large number of mathematical
operations quickly. If a problem has low arithmetic intensity (i.e., a low ratio of
arithmetic operations to memory accesses), the GPU may not be able to efficiently utilize
its computational power, leading to underperformance.</p></li>
<li><p><strong>Small data sets</strong>: If the problem involves a small data set that does not require significant
parallelism, using a GPU may not result in noticeable performance gains. In such cases,
the overhead of transferring data between the CPU and GPU, and the time spent initializing the GPU,
may outweigh any potential benefits.</p></li>
<li><p><strong>Limited parallelism</strong>: Some algorithms have inherent limitations on the degree of parallelism that can be
achieved. In these cases, using a GPU may not lead to significant performance improvements.</p></li>
<li><p><strong>Memory-bound problems</strong>: GPUs generally have less memory available compared to CPUs, and their memory bandwidth
can be a limiting factor. If a problem requires a large amount of memory or involves memory-intensive operations,
it may not be well-suited for a GPU.</p></li>
</ul>
</section>
<section id="examples-of-gpu-acceleration">
<h3>Examples of GPU acceleration<a class="headerlink" href="#examples-of-gpu-acceleration" title="Link to this heading"></a></h3>
<p>To give a flavor of what type of performance gains we can achieve by porting a calculations to a GPU
(if we’re lucky!), let’s look at a few case examples.</p>
<div class="admonition-effect-of-array-size discussion important admonition" id="discussion-0">
<p class="admonition-title">Effect of array size</p>
<p>Consider the case of matrix multiplication in the Julia language:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">AMDGPU</span>
<span class="k">using</span><span class="w"> </span><span class="n">BenchmarkTools</span>

<span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">11</span><span class="p">,</span><span class="w"> </span><span class="mi">12</span><span class="p">]</span>

<span class="k">for</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">N</span>
<span class="w">   </span><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="n">n</span><span class="p">);</span><span class="w"> </span><span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="w">   </span><span class="nd">@btime</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="p">;</span>

<span class="w">   </span><span class="nd">@btime</span><span class="w"> </span><span class="k">begin</span>
<span class="w">      </span><span class="o">$</span><span class="n">A_d</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A_d</span><span class="p">;</span>
<span class="w">      </span><span class="n">AMDGPU</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="w">   </span><span class="k">end</span>
<span class="k">end</span>
</pre></div>
</div>
<ul class="simple">
<li><p>How much faster do you think the GPU version is compared to running on a single CPU core?</p></li>
<li><p>Julia automatically parallelises matrix multiplication over available CPU cores. Will the GPU version be faster than running on 64 cores?</p></li>
<li><p>Does the size of the array affect how much the performance improves?</p></li>
</ul>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<p>Example results from running on LUMI (MI250X AMD GPU, 64-core AMD Trento CPUs):</p>
<table class="docutils align-default" id="id1">
<caption><span class="caption-text">GPU acceleration for matrix multiply in Julia</span><a class="headerlink" href="#id1" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Matrix size</p></th>
<th class="head"><p>1 CPU core</p></th>
<th class="head"><p>64 CPU cores</p></th>
<th class="head"><p>1 GPU</p></th>
<th class="head"><p>GPU speedup</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>(512, 512)</p></td>
<td><p>5.472 ms</p></td>
<td><p>517.722 μs</p></td>
<td><p>115.805 μs</p></td>
<td><p>~47x / ~5x</p></td>
</tr>
<tr class="row-odd"><td><p>(1024, 1024)</p></td>
<td><p>43.364 ms</p></td>
<td><p>2.929 ms</p></td>
<td><p>173.316 μs</p></td>
<td><p>~250x / ~17x</p></td>
</tr>
<tr class="row-even"><td><p>(2048, 2048)</p></td>
<td><p>344.364 ms</p></td>
<td><p>30.081 ms</p></td>
<td><p>866.348 μs</p></td>
<td><p>~400x / ~35x</p></td>
</tr>
<tr class="row-odd"><td><p>(4096, 4096)</p></td>
<td><p>3.221 s</p></td>
<td><p>159.563 ms</p></td>
<td><p>5.910 ms</p></td>
<td><p>~550x / ~27x</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<section id="electronic-structure-calculations">
<h4>Electronic structure calculations<a class="headerlink" href="#electronic-structure-calculations" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://www.vasp.at/">VASP</a> is a popular software package used for electronic structure calculations. The figures below show the speedup observed in a recent benchmark study on the <a class="reference external" href="https://ieeexplore.ieee.org/document/10820603">VASP Power Profiles on NVIDIA A100 GPUs</a>, which was conducted on the Perlmutter system at NERSC.
An analysis of total energy usage demonstrated that VASP’s power usage varies significantly with different workloads, more so than with parallel concurrency.
Additionally, power capping GPUs to 50% of their Thermal Design Power can be applied to most VASP workloads with less than a 10% performance loss.</p>
<figure class="align-center" id="id2">
<img alt="_images/vasp_parallel_efficiency.png" src="_images/vasp_parallel_efficiency.png" />
<figcaption>
<p><span class="caption-text">Parallel efficiency of VASP on seven test cases representing diverse VASP production workloads and ensuring a comprehensive coverage of various code paths, elements, and problem sizes.</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-center" id="id3">
<img alt="_images/vasp_energy_consumption.jpg" src="_images/vasp_energy_consumption.jpg" />
<figcaption>
<p><span class="caption-text">(Left) Power usage of seven representative VASP workloads. The horizontal axis shows number of nodes used, and vertical axis shows high power mode per node. (Right) Power consumed per GPU when running VASP under four different power caps: 400 W (default), 300 W, 200 W, and 100 W. Horizontal axis shows power caps applied to GPUs, and vertical axis shows high power mode per GPU as a fraction of applied cap. The dashed horizontal line represents applied power cap. Each benchmark was run with a node count optimizing runtime while remaining above 70% parallel efficiency.</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="computational-chemistry">
<h4>Computational Chemistry<a class="headerlink" href="#computational-chemistry" title="Link to this heading"></a></h4>
<p>A great deal of computational resources are spent in Quantum Chemical calculations which involve
the solution of the Hartree-Fock eigenvalue problem, which requires the diagonalization of the
Fock matrix whose elements are given by:</p>
<div class="math notranslate nohighlight">
\[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma \beta) \right ],\]</div>
<p>The first term is related to the one electron contributions and the second term is related to the
electron repulsion integrals (ERIs), in parenthesis, weighted by the by the density matrix
<span class="math notranslate nohighlight">\(D_{\gamma \delta}\)</span>. One of the most expensive parts in the solution of the Hartree-Fock equations is the
processing (digestion) of the ERIs, one algorithm to do this task is as follows:</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="_images/algorithms.svg"><img alt="_images/algorithms.svg" src="_images/algorithms.svg" style="width: 200px;" />
</a>
<figcaption>
<p><span class="caption-text">Algorithm for processing ERIs [see <a class="reference external" href="https://doi.org/10.1021/acs.jctc.1c00720">JCTC, 17, 7486, (2021)</a> for details]</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>This algorithm is suitable for GPUs as it involves many arithmetic operations. In addition to this,
there are symmetries and properties of the integrals that could be used to rearrange the loops in
an efficient manner that fit GPU architectures.</p>
</section>
<section id="humanities">
<h4>Humanities<a class="headerlink" href="#humanities" title="Link to this heading"></a></h4>
<p>A brief introduction into some of the work that is being done in the humanities that can benefit from utilizing GPUs.</p>
<p><strong>Language models and NLP (natural language processing)</strong></p>
<p>With the recent popularity of ChatGPT, the use of language models has come into the mainstream,
however such models have been used in the humanities many years already. One of the biggest goals of humanities
researchers is working with textual data which has increased exponentially over recent years due to the rise in
social media. Analyzing such textual data to gain insights into questions of sociology, linguistics and various
other fields have become increasingly reliant on using language models. Along with language models,
the need for GPU access has become essential.</p>
<p><strong>Archeology</strong></p>
<p>The field of archeology also makes use of GPUs in their 3D modelling
and rendering work. The biggest problem with archeological sites is that once they are excavated,
they are destroyed, so any researchers who aren’t present at the site, would lose valuable insights into how
it looked when it was found. However, with recent developments in technology and accessibility to high-performance
computing, they are able to generate extremely detailed renderings of the excavation sites which act as a way to
preserve the site for future researchers to gain critical insights and contribute to the research.</p>
<p><strong>Cognitive Science</strong></p>
<p>Techniques such as Markov Chain Monte Carlo (MCMC) sampling have proven to be invaluable in studies that delve into human behavior or population dynamics. MCMC sampling allows researchers to simulate and analyze complex systems by iteratively sampling from a Markov chain, enabling the exploration of high-dimensional parameter spaces. This method is particularly useful when studying human behavior, as it can capture the inherent randomness and interdependencies that characterize social systems. By leveraging MCMC sampling, researchers can gain insights into various aspects of human behavior, such as decision-making, social interactions, and the spread of information or diseases within populations.</p>
<p>By offloading the computational workload to GPUs, researchers can experience substantial speedup in the execution of MCMC algorithms. This speedup allows for more extensive exploration of parameter spaces and facilitates the analysis of larger datasets, leading to more accurate and detailed insights into human behavior or population dynamics. Examples of studies done using these methods can be found at the <a class="reference external" href="https://chc.au.dk/">Center for Humanities Computing Aarhus</a> (CHCAA) and <a class="reference external" href="https://interactingminds.au.dk/">Interacting Minds Centre</a> (IMC) at Aarhus University.</p>
</section>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-discussion exercise important admonition" id="exercise-0">
<p class="admonition-title">Discussion</p>
<ul class="simple">
<li><p>What type of problems have you used GPUs for?</p></li>
<li><p>How large was the performance boost?</p></li>
</ul>
</div>
<div class="admonition-good-and-bad-use-cases-for-gpu-porting exercise important admonition" id="exercise-1">
<p class="admonition-title">Good and bad use cases for GPU porting</p>
<p>Which of the following computational tasks is likely to gain the least performance benefit from being ported to a GPU?</p>
<ol class="arabic simple">
<li><p>Training a large, deep neural network.</p></li>
<li><p>Performing a Monte Carlo simulation with a large number of independent trials.</p></li>
<li><p>Executing an algorithm with heavy use of recursion and frequent branching.</p></li>
<li><p>Processing a large image with a convolutional filter.</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<p>The right answer is option 3. GPUs do not handle recursion and branching as effectively as more
data-heavy algorithms.</p>
</div>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>GPUs excel in processing tasks with high data parallelism, such as large-scale matrix operations, Fourier transforms, and big data analytics.</p></li>
<li><p>GPUs struggle with sequential tasks, problems with extensive control flow divergence, low arithmetic intensity tasks, small data sets, and memory-bound problems.</p></li>
</ul>
</div>
</section>
</section>
<span id="document-4-gpu-concepts"></span><section id="gpu-programming-concepts">
<span id="gpu-concepts"></span><h2>GPU programming concepts<a class="headerlink" href="#gpu-programming-concepts" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What types of parallel computing is possible?</p></li>
<li><p>How does data parallelism differ from task parallelism, and how are they utilized in parallel computing?</p></li>
<li><p>How is the work parallelized and executed on GPUs?</p></li>
<li><p>What are general considerations for an efficient code running on GPUs?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand parallel computing principles and architectures.</p></li>
<li><p>Differentiate data parallelism from task parallelism.</p></li>
<li><p>Learn the GPU execution model.</p></li>
<li><p>Parallelize and execute work on GPUs.</p></li>
<li><p>Develop efficient GPU code for high performance.</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>25 min teaching</p></li>
<li><p>0 min exercises</p></li>
</ul>
</div>
<section id="different-types-of-parallelism">
<h3>Different types of parallelism<a class="headerlink" href="#different-types-of-parallelism" title="Link to this heading"></a></h3>
<section id="distributed-vs-shared-memory-architecture">
<h4>Distributed- vs. Shared-Memory Architecture<a class="headerlink" href="#distributed-vs-shared-memory-architecture" title="Link to this heading"></a></h4>
<p>Most of computing problems are not trivially parallelizable, which means that the subtasks
need to have access from time to time to some of the results computed by other subtasks.
The way subtasks exchange needed information depends on the available hardware.</p>
<figure class="align-center" id="id4">
<img alt="_images/distributed_vs_shared.png" src="_images/distributed_vs_shared.png" />
<figcaption>
<p><span class="caption-text">Distributed- vs shared-memory parallel computing.</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>In a distributed memory environment each processing unit operates independently from the
others. It has its own memory and it  <strong>cannot</strong> access the memory in other nodes.
The communication is done via network and each computing unit runs a separate copy of the
operating system. In a shared memory machine all processing units have access to the memory
and can read or modify the variables within.</p>
</section>
<section id="processes-and-threads">
<h4>Processes and Threads<a class="headerlink" href="#processes-and-threads" title="Link to this heading"></a></h4>
<p>The type of environment (distributed- or shared-memory) determines the programming model.
There are two types of parallelism possible, process based and thread based.</p>
<figure class="align-center">
<img alt="_images/processes-threads.png" src="_images/processes-threads.png" />
</figure>
<p>For distributed memory machines, a process-based parallel programming model is employed.
The processes are independent execution units which have their <em>own memory</em> address spaces.
They are created when the parallel program is started and they are only terminated at the
end. The communication between them is done explicitly via message passing like MPI.</p>
<p>On the shared memory architectures it is possible to use a thread based parallelism.
The threads are light execution units and can be created and destroyed at a relatively
small cost. The threads have their own state information, but they <em>share</em> the <em>same memory</em>
address space. When needed the communication is done though the shared memory.</p>
<p>Both approaches have their advantages and disadvantages.  Distributed machines are
relatively cheap to build and they  have an “infinite “ capacity. In principle one could
add more and more computing units. In practice the more computing units are used the more
time consuming is the communication. The shared memory systems can achieve good performance
and the programming model is quite simple. However they are limited by the memory capacity
and by the access speed. In addition in the shared parallel model it is much easier to
create race conditions.</p>
</section>
</section>
<section id="exposing-parallelism">
<h3>Exposing parallelism<a class="headerlink" href="#exposing-parallelism" title="Link to this heading"></a></h3>
<p>There are two types of parallelism that can be explored.
The data parallelism is when the data can be distributed across computational units that can run in parallel.
The units process the data by applying the same or very similar operation to different data elements.
A common example is applying a blur filter to an image — the same function is applied to all the pixels on an image.
This parallelism is natural for the GPU, where the same instruction set is executed in multiple <abbr title="In OpenCL and SYCL: work-item.">threads</abbr>.</p>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="_images/ENCCS-OpenACC-CUDA_TaskParallelism_Explanation.png"><img alt="_images/ENCCS-OpenACC-CUDA_TaskParallelism_Explanation.png" src="_images/ENCCS-OpenACC-CUDA_TaskParallelism_Explanation.png" style="width: 715.2px; height: 265.6px;" />
</a>
<figcaption>
<p><span class="caption-text">Data parallelism and task parallelism.
The data parallelism is when the same operation applies to multiple data (e.g. multiple elements of an array are transformed).
The task parallelism implies that there are more than one independent task that, in principle, can be executed in parallel.</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Data parallelism can usually be explored by the GPUs quite easily.
The most basic approach would be finding a loop over many data elements and converting it into a GPU kernel.
If the number of elements in the data set is fairly large (tens or hundred of thousands elements), the GPU should perform quite well. Although it would be odd to expect absolute maximum performance from such a naive approach, it is often the one to take. Getting absolute maximum out of the data parallelism requires good understanding of how GPU works.</p>
<p>Another type of parallelism is a task parallelism.
This is when an application consists of more than one task that requiring to perform different operations with (the same or) different data.
An example of task parallelism is cooking: slicing vegetables and grilling are very different tasks and can be done at the same time.
Note that the tasks can consume totally different resources, which also can be explored.</p>
<div class="dropdown admonition">
<p class="admonition-title">In short</p>
<ul class="simple">
<li><p>Computing problems can be parallelized in distributed memory or shared memory architectures.</p></li>
<li><p>In distributed memory, each unit operates independently, with no direct memory access between nodes.</p></li>
<li><p>In shared memory, units have access to the same memory and can communicate through shared variables.</p></li>
<li><p>Parallel programming can be process-based (distributed memory) or thread-based (shared memory).</p></li>
<li><p>Process-based parallelism uses independent processes with separate memory spaces and explicit message passing.</p></li>
<li><p>Thread-based parallelism uses lightweight threads that share the same memory space and communicate through shared memory.</p></li>
<li><p>Data parallelism distributes data across computational units, processing them with the same or similar operations.</p></li>
<li><p>Task parallelism involves multiple independent tasks that perform different operations on the same or different data.</p></li>
<li><p>Task parallelism involves executing different tasks concurrently, leveraging different resources.</p></li>
</ul>
</div>
</section>
<section id="gpu-execution-model">
<h3>GPU Execution Model<a class="headerlink" href="#gpu-execution-model" title="Link to this heading"></a></h3>
<p>In order to obtain maximum performance it is important to understand how GPUs execute the programs. As mentioned before a CPU is a flexible device oriented towards general purpose usage. It’s fast and versatile, designed to run operating systems and various, very different types of applications. It has lots of features, such as better control logic, caches and cache coherence, that are not related to pure computing. CPUs optimize the execution by trying to achieve low latency via heavy caching and branch prediction.</p>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="_images/cpu-gpu-highway.png"><img alt="_images/cpu-gpu-highway.png" src="_images/cpu-gpu-highway.png" style="width: 768.0px; height: 432.0px;" />
</a>
<figcaption>
<p><span class="caption-text">Cars and roads analogy for the CPU and GPU behavior. The compact road is analogous to the CPU
(low latency, low throughput) and the broader road is analogous to the GPU (high latency, high throughput).</span><a class="headerlink" href="#id6" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>In contrast the GPUs contain a relatively small amount of transistors dedicated to control and caching, and a much larger fraction of transistors dedicated to the mathematical operations. Since the cores in a GPU are designed just for 3D graphics, they can be made much simpler and there can be a very larger number of cores. The current GPUs contain thousands of CUDA cores. Performance in GPUs is obtain by having a very high degree of parallelism. Lots of threads are launched in parallel. For good performance there should be at least several times more than the number of CUDA cores. GPU <abbr title="In OpenCL and SYCL: work-item.">threads</abbr> are much lighter than the usual CPU threads and they have very little penalty for context switching. This way when some threads are performing some memory operations (reading or writing) others execute instructions.</p>
</section>
<section id="cuda-threads-warps-blocks">
<h3>CUDA Threads, Warps, Blocks<a class="headerlink" href="#cuda-threads-warps-blocks" title="Link to this heading"></a></h3>
<p>In order to understand the GPU execution model let’s look at the so called <cite>axpy</cite> operation. On a single CPU core this operation would be executed in a serial manner in a <cite>for/do</cite> loop going over each element on the array, <cite>id</cite>, and computing <cite>y[id]=y[id]+a*x[id]</cite>.</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">axpy_</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">id</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">id</span><span class="o">&lt;</span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">id</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">y</span><span class="p">[</span><span class="n">id</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">id</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In order to perform the some operation on a GPU the program launches a function called <em>kernel</em>, which is executed simultaneously by tens of thousands of <abbr title="In OpenCL and SYCL: work-item.">threads</abbr> that can be run on GPU cores parallelly.</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">GPU_K</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ker_axpy_</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">id</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">id</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">id</span><span class="p">];</span><span class="w"> </span><span class="c1">// id&lt;n</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The programmers control how many instances of <cite>ker_axpy_</cite> are created and they have to make sure that all the elements are processed and also that no out of bounds accessed are happening.</p>
<p>GPU threads are much lighter than the usual CPU threads and they have very little penalty for context switching. By “over-subscribing” the GPU there are threads that are performing some memory operations (reading or writing), while others execute instructions.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/THREAD_CORE.png"><img alt="_images/THREAD_CORE.png" src="_images/THREAD_CORE.png" style="width: 638.8000000000001px; height: 265.6px;" />
</a>
</figure>
<p>Every <abbr title="In OpenCL and SYCL: work-item.">thread</abbr> is associated with a particular intrinsic index which can be used to calculate and access  memory locations in an array. Each thread has its context and set of private variables. All threads have access to the global GPU memory, but there is no general way to synchronize when executing a kernel. If some threads need data from the global memory which was modified by other threads the code would have to be split in several kernels because only at the completion of a kernel it is ensured that the writing to the global memory was completed.</p>
<p>Apart from being much light weighted there are more differences between GPU threads and CPU threads. GPU <abbr title="In OpenCL and SYCL: work-item.">threads</abbr> are grouped together in groups called <abbr title="In HIP: wavefront. In OpenCL and SYCL: sub-group.">warps</abbr>. This done at hardware level.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/WARP_SMTU.png"><img alt="_images/WARP_SMTU.png" src="_images/WARP_SMTU.png" style="width: 548.8000000000001px; height: 435.6px;" />
</a>
</figure>
<p>All memory accesses to the GPU memory are as a group in blocks of specific sizes (32B, 64B, 128B etc.). To obtain good performance the CUDA threads in the same warp need to access elements of the data which are adjacent in the memory. This is called <em>coalesced</em> memory access.</p>
<p>On some architectures, all members of a <abbr title="In HIP: wavefront. In OpenCL and SYCL: sub-group.">warp</abbr> have to execute the
same instruction, the so-called “lock-step” execution. This is done to achieve
higher performance, but there are some drawbacks. If an <strong>if</strong> statement
is present inside a <abbr title="In HIP: wavefront. In OpenCL and SYCL: sub-group.">warp</abbr> will cause the warp to be executed more than once,
one time for each branch. When different threads within a single <abbr title="In HIP: wavefront. In OpenCL and SYCL: sub-group.">warp</abbr>
take different execution paths based on a conditional statement (if), both
branches are executed sequentially, with some threads being active while
others are inactive. On architectures without lock-step execution, such
as NVIDIA Volta / Turing (e.g., GeForce 16xx-series) or newer, <abbr title="In HIP: wavefront. In OpenCL and SYCL: sub-group.">warp</abbr>
divergence is less costly.</p>
<p>There is another level in the GPU <abbr title="In OpenCL and SYCL: work-item.">threads</abbr> hierarchy. The <abbr title="In OpenCL and SYCL: work-item.">threads</abbr> are grouped together in so called <abbr title="In OpenCL and SYCL: work-group.">blocks</abbr>. Each block is assigned to one Streaming Multiprocessor (SMP) unit. A SMP contains one or more SIMT (single instruction multiple threads) units, schedulers, and very fast on-chip memory. Some of this on-chip memory can be used in the programs, this is called <abbr title="In OpenCL and SYCL: local memory (not to be confused with CUDA and HIP local memory).">shared memory</abbr>. The shared memory can be used to “cache” data that is used by more than one thread, thus avoiding multiple reads from the global memory. It can also be used to avoid memory accesses which are not efficient. For example in a matrix transpose operation, we have two memory operations per element and only can be coalesced. In the first step a tile of the matrix is saved read a coalesced manner in the shared memory. After all the reads of the block are done the tile can be locally transposed (which is very fast) and then written to the destination matrix in a coalesced manner as well. Shared memory can also be used to perform block-level reductions and similar collective operations. All threads can be synchronized at block level. Furthermore when the shared memory is written in order to ensure that all threads have completed the operation the synchronization is compulsory to ensure correctness of the program.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/BLOCK_SMP.png"><img alt="_images/BLOCK_SMP.png" src="_images/BLOCK_SMP.png" style="width: 550.8000000000001px; height: 430.0px;" />
</a>
</figure>
<p>Finally, a block of threads can not be split among SMPs. For performance blocks should have more than one <abbr title="In HIP: wavefront. In OpenCL and SYCL: sub-group.">warp</abbr>. The more warps are active on an SMP the better is hidden the latency associated with the memory operations. If the resources are sufficient, due to fast context switching, an SMP can have more than one block active in the same time. However these blocks can not share data with each other via the on-chip memory.</p>
<p>To summarize this section. In order to take advantage of GPUs the algorithms must allow the division of work in many small subtasks which can be executed in the same time. The computations are offloaded to GPUs, by launching tens of thousands of threads all executing the same function, <em>kernel</em>, each thread working on different part of the problem. The threads are executed in groups called <em>blocks</em>, each block being assigned to a SMP. Furthermore the threads of a block are divided in <em>warps</em>, each executed by SIMT unit. All threads in a warp execute the same instructions and all memory accesses are done collectively at warp level. The threads can synchronize and share data only at block level. Depending on the architecture, some data sharing can be done as well at warp level.</p>
<p>In order to hide latencies it is recommended to “over-subscribe” the GPU. There should be many more blocks than SMPs present on the device. Also in order to ensure a good occupancy of the CUDA cores there should be more warps active on a given SMP than SIMT units. This way while some warps of threads are idle waiting for some memory operations to complete, others use the CUDA cores, thus ensuring a high occupancy of the GPU.</p>
<p>In addition to this there are some architecture-specific features of which the developers can take advantage. <abbr title="In HIP: wavefront. In OpenCL and SYCL: sub-group.">Warp</abbr>-level operations are primitives provided by the GPU architecture to allow for efficient communication and synchronization within a warp. They allow <abbr title="In OpenCL and SYCL: work-item.">threads</abbr> within a warp to exchange data efficiently, without the need for explicit synchronization. These warp-level operations, combined with the organization of threads into blocks and clusters, make it possible to implement complex algorithms and achieve high performance on the GPU. The cooperative groups feature introduced in recent versions of CUDA provides even finer-grained control over thread execution, allowing for even more efficient processing by giving more flexibility to the thread hierarchy. Cooperative groups allow threads within a block to organize themselves into smaller groups, called cooperative groups, and to synchronize their execution and share data within the group.</p>
<p>Below there is an example of how the threads in a grid can be associated with specific elements of an array</p>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/Indexing.png"><img alt="_images/Indexing.png" src="_images/Indexing.png" style="width: 546.4px; height: 247.20000000000002px;" />
</a>
</figure>
<p>The thread marked by orange color is part of a grid of threads size 4096. The threads are grouped in blocks of size 256. The “orange” thread has index 3 in the block 2 and the global calculated index 515.</p>
<p>For a vector addition example this would be used as follow <code class="docutils literal notranslate"><span class="pre">c[index]=a[index]+b[index]</span></code>.</p>
<div class="dropdown admonition">
<p class="admonition-title">In short</p>
<ul class="simple">
<li><p>GPUs have a different execution model compared to CPUs, with a focus on parallelism and mathematical operations.</p></li>
<li><p>GPUs consist of thousands of lightweight threads that can be executed simultaneously on GPU cores.</p></li>
<li><p>Threads are organized into warps, and warps are grouped into blocks assigned to streaming multiprocessors (SMPs).</p></li>
<li><p>GPUs achieve performance through high degrees of parallelism and efficient memory access.</p></li>
<li><p>Shared memory can be used to cache data and improve memory access efficiency within a block.</p></li>
<li><p>Synchronization and data sharing are limited to the block level, with some possible sharing at the warp level depending on the architecture.</p></li>
<li><p>Over-subscribing the GPU and maximizing warp and block occupancy help hide latencies and improve performance.</p></li>
<li><p>Warp-level operations and cooperative groups provide efficient communication and synchronization within a warp or block.</p></li>
<li><p>Thread indexing allows associating threads with specific elements in an array for parallel processing.</p></li>
</ul>
</div>
</section>
<section id="terminology">
<h3>Terminology<a class="headerlink" href="#terminology" title="Link to this heading"></a></h3>
<p>At the moment there are three major GPU producers: NVIDIA, Intel, and AMD. While the basic concept behind GPUs is pretty similar they use different names for the various parts. Furthermore there are software environments for GPU programming, some from the producers and some from external groups all having different naming as well. Below there is a short compilation of the some terms used across different platforms and software environments.</p>
<table class="docutils align-center" id="id7">
<caption><span class="caption-text">Software mapping naming</span><a class="headerlink" href="#id7" title="Link to this table"></a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>CUDA</p></th>
<th class="head"><p>HIP</p></th>
<th class="head"><p>OpenCL</p></th>
<th class="head"><p>SYCL</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td colspan="2"><p>grid of threads</p></td>
<td colspan="2"><p>NDRange</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p>block</p></td>
<td colspan="2"><p>work-group</p></td>
</tr>
<tr class="row-even"><td><p>warp</p></td>
<td><p>wavefront</p></td>
<td colspan="2"><p>sub-group</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p>thread</p></td>
<td colspan="2"><p>work-item</p></td>
</tr>
<tr class="row-even"><td colspan="2"><p>registers</p></td>
<td colspan="2"><p>private memory</p></td>
</tr>
<tr class="row-odd"><td><p>shared memory</p></td>
<td><p>local data share</p></td>
<td colspan="2"><p>local memory</p></td>
</tr>
<tr class="row-even"><td colspan="2"><p>threadIdx.{x,y,z}</p></td>
<td><p>get_local_id({0,1,2})</p></td>
<td><p>nd_item::get_local({2,1,0}) <a class="footnote-reference brackets" href="#syclindex" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p>blockIdx.{x,y,z}</p></td>
<td><p>get_group_id({0,1,2})</p></td>
<td><p>nd_item::get_group({2,1,0}) <a class="footnote-reference brackets" href="#syclindex" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-even"><td colspan="2"><p>blockDim.{x,y,z}</p></td>
<td><p>get_local_size({0,1,2})</p></td>
<td><p>nd_item::get_local_range({2,1,0}) <a class="footnote-reference brackets" href="#syclindex" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
</tr>
</tbody>
</table>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="syclindex" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id2">2</a>,<a role="doc-backlink" href="#id3">3</a>)</span>
<p>In SYCL, the thread indexing is inverted. In a 3D grid, physically adjacent threads have consecutive X (0) index in CUDA, HIP, and OpenCL, but consecutive Z (2) index in SYCL.
In a 2D grid, CUDA, HIP, and OpenCL still has contiguous indexing along X (0) dimension, while in SYCL it is Y (1).
Same applies to block dimensions and indexing.</p>
</aside>
</aside>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-what-are-threads-in-the-context-of-shared-memory-architectures exercise important admonition" id="exercise-0">
<p class="admonition-title">What are threads in the context of shared memory architectures?</p>
<ol class="loweralpha simple">
<li><p>Independent execution units with their own memory address spaces</p></li>
<li><p>Light execution units with shared memory address spaces</p></li>
<li><p>Communication devices between separate memory units</p></li>
<li><p>Programming models for distributed memory machines</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<p>Correct answer:  <em>b) Light execution units with shared memory address spaces</em></p>
</div>
</div>
<div class="admonition-what-is-data-parallelism exercise important admonition" id="exercise-1">
<p class="admonition-title">What is data parallelism?</p>
<ol class="loweralpha simple">
<li><p>Distributing data across computational units that run in parallel, applying the same or similar operations to different data elements.</p></li>
<li><p>Distributing tasks across computational units that run in parallel, applying different operations to the same data elements.</p></li>
<li><p>Distributing data across computational units that run sequentially, applying the same operation to all data elements.</p></li>
<li><p>Distributing tasks across computational units that run sequentially, applying different operations to different data elements.</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<p>Correct answer: <em>a) Distributing data across computational units that run in parallel, applying the same or similar operations to different data elements.</em></p>
</div>
</div>
<div class="admonition-what-type-of-parallelism-is-natural-for-gpu exercise important admonition" id="exercise-2">
<p class="admonition-title">What type of parallelism is natural for GPU?</p>
<ol class="loweralpha simple">
<li><p>Task Parallelism</p></li>
<li><p>Data Parallelism</p></li>
<li><p>Both data and task parallelism</p></li>
<li><p>Neither data nor task parallelism</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-2">
<p class="admonition-title">Solution</p>
<p>Correct answer: <em>b) Data Parallelism</em></p>
</div>
</div>
<div class="admonition-what-is-a-kernel-in-the-context-of-gpu-execution exercise important admonition" id="exercise-3">
<p class="admonition-title">What is a kernel in the context of GPU execution?</p>
<ol class="loweralpha simple">
<li><p>A specific section of the CPU used for memory operations.</p></li>
<li><p>A specific section of the GPU used for memory operations.</p></li>
<li><p>A type of thread that operates on the GPU.</p></li>
<li><p>A function that is executed simultaneously by tens of thousands of threads on GPU cores.</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-3">
<p class="admonition-title">Solution</p>
<p>Correct answer: <em>d) A function that is executed simultaneously by tens of thousands of threads on GPU cores.</em></p>
</div>
</div>
<div class="admonition-what-is-coalesced-memory-access exercise important admonition" id="exercise-4">
<p class="admonition-title">What is coalesced memory access?</p>
<ol class="loweralpha simple">
<li><p>It’s when CUDA threads in the same warp access elements of the data which are adjacent in the memory.</p></li>
<li><p>It’s when CUDA threads in different warps access elements of the data which are far in the memory.</p></li>
<li><p>It’s when all threads have access to the global GPU memory.</p></li>
<li><p>It’s when threads in a warp perform different operations.</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-4">
<p class="admonition-title">Solution</p>
<p>Correct answer: <em>a) It’s when CUDA threads in the same warp access elements of the data which are adjacent in the memory.</em></p>
</div>
</div>
<div class="admonition-what-is-the-function-of-shared-memory-in-the-context-of-gpu-execution exercise important admonition" id="exercise-5">
<p class="admonition-title">What is the function of shared memory in the context of GPU execution?</p>
<ol class="loweralpha simple">
<li><p>It’s used to store global memory.</p></li>
<li><p>It’s used to store all the threads in a block.</p></li>
<li><p>It can be used to “cache” data that is used by more than one thread, avoiding multiple reads from the global memory.</p></li>
<li><p>It’s used to store all the CUDA cores.</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-5">
<p class="admonition-title">Solution</p>
<p>Correct answer: <em>c) It can be used to “cache” data that is used by more than one thread, avoiding multiple reads from the global memory.</em></p>
</div>
</div>
<div class="admonition-what-is-the-significance-of-over-subscribing-the-gpu exercise important admonition" id="exercise-6">
<p class="admonition-title">What is the significance of over-subscribing the GPU?</p>
<ol class="loweralpha simple">
<li><p>It reduces the overall performance of the GPU.</p></li>
<li><p>It ensures that there are more blocks than SMPs present on the device, helping to hide latencies and ensure high occupancy of the GPU.</p></li>
<li><p>It leads to a memory overflow in the GPU.</p></li>
<li><p>It ensures that there are more SMPs than blocks present on the device.</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-6">
<p class="admonition-title">Solution</p>
<p>Correct answer: <em>b) It ensures that there are more blocks than SMPs present on the device, helping to hide latencies and ensure high occupancy of the GPU.</em></p>
</div>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Parallel computing can be classified into distributed-memory and shared-memory architectures</p></li>
<li><p>Two types of parallelism that can be explored are data parallelism and task parallelism.</p></li>
<li><p>GPUs are a type of shared memory architecture suitable for data parallelism.</p></li>
<li><p>GPUs have high parallelism, with threads organized into warps and blocks and.</p></li>
<li><p>GPU optimization involves coalesced memory access, shared memory usage, and high thread and warp occupancy. Additionally, architecture-specific features such as warp-level operations and cooperative groups can be leveraged for more efficient processing.</p></li>
</ul>
</div>
</section>
</section>
<span id="document-5-intro-to-gpu-prog-models"></span><section id="introduction-to-gpu-programming-models">
<span id="intro-to-gpu-prog-models"></span><h2>Introduction to GPU programming models<a class="headerlink" href="#introduction-to-gpu-programming-models" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What are the key differences between different GPU programming approaches?</p></li>
<li><p>How should I choose which framework to use for my project?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand the  basic ideas in different GPU programming frameworks</p></li>
<li><p>Perform a quick cost-benefit analysis in the context of own code projects</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>20 min teaching</p></li>
<li><p>10 min discussion</p></li>
</ul>
</div>
<p>There are different ways to use GPUs for computations. In the best case, when the code has already been written, one only needs to set the parameters and initial configuration in order to get started. In some other cases the problem is posed in such a way that a third-party library can be used to solve the most intensive part of the code (for example, this is increasingly the case with machine-learning workflows in Python).
However, these cases are stil quite limited; in general, some additional programming might be needed. There are many GPU programming software environments and APIs available, which can be broadly grouped into <strong>directive-based models</strong>, <strong>non-portable kernel-based models</strong>, and <strong>portable kernel-based models</strong>, as well as high-level frameworks and libraries (including attempts at language-level support).</p>
<section id="standard-c-fortran">
<h3>Standard C++/Fortran<a class="headerlink" href="#standard-c-fortran" title="Link to this heading"></a></h3>
<p>Programs written in standard C++ and Fortran languages can now take advantage of NVIDIA GPUs without depending on any external library. This is possible thanks to the <a class="reference external" href="https://developer.nvidia.com/hpc-sdk">NVIDIA SDK</a> suite of compilers that translates and optimizes the code for running on GPUs.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://developer.nvidia.com/blog/developing-accelerated-code-with-standard-language-parallelism/">Here</a> is the series of articles on acceleration with standard language parallelism.</p></li>
<li><p>Guidelines for writing C++ code can be found <a class="reference external" href="https://developer.nvidia.com/blog/accelerating-standard-c-with-gpus-using-stdpar/">here</a>,</p></li>
<li><p>while those for Fortran code can be found <a class="reference external" href="https://developer.nvidia.com/blog/accelerating-fortran-do-concurrent-with-gpus-and-the-nvidia-hpc-sdk/">here</a>.</p></li>
</ul>
<p>The performance of these two approaches is promising, as can be seen in the examples provided in those guidelines.</p>
</section>
<section id="directive-based-programming">
<h3>Directive-based programming<a class="headerlink" href="#directive-based-programming" title="Link to this heading"></a></h3>
<p>A fast and cheap way is to use <strong>directive based</strong> approaches. In this case the existing <em>serial</em> code is annotated with <em>hints</em> which indicate to the compiler which loops and regions should be executed on the GPU. In the absence of the API the directives are treated as comments and the code will just be executed as a usual serial code. This approach is focused on productivity and easy usage (but to the possible detriment of performance), and allows employing accelerators with minimal programming effort by adding parallelism to existing code without the need to write accelerator-specific code. There are two common ways to program using directives, namely <strong>OpenACC</strong> and <strong>OpenMP</strong>.</p>
<section id="openacc">
<h4>OpenACC<a class="headerlink" href="#openacc" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://www.openacc.org/">OpenACC</a> is developed by a consortium formed in 2010 with the goal of developing a standard, portable, and scalable programming model for accelerators, including GPUs. Members of the OpenACC consortium include GPU vendors, such as NVIDIA and AMD, as well as leading supercomputing centers, universities, and software companies. Until recently it was supporting only NVIDIA GPUs, but now there is effort to support more devices and architectures.</p>
</section>
<section id="openmp">
<h4>OpenMP<a class="headerlink" href="#openmp" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://www.openmp.org/">OpenMP</a> started as a multi-platform, shared-memory parallel programming API for multi-core CPUs and relatively recently has added support for GPU offloading. OpenMP aims to support various types of GPUs, which is done through the parent compiler.</p>
<p>The directive based approaches work with C/C++ and FORTRAN codes, while some third party extensions are available for other languages.</p>
</section>
</section>
<section id="non-portable-kernel-based-models-native-programming-models">
<h3>Non-portable kernel-based models (native programming models)<a class="headerlink" href="#non-portable-kernel-based-models-native-programming-models" title="Link to this heading"></a></h3>
<p>When doing direct GPU programming the developer has a large level of control by writing low-level code that directly communicates with the GPU and its hardware. Theoretically direct GPU programming methods provide the ability to write low-level, GPU-accelerated code that can provide significant performance improvements over CPU-only code. However, they also require a deeper understanding of the GPU architecture and its capabilities, as well as the specific programming method being used.</p>
<section id="cuda">
<h4>CUDA<a class="headerlink" href="#cuda" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://developer.nvidia.com/cuda-toolkit">CUDA</a> is a parallel computing platform and API developed by NVIDIA. It is historically the first mainstream GPU programming framework. It allows developers to write C-like code that is executed on the GPU. CUDA provides a set of libraries and tools for low-level GPU programming and provides a performance boost for demanding computationally-intensive applications. While there is an extensive ecosystem, CUDA is restricted to NVIDIA hardware.</p>
</section>
<section id="hip">
<h4>HIP<a class="headerlink" href="#hip" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://rocm.docs.amd.com/projects/HIP/en/latest/what_is_hip.html">HIP</a> (Heterogeneous Interface for Portability) is an API developed by AMD that provides a low-level interface for GPU programming. HIP is designed to provide a single source code that can be used on both NVIDIA and AMD GPUs. It is based on the CUDA programming model and provides an almost identical programming interface to CUDA.</p>
<p>Multiple examples of CUDA/HIP code are available in the <a class="reference external" href="https://github.com/ENCCS/gpu-programming/tree/main/content/examples/cuda-hip">content/examples/cuda-hip</a> directory of this repository.</p>
</section>
</section>
<section id="portable-kernel-based-models-cross-platform-portability-ecosystems">
<h3>Portable kernel-based models (cross-platform portability ecosystems)<a class="headerlink" href="#portable-kernel-based-models-cross-platform-portability-ecosystems" title="Link to this heading"></a></h3>
<p>Cross-platform portability ecosystems typically provide a higher-level abstraction layer which enables a convenient and portable programming model for GPU programming. They can help reduce the time and effort required to maintain and deploy GPU-accelerated applications. The goal of these ecosystems is to achieve performance portability with a single-source application. In C++, the most notable cross-platform portability ecosystems are <a class="reference external" href="https://www.khronos.org/sycl/">SYCL</a>, <a class="reference external" href="https://www.khronos.org/opencl/">OpenCL</a> (C and C++ APIs), and <a class="reference external" href="https://github.com/kokkos/kokkos">Kokkos</a>; others include <a class="reference external" href="https://alpaka.readthedocs.io/">alpaka</a> and <a class="reference external" href="https://github.com/LLNL/RAJA">RAJA</a>.</p>
<section id="id5">
<h4>OpenCL<a class="headerlink" href="#id5" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://www.khronos.org/opencl/">OpenCL</a> (Open Computing Language) is a cross-platform, open-standard API for general-purpose parallel computing on CPUs, GPUs and FPGAs. It supports a wide range of hardware from multiple vendors. OpenCL provides a low-level programming interface for GPU programming and enables developers to write programs that can be executed on a variety of platforms. Unlike programming models such as CUDA, HIP, Kokkos, and SYCL, OpenCL uses a separate-source model. Recent versions of the OpenCL standard added C++ support for both API and the kernel code, but the C-based interface is still more widely used.
The OpenCL Working Group doesn’t provide any frameworks of its own. Instead, vendors who produce OpenCL-compliant devices release frameworks as part of their software development kits (SDKs). The two most popular OpenCL SDKs are released by NVIDIA and AMD. In both cases, the development kits are free and contain the libraries and tools that make it possible to build OpenCL applications.</p>
</section>
<section id="id7">
<h4>Kokkos<a class="headerlink" href="#id7" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://github.com/kokkos/kokkos">Kokkos</a> is an open-source performance portable programming model for heterogeneous parallel computing that has been mainly developed at Sandia National Laboratories. It is a C++-based ecosystem that provides a programming model for developing efficient and scalable parallel applications that run on many-core architectures such as CPUs, GPUs, and FPGAs. The Kokkos ecosystem consists of several components, such as the Kokkos core library, which provides parallel execution and memory abstraction, the Kokkos kernel library, which provides math kernels for linear algebra and graph algorithms, and the Kokkos tools library, which provides profiling and debugging tools. Kokkos components integrate well with other software libraries and technologies, such as MPI and OpenMP. Furthermore, the project collaborates with other projects, in order to provide interoperability and standardization for portable C++ programming.</p>
</section>
<section id="id9">
<h4>alpaka<a class="headerlink" href="#id9" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://alpaka.readthedocs.io/">alpaka</a> (Abstraction Library for Parallel Kernel Acceleration) is an open-source C++ header-only library that aims to provide performance portability across heterogeneous accelerator architectures by abstracting the underlying levels of parallelism. The library is platform-independent and supports the concurrent and cooperative use of multiple devices, including host CPUs (x86, ARM, RISC-V) and GPUs from different vendors (NVIDIA, AMD, and Intel).</p>
<p>A key advantage of alpaka is that it requires only a single implementation of a user kernel, expressed as a function object with a standardized interface. This eliminates the need to write specialized code for different backends. The library provides a variety of accelerator backends, including CUDA, HIP, SYCL, OpenMP, and serial execution, that can be selected based on the target device. Moreover, multiple accelerator backends can even be combined to target different vendor hardware within a single application.</p>
</section>
<section id="id11">
<h4>SYCL<a class="headerlink" href="#id11" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://www.khronos.org/sycl/">SYCL</a> is a royalty-free, open-standard C++ programming model for multi-device programming. It provides a high-level, single-source programming model for heterogeneous systems, including GPUs. Originally SYCL was developed on top of OpenCL; however, it is no more limited to just that. It can be implemented on top of other low-level heterogeneous computing APIs, such as CUDA or HIP, enabling developers to write programs that can be executed on a variety of platforms. Note that while SYCL is relatively high-level model, the developers are still required to write GPU kernels explicitly.</p>
<p>While alpaka, Kokkos, and RAJA refer to specific projects, SYCL itself is only a standard, for which several implementations exist. For GPU programming, <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html">Intel oneAPI DPC++</a> (supporting Intel GPUs natively, and NVIDIA and AMD GPUs with <a class="reference external" href="https://codeplay.com/solutions/oneapi/">Codeplay oneAPI plugins</a>) and <a class="reference external" href="https://github.com/AdaptiveCpp/AdaptiveCpp/">AdaptiveCpp</a> (previously also known as hipSYCL or Open SYCL, supporting NVIDIA and AMD GPUs, with experimental Intel GPU support available in combination with Intel oneAPI DPC++) are the most widely used. Other implementations of note are <a class="reference external" href="https://github.com/triSYCL/triSYCL">triSYCL</a> and <a class="reference external" href="https://developer.codeplay.com/products/computecpp/ce/home/">ComputeCPP</a>.</p>
</section>
</section>
<section id="high-level-language-support">
<h3>High-level language support<a class="headerlink" href="#high-level-language-support" title="Link to this heading"></a></h3>
<section id="python">
<h4>Python<a class="headerlink" href="#python" title="Link to this heading"></a></h4>
<p>Python offers support for GPU programming through multiple abstraction levels.</p>
<p><strong>CUDA Python, HIP Python and PyCUDA</strong></p>
<p>These projects are, respectively, <a class="reference external" href="https://developer.nvidia.com/cuda-python">NVIDIA-</a>, <a class="reference external" href="https://rocm.docs.amd.com/projects/hip-python/en/latest/">AMD-</a>
and <a class="reference external" href="https://documen.tician.de/pycuda/">community-supported</a> wrappers providing Python bindings to the low-level CUDA and HIP APIs. To use these approaches directly, in most cases knowledge of CUDA or HIP programming is needed.</p>
<p>CUDA Python also aims to support higher-level toolkits and libraries, such as <strong>CuPy</strong> and <strong>Numba</strong>.</p>
<p><strong>CuPy</strong></p>
<p><a class="reference external" href="https://cupy.dev/">CuPy</a> is a GPU-based data array library compatible with NumPy/SciPy. It offers a highly similar interface to NumPy and SciPy, making it easy for developers to transition to GPU computing. Code written with NumPy can often be adapted to use CuPy with minimal modifications; in most straightforward cases, one might simply replace ‘numpy’ and ‘scipy’ with ‘cupy’ and ‘cupyx.scipy’ in their Python code.</p>
<p><strong>Numba</strong></p>
<p><a class="reference external" href="https://numba.pydata.org/">Numba</a> is an open-source JIT compiler that translates a subset of Python and NumPy code into optimized machine code. Numba supports CUDA-capable GPUs and is able to generate code for them using several different syntax variants.
In 2021, upstream support for <a class="reference external" href="https://numba.readthedocs.io/en/stable/release-notes.html#version-0-54-0-19-august-2021">AMD (ROCm) support</a> was discontinued.
However, as of 2025, AMD has added downstream support for the Numba API through the
<a class="reference external" href="https://github.com/ROCm/numba-hip">Numba HIP package</a>.</p>
</section>
<section id="julia">
<h4>Julia<a class="headerlink" href="#julia" title="Link to this heading"></a></h4>
<p>Julia has first-class support for GPU programming through the following packages that target GPUs from all three major vendors:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://cuda.juliagpu.org/stable/">CUDA.jl</a> for NVIDIA GPUs</p></li>
<li><p><a class="reference external" href="https://amdgpu.juliagpu.org/stable/">AMDGPU.jl</a> for AMD GPUs</p></li>
<li><p><a class="reference external" href="https://github.com/JuliaGPU/oneAPI.jl">oneAPI.jl</a> for Intel GPUs</p></li>
<li><p><a class="reference external" href="https://github.com/JuliaGPU/Metal.jl">Metal.jl</a> for Apple M-series GPUs</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">CUDA.jl</span></code> is the most mature, <code class="docutils literal notranslate"><span class="pre">AMDGPU.jl</span></code> is somewhat behind but still ready for general use, while <code class="docutils literal notranslate"><span class="pre">oneAPI.jl</span></code> and <code class="docutils literal notranslate"><span class="pre">Metal.jl</span></code> are functional but might contain bugs, miss some features and provide suboptimal performance. Their respective APIs are however completely analogous and translation between libraries is straightforward.</p>
<p>All packages offer both high-level abstractions that require very little programming effort and a lower level approach for writing kernels for fine-grained control.</p>
<div class="dropdown admonition">
<p class="admonition-title">In short</p>
<ul class="simple">
<li><p><strong>Directive-based programming:</strong></p>
<ul>
<li><p>Existing serial code is annotated with directives to indicate which parts should be executed on the GPU.</p></li>
<li><p>OpenACC and OpenMP are common directive-based programming models.</p></li>
<li><p>Productivity and easy usage are prioritized over performance.</p></li>
<li><p>Minimum programming effort is required to add parallelism to existing code.</p></li>
</ul>
</li>
<li><p><strong>Non-portable kernel-based models:</strong></p>
<ul>
<li><p>Low-level code is written to directly communicate with the GPU.</p></li>
<li><p>CUDA is NVIDIA’s parallel computing platform and API for GPU programming.</p></li>
<li><p>HIP is an API developed by AMD that provides a similar programming interface to CUDA for both NVIDIA and AMD GPUs.</p></li>
<li><p>Deeper understanding of GPU architecture and programming methods is needed.</p></li>
</ul>
</li>
<li><p><strong>Portable kernel-based models:</strong></p>
<ul>
<li><p>Higher-level abstractions for GPU programming that provide portability.</p></li>
<li><p>Examples include OpenCL, Kokkos, alpaka, RAJA, and SYCL.</p></li>
<li><p>Aim to achieve performance portability with a single-source application.</p></li>
<li><p>Can run on various GPUs and platforms, reducing the effort required to maintain and deploy GPU-accelerated applications.</p></li>
</ul>
</li>
<li><p><strong>High-level language support:</strong></p>
<ul>
<li><p>C++ and Fortran feature initiatives to support GPUs through language-standard parallelism.</p></li>
<li><p>Python libraries like PyCUDA, CuPy, and Numba offer GPU programming capabilities.</p></li>
<li><p>Julia has packages such as CUDA.jl, AMDGPU.jl, oneAPI.jl, and Metal.jl for GPU programming.</p></li>
<li><p>These approaches provide high-level abstraction and interfaces for GPU programming in the respective languages.</p></li>
</ul>
</li>
</ul>
</div>
</section>
</section>
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h3>
<p>Each of these GPU programming environments has its own strengths and weaknesses, and the best choice for a given project will depend on a range of factors, including:</p>
<ul class="simple">
<li><p>the hardware platforms being targeted,</p></li>
<li><p>the type of computation being performed, and</p></li>
<li><p>the developer’s experience and preferences.</p></li>
</ul>
<p><strong>High-level and productivity-focused APIs</strong> provide a simplified programming model and maximize code portability, while <strong>low-level and performance-focused APIs</strong> provide a high level of control over the GPU’s hardware but also require more coding effort and expertise.</p>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-discussion exercise important admonition" id="exercise-0">
<p class="admonition-title">Discussion</p>
<ul class="simple">
<li><p>Which GPU programming frameworks have you already used previously, if any?</p></li>
<li><p>What did you find most challenging? What was most useful?</p></li>
</ul>
<p>Let us know in the main room or via comments in HackMD document.</p>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>GPU programming approaches can be split into 1) directive-based, 2) non-portable kernel-based, 3) portable kernel-based, and 4) high-level language support.</p></li>
<li><p>There are multiple frameworks/languages available for each approach, each with pros and cons.</p></li>
</ul>
</div>
</section>
</section>
<span id="document-6-directive-based-models"></span><section id="directive-based-models">
<span id="id1"></span><h2>Directive-based models<a class="headerlink" href="#directive-based-models" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What is OpenACC and OpenMP offloading</p></li>
<li><p>How to write GPU code using directives</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand the process of offloading</p></li>
<li><p>Understand the differences between OpenACC and OpenMP offloading</p></li>
<li><p>Understand the various levels of parallelism on a GPU</p></li>
<li><p>Understand what is data movement</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>40 min teaching</p></li>
<li><p>40 min exercises</p></li>
</ul>
</div>
<p>The most common directive-based models for GPU parallel programming are OpenMP offloading and OpenACC.
The parallelization is done by introducing directives in places which are targeted for parallelization.</p>
<ul class="simple">
<li><p><strong>OpenACC</strong> is known to be more <strong>descriptive</strong>, which means the programmer uses directives to tell the compiler how/where to parallelize the code and to move the data.</p></li>
<li><p><strong>OpenMP offloading</strong>, on the other hand, is known to be more <strong>prescriptive</strong>, where the programmer uses directives to tell the compiler more explicitly how/where to parallelize the code, instead of letting the compiler decide.</p></li>
</ul>
<p>In OpenMP/OpenACC the compiler directives are specified by using <strong>#pragma</strong> in C/C++ or as special comments identified by unique sentinels in Fortran. Compilers can ignore the directives if the support for OpenMP/OpenACC is not enabled.</p>
<p>The compiler directives are used for various purposes: for thread creation, workload
distribution (work sharing), data-environment management, serializing sections of code or
for synchronization of work among the threads.</p>
<section id="execution-model">
<h3>Execution model<a class="headerlink" href="#execution-model" title="Link to this heading"></a></h3>
<p>OpenMP and OpenACC use the fork-join model of parallel execution. The program begins as a single
thread of execution, the <strong>master</strong> thread. Everything is executed sequentially until the
first parallel region construct is encountered.</p>
<figure class="align-center">
<img alt="_images/threads.png" src="_images/threads.png" />
</figure>
<p>When a parallel region is encountered, the master thread creates a group of threads,
becomes the master of this group of threads, and is assigned the thread index 0 within
the group. There is an implicit barrier at the end of the parallel regions.</p>
</section>
<section id="offloading-directives">
<h3>Offloading Directives<a class="headerlink" href="#offloading-directives" title="Link to this heading"></a></h3>
<section id="openacc">
<h4>OpenACC<a class="headerlink" href="#openacc" title="Link to this heading"></a></h4>
<p>In OpenACC, one of the most commonly used directives is <code class="docutils literal notranslate"><span class="pre">kernels</span></code>,
which defines a region to be transferred into a series of kernels to be executed in sequence on a GPU.
Work sharing is defined automatically for the separate kernels, but tuning prospects are limited.</p>
<div class="admonition-example-kernels exercise important admonition" id="exercise-0">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">kernels</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;openacc.h&gt;</span>

<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>

<span class="w">    </span><span class="cm">/* Initialization of the vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="hll"><span class="w">    </span><span class="cp">#pragma acc kernels</span>
</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">main</span>
<span class="w">  </span><span class="k">implicit none</span>

<span class="k">  </span><span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="w">  </span><span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="w">  </span><span class="kt">double precision</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="w"> </span><span class="n">vecC</span><span class="p">(</span><span class="n">nx</span><span class="p">)</span>

<span class="w">  </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">     </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">     </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">  </span><span class="k">end do</span>

<span class="hll"><span class="w">  </span><span class="c">!$acc kernels</span>
</span><span class="w">  </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">    </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">  </span><span class="k">end do</span>
<span class="hll"><span class="w">  </span><span class="c">!$acc end kernels</span>
</span>
<span class="k">end program</span>
</pre></div>
</div>
</div></div>
</div>
<p>The other approach of OpenACC to define parallel regions is to use the <code class="docutils literal notranslate"><span class="pre">parallel</span></code> directive.
Contrary to the <code class="docutils literal notranslate"><span class="pre">kernels</span></code> directive, the <code class="docutils literal notranslate"><span class="pre">parallel</span></code> directive is more explicit and requires
more analysis by the programmer. Work sharing has to be defined manually using the <code class="docutils literal notranslate"><span class="pre">loop</span></code> directive,
and refined tuning is possible to achieve. The above example can be re-written as the following:</p>
<div class="admonition-example-parallel-loop exercise important admonition" id="exercise-1">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">parallel</span> <span class="pre">loop</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;openacc.h&gt;</span>

<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>

<span class="w">    </span><span class="cm">/* Initialization of the vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="hll"><span class="w">    </span><span class="cp">#pragma acc parallel loop</span>
</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">main</span>
<span class="w">  </span><span class="k">implicit none</span>

<span class="k">  </span><span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="w">  </span><span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="w">  </span><span class="kt">double precision</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="w"> </span><span class="n">vecC</span><span class="p">(</span><span class="n">nx</span><span class="p">)</span>

<span class="w">  </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">     </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">     </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">  </span><span class="k">end do</span>

<span class="hll"><span class="w">  </span><span class="c">!$acc parallel loop</span>
</span><span class="w">  </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">    </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">  </span><span class="k">end do</span>
<span class="hll"><span class="w">  </span><span class="c">!$acc end parallel loop</span>
</span>
<span class="k">end program</span>
</pre></div>
</div>
</div></div>
</div>
<p>Sometimes we can obtain a little more performance by guiding the compiler to make specific choices.
OpenACC has four levels of parallelism for offloading execution:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>gang</strong> coarse grain: the iterations are distributed among the gangs</p></li>
<li><p><strong>worker</strong> fine grain: worker’s threads are activated within gangs and iterations are shared among the threads</p></li>
<li><p><strong>vector</strong> each worker activates its threads working in SIMT fashion and the work is shared among the threads</p></li>
<li><p><strong>seq</strong> the iterations are executed sequentially</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">gang</span></code>, <code class="docutils literal notranslate"><span class="pre">worker</span></code> and <code class="docutils literal notranslate"><span class="pre">vector</span></code> parallelism are automatically decided and applied by the compiler.</p>
<p>The programmer could add clauses like <code class="docutils literal notranslate"><span class="pre">num_gangs</span></code>, <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> and <code class="docutils literal notranslate"><span class="pre">vector_length</span></code> within the parallel region to specify the number of gangs, workers and vector length.</p>
<p>The optimal numbers are highly dependent on the GPU architecture and the compiler implementation though.</p>
<p>There is no thread synchronization at <code class="docutils literal notranslate"><span class="pre">gang</span></code> level, which means there is a risk of race condition.</p>
</div>
</section>
<section id="openmp-offloading">
<h4>OpenMP Offloading<a class="headerlink" href="#openmp-offloading" title="Link to this heading"></a></h4>
<p>With OpenMP, the <code class="docutils literal notranslate"><span class="pre">target</span></code> directive is used for device offloading.</p>
<div class="admonition-example-target-construct exercise important admonition" id="exercise-2">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">target</span></code> construct</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>

<span class="w">    </span><span class="cm">/* Initialization of the vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="hll"><span class="w">    </span><span class="cp">#pragma omp target</span>
</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">main</span>
<span class="w">  </span><span class="k">implicit none</span>

<span class="k">  </span><span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="w">  </span><span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="w">  </span><span class="kt">double precision</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="w"> </span><span class="n">vecC</span><span class="p">(</span><span class="n">nx</span><span class="p">)</span>

<span class="w">  </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">     </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">     </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">  </span><span class="k">end do</span>

<span class="hll"><span class="w">  </span><span class="c">!$omp target</span>
</span><span class="w">  </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">    </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">  </span><span class="k">end do</span>
<span class="hll"><span class="w">  </span><span class="c">!$omp end target</span>
</span>
<span class="k">end program</span>
</pre></div>
</div>
</div></div>
</div>
<p>Compared to the OpenACC’s <code class="docutils literal notranslate"><span class="pre">kernels</span></code> directive, the <code class="docutils literal notranslate"><span class="pre">target</span></code> directive will not parallelise the underlying loop at all.
To achieve proper parallelisation, one needs to be more prescriptive and specify what one wants.
OpenMP offloading offers multiple levels of parallelism as well:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>teams</strong> coarse grain: creates a league of teams and one master thread in each team, but no worksharing among the teams</p></li>
<li><p><strong>distribute</strong> distributes the iterations across the master threads in the teams, but no worksharing among the threads within one team</p></li>
<li><p><strong>parallel do/for</strong> fine grain: threads are activated within one team and worksharing among them</p></li>
<li><p><strong>SIMD</strong> like the <code class="docutils literal notranslate"><span class="pre">vector</span></code> directive in OpenACC</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The programmer can add clauses like <code class="docutils literal notranslate"><span class="pre">num_teams</span></code> and <code class="docutils literal notranslate"><span class="pre">thread_limit</span></code> to specify the number of teams and threads within a team.</p>
<p>Threads in a team can synchronize but no synchronization among the teams.</p>
<p>Since OpenMP 5.0, there is a new <code class="docutils literal notranslate"><span class="pre">loop</span></code> directive available, which has a functionality similar to the corresponding one in OpenACC.</p>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<table class="docutils align-default" id="id2">
<caption><span class="caption-text">Mapping between OpenACC/OpenMP directives and GPU (<strong>HPE implementation</strong>)</span><a class="headerlink" href="#id2" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Nvidia</p></th>
<th class="head"><p>AMD</p></th>
<th class="head"><p>Fortran OpenACC/OpenMP</p></th>
<th class="head"><p>C/C++ OpenMP</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Threadblock</p></td>
<td><p>Work group</p></td>
<td><p>gang/teams</p></td>
<td><p>teams</p></td>
</tr>
<tr class="row-odd"><td><p>Warp</p></td>
<td><p>Wavefront</p></td>
<td><p>worker/simd</p></td>
<td><p>parallel for simd</p></td>
</tr>
<tr class="row-even"><td><p>Thread</p></td>
<td><p>Work item</p></td>
<td><p>vector/simd</p></td>
<td><p>parallel for simd</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>Each compiler supports different levels of parallelism.</p></li>
<li><p>The size of gang/team/worker/vector_length can be chosen arbitrarily by the user but there are limits defined by the implementation.</p></li>
<li><p>The maximum thread/grid/block size can be found via <code class="docutils literal notranslate"><span class="pre">rocminfo</span></code>/<code class="docutils literal notranslate"><span class="pre">nvaccelinfo</span></code>.</p></li>
</ul>
</div>
<div class="admonition-exercise-change-the-levels-of-parallelism exercise important admonition" id="exercise-3">
<p class="admonition-title">Exercise: Change the levels of parallelism</p>
<p>In this exercise we would like to change the levels of parallelism using clauses.
First compile and run one of the examples to find out the default number of blocks and threads set by the compiler at runtime.
To make a change, try adding clauses like <code class="docutils literal notranslate"><span class="pre">num_gangs</span></code>, <code class="docutils literal notranslate"><span class="pre">num_workers</span></code>,  <code class="docutils literal notranslate"><span class="pre">vector_length</span></code> for OpenACC
and <code class="docutils literal notranslate"><span class="pre">num_teams</span></code>, <code class="docutils literal notranslate"><span class="pre">thread_limit</span></code> for OpenMP offloading.</p>
<p>Remember to set the environment by executing <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">CRAY_ACC_DEBUG=2</span></code> at runtime.</p>
<p>How to compile and run the code interactively:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>salloc<span class="w"> </span>-A<span class="w"> </span>project_465002387<span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>-t<span class="w"> </span><span class="m">1</span>:00:00<span class="w"> </span>-p<span class="w"> </span>standard-g<span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">1</span>

module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03
module<span class="w"> </span>load<span class="w"> </span>partition/G
module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3

<span class="c1"># OpenMP</span>
cc<span class="w"> </span>-O2<span class="w"> </span>-fopenmp<span class="w"> </span>-o<span class="w"> </span>ex1<span class="w"> </span>ex1.c
<span class="c1"># Only OpenACC Fortran is supported by HPE compiler.</span>

<span class="nb">export</span><span class="w"> </span><span class="nv">CRAY_ACC_DEBUG</span><span class="o">=</span><span class="m">2</span>
srun<span class="w"> </span>./ex1
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>salloc<span class="w"> </span>-A<span class="w"> </span>project_465002387<span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>-t<span class="w"> </span><span class="m">1</span>:00:00<span class="w"> </span>-p<span class="w"> </span>standard-g<span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">1</span>

module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03
module<span class="w"> </span>load<span class="w"> </span>partition/G
module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3

<span class="nb">export</span><span class="w"> </span><span class="nv">CRAY_ACC_DEBUG</span><span class="o">=</span><span class="m">2</span>
<span class="c1"># OpenMP</span>
ftn<span class="w"> </span>-O2<span class="w"> </span>-homp<span class="w"> </span>-o<span class="w"> </span>ex1<span class="w"> </span>ex1.f90
srun<span class="w"> </span>./ex1

<span class="c1"># OpenACC</span>
ftn<span class="w"> </span>-O2<span class="w"> </span>-hacc<span class="w"> </span>-o<span class="w"> </span>ex1<span class="w"> </span>ex1.f90
srun<span class="w"> </span>./ex1
</pre></div>
</div>
</div></div>
<p>Example of a trivially parallelizable vector addition problem:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">OpenMP</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1">OpenACC</button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-5-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-5-5-0" name="5-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-5-5-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-1" name="5-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-5-5-0" class="sphinx-tabs-panel" id="panel-5-5-0" name="5-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">){</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>

<span class="w">    </span><span class="cm">/* Initialize vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="cp">#pragma omp target teams distribute parallel for simd</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w"> </span><span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-1" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-1" name="5-1" role="tabpanel" tabindex="0"><div class="highlight-Fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">vecsum</span>
<span class="w">    </span><span class="k">implicit none</span>

<span class="k">    </span><span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="w">    </span><span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="n">nx</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">,</span><span class="n">vecB</span><span class="p">,</span><span class="n">vecC</span>
<span class="w">    </span><span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="w">    </span><span class="c">! Initialization of vectors</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">    </span><span class="k">end do</span>

<span class="w">    </span><span class="c">!$omp target teams distribute parallel do simd</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nx</span>
<span class="w">       </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$omp end target teams distribute parallel do simd</span>
<span class="k">end program </span><span class="n">vecsum</span>
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-6-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-6-6-0" name="6-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-6-6-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-1" name="6-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-6-6-0" class="sphinx-tabs-panel" id="panel-6-6-0" name="6-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;openacc.h&gt;</span>
<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>

<span class="w">    </span><span class="cm">/* Initialization of the vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="cp">#pragma acc parallel loop</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-1" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-1" name="6-1" role="tabpanel" tabindex="0"><div class="highlight-Fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">vecsum</span>
<span class="w">    </span><span class="k">implicit none</span>

<span class="k">    </span><span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="w">    </span><span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">dimension</span><span class="p">(:),</span><span class="w"> </span><span class="k">allocatable</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">,</span><span class="n">vecB</span><span class="p">,</span><span class="n">vecC</span>
<span class="w">    </span><span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="w">    </span><span class="k">allocate</span><span class="w"> </span><span class="p">(</span><span class="n">vecA</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="n">vecC</span><span class="p">(</span><span class="n">nx</span><span class="p">))</span>
<span class="w">    </span><span class="c">! Initialization of vectors</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">    </span><span class="k">end do</span>

<span class="w">    </span><span class="c">!$acc parallel loop</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nx</span>
<span class="w">        </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$acc end parallel loop</span>
<span class="k">end program </span><span class="n">vecsum</span>
</pre></div>
</div>
</div></div>
</div></div>
</div>
</section>
</section>
<section id="data-movement">
<h3>Data Movement<a class="headerlink" href="#data-movement" title="Link to this heading"></a></h3>
<p>Due to distinct memory spaces on host and device, transferring data becomes inevitable.
New directives are needed to specify how variables are transferred from the host to the device data environment.
Commonly transferred items consist of arrays (array sections), scalars, pointers, and structure elements.
Various data clauses used for data movement are summarised in the following table:</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">OpenMP</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">OpenACC</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">map(to:list)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">copyin(list)</span></code></p></td>
<td><p>On entering the region, variables in the list are initialized on the device using the original values from the host</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">map(from:list)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">copyout(list)</span></code></p></td>
<td><p>At the end of the target region, the values from variables in the list are copied into the original variables on the host. On entering the region, the initial value of the variables on the device is not initialized</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">map(tofrom:list)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">copy(list)</span></code></p></td>
<td><p>The effect of both a map-to and a map-from</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">map(alloc:list)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">create(list)</span></code></p></td>
<td><p>On entering the region, data is allocated and uninitialized on the device</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">map(delete:list)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">delete(list)</span></code></p></td>
<td><p>Delete data on the device</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl class="simple">
<dt>When mapping data arrays or pointers, be careful about the array section notation:</dt><dd><ul class="simple">
<li><p>In C/C++: array[lower-bound:length]. The notation :N is equivalent to 0:N.</p></li>
<li><p>In Fortran:array[lower-bound:upper-bound]. The notation :N is equivalent to 1:N.</p></li>
</ul>
</dd>
</dl>
</div>
<section id="data-region">
<h4>Data region<a class="headerlink" href="#data-region" title="Link to this heading"></a></h4>
<p>The specific data clause combined with the data directive constitutes the start of a data region.
How the directives create storage, transfer data, and remove storage on the device are classified as two categories:
structured data region and unstructured data region.</p>
<section id="structured-data-region">
<h5>Structured Data Region<a class="headerlink" href="#structured-data-region" title="Link to this heading"></a></h5>
<p>A structured data region is convenient for providing persistent data on the device which could be used for subsequent GPU directives.</p>
<div class="admonition-syntax-for-structured-data-region exercise important admonition" id="exercise-4">
<p class="admonition-title">Syntax for structured data region</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-7-7-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-7-7-0" name="7-0" role="tab" tabindex="0">OpenMP</button><button aria-controls="panel-7-7-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-1" name="7-1" role="tab" tabindex="-1">OpenACC</button></div><div aria-labelledby="tab-7-7-0" class="sphinx-tabs-panel" id="panel-7-7-0" name="7-0" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-8-8-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-8-8-0" name="8-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-8-8-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-1" name="8-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-8-8-0" class="sphinx-tabs-panel" id="panel-8-8-0" name="8-0" role="tabpanel" tabindex="0"><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma omp target data [clauses]</span>
<span class="p">{</span><span class="n">structured</span><span class="o">-</span><span class="n">block</span><span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-1" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-1" name="8-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="c">!$omp target data [clauses]</span>
<span class="w"> </span><span class="n">structured</span><span class="o">-</span><span class="k">block</span>
<span class="c">!$omp end target data</span>
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-7-7-1" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-1" name="7-1" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-9-9-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-9-9-0" name="9-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-9-9-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-1" name="9-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-9-9-0" class="sphinx-tabs-panel" id="panel-9-9-0" name="9-0" role="tabpanel" tabindex="0"><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma acc data [clauses]</span>
<span class="w"> </span><span class="p">{</span><span class="n">structured</span><span class="o">-</span><span class="n">block</span><span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-1" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-1" name="9-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="c">!$acc data [clauses]</span>
<span class="w">  </span><span class="n">structured</span><span class="o">-</span><span class="k">block</span>
<span class="c">!$acc end data</span>
</pre></div>
</div>
</div></div>
</div></div>
</div>
</section>
<section id="unstructured-data-region">
<h5>Unstructured Data Region<a class="headerlink" href="#unstructured-data-region" title="Link to this heading"></a></h5>
<p>However it is inconvenient in real applications to use a structured data region. An unstructured data region
gives more freedom in creating and deleting data on the device at any appropriate point.</p>
<div class="admonition-syntax-for-unstructured-data-region exercise important admonition" id="exercise-5">
<p class="admonition-title">Syntax for unstructured data region</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-10-10-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-10-10-0" name="10-0" role="tab" tabindex="0">OpenMP</button><button aria-controls="panel-10-10-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-10-10-1" name="10-1" role="tab" tabindex="-1">OpenACC</button></div><div aria-labelledby="tab-10-10-0" class="sphinx-tabs-panel" id="panel-10-10-0" name="10-0" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-11-11-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-11-11-0" name="11-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-11-11-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-11-11-1" name="11-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-11-11-0" class="sphinx-tabs-panel" id="panel-11-11-0" name="11-0" role="tabpanel" tabindex="0"><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma omp target enter data [clauses]</span>
</pre></div>
</div>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma omp target exit data</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-11-11-1" class="sphinx-tabs-panel" hidden="true" id="panel-11-11-1" name="11-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="c">!$omp target enter data [clauses]</span>
</pre></div>
</div>
<div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="c">!$omp target exit data</span>
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-10-10-1" class="sphinx-tabs-panel" hidden="true" id="panel-10-10-1" name="10-1" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-12-12-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-12-12-0" name="12-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-12-12-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-12-12-1" name="12-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-12-12-0" class="sphinx-tabs-panel" id="panel-12-12-0" name="12-0" role="tabpanel" tabindex="0"><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma acc enter data [clauses]</span>
</pre></div>
</div>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma acc exit data</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-12-12-1" class="sphinx-tabs-panel" hidden="true" id="panel-12-12-1" name="12-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="c">!$acc enter data [clauses]</span>
</pre></div>
</div>
<div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="c">!$acc exit data</span>
</pre></div>
</div>
</div></div>
</div></div>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-1">
<p class="admonition-title">Keypoints</p>
<dl class="simple">
<dt>Structured Data Region</dt><dd><ul class="simple">
<li><p>Start and end points within a single subroutine</p></li>
<li><p>Memory exists within the data region</p></li>
</ul>
</dd>
<dt>Unstructured Data Region</dt><dd><ul class="simple">
<li><p>Multiple start and end points across different subroutines</p></li>
<li><p>Memory exists until explicitly deallocated</p></li>
</ul>
</dd>
</dl>
</div>
</section>
<section id="update">
<h5>Update<a class="headerlink" href="#update" title="Link to this heading"></a></h5>
<p>Sometimes, variables need to be synchronized between the host and the device memory, e.g. in order to write out variables on the host for debugging or visualization, and it is often used in conjunction with unstructured data regions. To control the data transfer direction, a motion-clause must be present.</p>
<div class="admonition-syntax-for-update-directive exercise important admonition" id="exercise-6">
<p class="admonition-title">Syntax for update directive</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-13-13-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-13-13-0" name="13-0" role="tab" tabindex="0">OpenMP</button><button aria-controls="panel-13-13-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-13-13-1" name="13-1" role="tab" tabindex="-1">OpenACC</button></div><div aria-labelledby="tab-13-13-0" class="sphinx-tabs-panel" id="panel-13-13-0" name="13-0" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-14-14-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-14-14-0" name="14-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-14-14-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-14-14-1" name="14-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-14-14-0" class="sphinx-tabs-panel" id="panel-14-14-0" name="14-0" role="tabpanel" tabindex="0"><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma omp target update [clauses]</span>
</pre></div>
</div>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">motion</span><span class="o">-</span><span class="n">clause</span><span class="o">:</span>
<span class="w">          </span><span class="n">to</span><span class="w"> </span><span class="p">(</span><span class="n">list</span><span class="p">)</span>
<span class="w">          </span><span class="n">from</span><span class="w"> </span><span class="p">(</span><span class="n">list</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-14-14-1" class="sphinx-tabs-panel" hidden="true" id="panel-14-14-1" name="14-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="c">!$omp target update [clauses]</span>
</pre></div>
</div>
<div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="n">motion</span><span class="o">-</span><span class="n">clause</span><span class="p">:</span>
<span class="w">          </span><span class="n">to</span><span class="w"> </span><span class="p">(</span><span class="n">list</span><span class="p">)</span>
<span class="w">          </span><span class="n">from</span><span class="w"> </span><span class="p">(</span><span class="n">list</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-13-13-1" class="sphinx-tabs-panel" hidden="true" id="panel-13-13-1" name="13-1" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-15-15-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-15-15-0" name="15-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-15-15-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-15-15-1" name="15-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-15-15-0" class="sphinx-tabs-panel" id="panel-15-15-0" name="15-0" role="tabpanel" tabindex="0"><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma acc update [clauses]</span>
</pre></div>
</div>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">motion</span><span class="o">-</span><span class="n">clause</span><span class="o">:</span>
<span class="w">          </span><span class="n">self</span><span class="w"> </span><span class="p">(</span><span class="n">list</span><span class="p">)</span>
<span class="w">          </span><span class="n">device</span><span class="w"> </span><span class="p">(</span><span class="n">list</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-15-15-1" class="sphinx-tabs-panel" hidden="true" id="panel-15-15-1" name="15-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="c">!$acc update [clauses]</span>
</pre></div>
</div>
<div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="n">motion</span><span class="o">-</span><span class="n">clause</span><span class="p">:</span>
<span class="w">          </span><span class="n">self</span><span class="w"> </span><span class="p">(</span><span class="n">list</span><span class="p">)</span>
<span class="w">          </span><span class="n">device</span><span class="w"> </span><span class="p">(</span><span class="n">list</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
</div></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">update</span></code> directive can only be used in host code since data movement must be initiated from the host, i.e. it may not appear inside of a compute region.</p></li>
<li><p>in OpenACC, motion-clause “host” has been deprecated and renamed “self”</p></li>
</ul>
</div>
<div class="admonition-exercise-update exercise important admonition" id="exercise-7">
<p class="admonition-title">Exercise:  <code class="docutils literal notranslate"><span class="pre">update</span></code></p>
<p>Try to figure out the variable values on host and device at each check point.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-16-16-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-16-16-0" name="16-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-16-16-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-16-16-1" name="16-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-16-16-0" class="sphinx-tabs-panel" id="panel-16-16-0" name="16-0" role="tabpanel" tabindex="0"><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
<span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="cp">#pragma omp target data map(tofrom:x)</span>
<span class="p">{</span>
<span class="w">   </span><span class="cm">/* check point 1 */</span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>
<span class="w">   </span><span class="cm">/* check point 2 */</span>
<span class="cp">#pragma omp target update to(x)</span>
<span class="w">   </span><span class="cm">/* check point 3 */</span>
<span class="p">}</span>

<span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-16-16-1" class="sphinx-tabs-panel" hidden="true" id="panel-16-16-1" name="16-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">ex_update</span>
<span class="k">implicit none</span>

<span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">x</span>

<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="c">!$acc data copy(x)</span>
<span class="c">! check point 1</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span>
<span class="c">! check point 2</span>
<span class="c">!$acc update device(x)</span>
<span class="c">! check point 3</span>
<span class="c">!$acc end data</span>

<span class="k">end program </span><span class="n">ex_update</span>
</pre></div>
</div>
</div></div>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>check point</p></th>
<th class="head"><p>x on host</p></th>
<th class="head"><p>x on device</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>check point1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>check point2</p></td>
<td><p>10</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>check point3</p></td>
<td><p>10</p></td>
<td><p>10</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="admonition-exercise-adding-data-mapping-clauses exercise important admonition" id="exercise-8">
<p class="admonition-title">Exercise: Adding data mapping clauses</p>
<p>Add proper data mapping clauses explicitly to the directives</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-17-17-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-17-17-0" name="17-0" role="tab" tabindex="0">OpenMP</button><button aria-controls="panel-17-17-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-17-17-1" name="17-1" role="tab" tabindex="-1">OpenACC</button></div><div aria-labelledby="tab-17-17-0" class="sphinx-tabs-panel" id="panel-17-17-0" name="17-0" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-18-18-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-18-18-0" name="18-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-18-18-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-18-18-1" name="18-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-18-18-0" class="sphinx-tabs-panel" id="panel-18-18-0" name="18-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">){</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>

<span class="w">    </span><span class="cm">/* Initialize vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">    </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="cm">/* Adding mapping clauses here */</span>
<span class="w">    </span><span class="cp">#pragma omp target teams distribute parallel for simd</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;The sum is: %8.6f </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-18-18-1" class="sphinx-tabs-panel" hidden="true" id="panel-18-18-1" name="18-1" role="tabpanel" tabindex="0"><div class="highlight-Fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">vecsum</span>
<span class="k">implicit none</span>

<span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="n">nx</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">,</span><span class="n">vecB</span><span class="p">,</span><span class="n">vecC</span>
<span class="w">          </span><span class="kt">real</span><span class="w">    </span><span class="kd">::</span><span class="w"> </span><span class="nb">sum</span>
<span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="c">! Initialization of vectors</span>
<span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">    </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">    </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="k">end do</span>
<span class="c">! Adding mapping clauses here</span>
<span class="c">!$omp target teams distribute parallel do simd</span>
<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nx</span>
<span class="w">    </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="k">enddo</span>
<span class="c">!$omp end target teams distribute parallel do simd</span>

<span class="nb">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="c">! Calculate the sum</span>
<span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">    </span><span class="nb">sum</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">sum</span>
<span class="k">end do</span>
<span class="k">write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="s1">&#39;(A,F18.6)&#39;</span><span class="p">)</span><span class="w"> </span><span class="s1">&#39;The sum is: &#39;</span><span class="p">,</span><span class="w"> </span><span class="nb">sum</span>

<span class="k">end program </span><span class="n">vecsum</span>
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-17-17-1" class="sphinx-tabs-panel" hidden="true" id="panel-17-17-1" name="17-1" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-19-19-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-19-19-0" name="19-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-19-19-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-19-19-1" name="19-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-19-19-0" class="sphinx-tabs-panel" id="panel-19-19-0" name="19-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;openacc.h&gt;</span>
<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>

<span class="w">    </span><span class="cm">/* Initialization of the vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="cm">/* Adding mapping clauses here */</span>
<span class="w">    </span><span class="cp">#pragma acc parallel loop</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;The sum is: %8.6f </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-19-19-1" class="sphinx-tabs-panel" hidden="true" id="panel-19-19-1" name="19-1" role="tabpanel" tabindex="0"><div class="highlight-Fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">vecsum</span>
<span class="w">    </span><span class="k">implicit none</span>

<span class="k">    </span><span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="w">    </span><span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">dimension</span><span class="p">(:),</span><span class="w"> </span><span class="k">allocatable</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">,</span><span class="n">vecB</span><span class="p">,</span><span class="n">vecC</span>
<span class="w">              </span><span class="kt">real</span><span class="w">    </span><span class="kd">::</span><span class="w"> </span><span class="nb">sum</span>
<span class="nb">    </span><span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="w">    </span><span class="k">allocate</span><span class="w"> </span><span class="p">(</span><span class="n">vecA</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span><span class="n">vecC</span><span class="p">(</span><span class="n">nx</span><span class="p">))</span>
<span class="w">    </span><span class="c">! Initialization of vectors</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">    </span><span class="k">end do</span>
<span class="w">    </span><span class="c">! Adding mapping clauses here</span>
<span class="w">    </span><span class="c">!$acc parallel loop</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nx</span>
<span class="w">        </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$acc end parallel loop</span>

<span class="w">    </span><span class="nb">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="w">    </span><span class="c">! Calculate the sum</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">       </span><span class="nb">sum</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">sum</span>
<span class="nb">    </span><span class="k">end do</span>
<span class="k">    write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="s1">&#39;(A,F18.6)&#39;</span><span class="p">)</span><span class="w"> </span><span class="s1">&#39;The sum is: &#39;</span><span class="p">,</span><span class="w"> </span><span class="nb">sum</span>

<span class="nb">    </span><span class="k">end program </span><span class="n">vecsum</span>
</pre></div>
</div>
</div></div>
</div></div>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-20-20-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-20-20-0" name="20-0" role="tab" tabindex="0">OpenMP</button><button aria-controls="panel-20-20-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-20-20-1" name="20-1" role="tab" tabindex="-1">OpenACC</button></div><div aria-labelledby="tab-20-20-0" class="sphinx-tabs-panel" id="panel-20-20-0" name="20-0" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-21-21-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-21-21-0" name="21-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-21-21-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-21-21-1" name="21-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-21-21-0" class="sphinx-tabs-panel" id="panel-21-21-0" name="21-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">){</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>

<span class="w">    </span><span class="cm">/* Initialize vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="hll"><span class="w">    </span><span class="cp">#pragma omp target teams distribute parallel for simd map(to:vecA[0:NX],vecB[0:NX]) map(from:vecC[0:NX])</span>
</span><span class="w">    </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">         </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;The sum is: %8.6f </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-21-21-1" class="sphinx-tabs-panel" hidden="true" id="panel-21-21-1" name="21-1" role="tabpanel" tabindex="0"><div class="highlight-Fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">vecsum</span>
<span class="w">    </span><span class="k">implicit none</span>

<span class="k">    </span><span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="w">    </span><span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="n">nx</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">,</span><span class="n">vecB</span><span class="p">,</span><span class="n">vecC</span>
<span class="w">              </span><span class="kt">real</span><span class="w">    </span><span class="kd">::</span><span class="w"> </span><span class="nb">sum</span>
<span class="nb">    </span><span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="w">    </span><span class="c">! Initialization of vectors</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">    </span><span class="k">end do</span>

<span class="hll"><span class="w">    </span><span class="c">!$omp target teams distribute parallel do simd map(to:vecA,vecB) map(from:vecC)</span>
</span><span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nx</span>
<span class="w">        </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$omp end target teams distribute parallel do simd</span>

<span class="w">    </span><span class="nb">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="w">    </span><span class="c">! Calculate the sum</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">        </span><span class="nb">sum</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">sum</span>
<span class="nb">    </span><span class="k">end do</span>
<span class="k">    write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="s1">&#39;(A,F18.6)&#39;</span><span class="p">)</span><span class="w"> </span><span class="s1">&#39;The sum is: &#39;</span><span class="p">,</span><span class="w"> </span><span class="nb">sum</span>

<span class="nb">    </span><span class="k">end program </span><span class="n">vecsum</span>
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-20-20-1" class="sphinx-tabs-panel" hidden="true" id="panel-20-20-1" name="20-1" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-22-22-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-22-22-0" name="22-0" role="tab" tabindex="0">C/C++</button><button aria-controls="panel-22-22-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-22-22-1" name="22-1" role="tab" tabindex="-1">Fortran</button></div><div aria-labelledby="tab-22-22-0" class="sphinx-tabs-panel" id="panel-22-22-0" name="22-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;openacc.h&gt;</span>
<span class="cp">#define NX 102400</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">NX</span><span class="p">],</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">NX</span><span class="p">];</span>

<span class="w">    </span><span class="cm">/* Initialization of the vectors */</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="hll"><span class="w">    </span><span class="cp">#pragma acc parallel loop copyin(vecA[0:NX],vecB[0:NX]) copyout(vecC[0:NX])</span>
</span><span class="w">    </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NX</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">vecC</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;The sum is: %8.6f </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-22-22-1" class="sphinx-tabs-panel" hidden="true" id="panel-22-22-1" name="22-1" role="tabpanel" tabindex="0"><div class="highlight-Fortran notranslate"><div class="highlight"><pre><span></span><span class="k">program </span><span class="n">vecsum</span>
<span class="w">    </span><span class="k">implicit none</span>

<span class="k">    </span><span class="kt">integer</span><span class="p">,</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">102400</span>
<span class="w">    </span><span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="n">nx</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">vecA</span><span class="p">,</span><span class="n">vecB</span><span class="p">,</span><span class="n">vecC</span>
<span class="w">              </span><span class="kt">real</span><span class="w">    </span><span class="kd">::</span><span class="w"> </span><span class="nb">sum</span>
<span class="nb">    </span><span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">i</span>

<span class="w">    </span><span class="c">! Initialization of vectors</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">        </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">        </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">    </span><span class="k">end do</span>

<span class="hll"><span class="w">    </span><span class="c">!$acc parallel loop copyin(vecA,vecB) copyout(vecC)</span>
</span><span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nx</span>
<span class="w">       </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecA</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">vecB</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$acc end parallel loop</span>

<span class="w">    </span><span class="nb">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="w">    </span><span class="c">! Calculate the sum</span>
<span class="w">    </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span>
<span class="w">       </span><span class="nb">sum</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">vecC</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">sum</span>
<span class="nb">    </span><span class="k">end do</span>
<span class="k">    write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="s1">&#39;(A,F18.6)&#39;</span><span class="p">)</span><span class="w"> </span><span class="s1">&#39;The sum is: &#39;</span><span class="p">,</span><span class="w"> </span><span class="nb">sum</span>

<span class="nb">    </span><span class="k">end program </span><span class="n">vecsum</span>
</pre></div>
</div>
</div></div>
</div></div>
</div>
</div>
</section>
</section>
<section id="optimize-data-transfers">
<h4>Optimize Data Transfers<a class="headerlink" href="#optimize-data-transfers" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Explicitly transfer the data as much as possible.</p></li>
<li><p>Reduce the amount of data mapping between host and device, get rid of unnecessary data transfers.</p></li>
<li><p>Try to keep the data environment residing on the device as long as possible.</p></li>
</ul>
</section>
</section>
<section id="pros-of-directive-based-frameworks">
<h3>Pros of directive-based frameworks<a class="headerlink" href="#pros-of-directive-based-frameworks" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Incremental programming</p></li>
<li><p>Porting of existing software requires less work</p></li>
<li><p>Same code can be compiled to CPU and GPU versions easily using compiler flag</p></li>
<li><p>Low learning curve, do not need to know low-level hardware details</p></li>
<li><p>Good portability</p></li>
</ul>
</section>
<section id="see-also">
<h3>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://enccs.github.io/openacc/">ENCCS lesson on OpenACC</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/openmp-gpu/">ENCCS lesson on OpenMP for GPU offloading</a></p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-2">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>OpenACC and OpenMP-offloading enables you to annotate your code with special directives to identify areas to be executed in parallel on a GPU.</p></li>
<li><p>Both allow to fine-tune the distribution of the work to match architecture characteristics.</p></li>
<li><p>Both allow to control the flow of data to/from the GPU.</p></li>
<li><p>The directive-based approaches save time compared to lower-level approaches, but you need to be mindful of data movement in particular to obtain good performance.</p></li>
</ul>
</div>
</section>
</section>
<span id="document-7-non-portable-kernel-models"></span><section id="non-portable-kernel-based-models">
<span id="non-portable-kernel-models"></span><h2>Non-portable kernel-based models<a class="headerlink" href="#non-portable-kernel-based-models" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>How to program GPUs with CUDA and HIP?</p></li>
<li><p>What optimizations are possible when programming with CUDA and HIP?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Be able to use CUDA and HIP to write basic codes</p></li>
<li><p>Understand how the execution is done and how to do optimizations</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>45 min teaching</p></li>
<li><p>30 min exercises</p></li>
</ul>
</div>
<section id="fundamentals-of-gpu-programming-with-cuda-and-hip">
<h3>Fundamentals of GPU programming with CUDA and HIP<a class="headerlink" href="#fundamentals-of-gpu-programming-with-cuda-and-hip" title="Link to this heading"></a></h3>
<p>Unlike some cross-platform portability ecosystems, such as alpaka, Kokkos, OpenCL, RAJA, and SYCL, which cater to multiple architectures, CUDA and HIP are solely focused on GPUs. They provide extensive libraries, APIs, and compiler toolchains that optimize code execution on NVIDIA GPUs (in the case of CUDA) and both NVIDIA and AMD GPUs (in the case of HIP). Because they are developed by the device producers, these programming models provide high-performance computing capabilities and offer advanced features like shared memory, thread synchronization, and memory management specific to GPU architectures.</p>
<p>CUDA, developed by NVIDIA, has gained significant popularity and is widely used for GPU programming. It offers a comprehensive ecosystem that includes not only the CUDA programming model but also a vast collection of GPU-accelerated libraries. Developers can write CUDA kernels using C++ and seamlessly integrate them into their applications to harness the massive parallelism of GPUs.</p>
<p>HIP, on the other hand, is an open-source project that aims to provide a more “portable” GPU programming interface. It allows developers to write GPU code in a syntax similar to CUDA and provides a translation layer that enables the same code to run on both NVIDIA and AMD GPUs. This approach minimizes the effort required to port CUDA code to different GPU architectures and provides flexibility for developers to target multiple platforms.</p>
<p>By being closely tied to the GPU hardware, CUDA and HIP provide a level of performance optimization that may not be achievable with cross-platform portability ecosystems. The libraries and toolchains offered by these programming models are specifically designed to exploit the capabilities of the underlying GPU architectures, enabling developers to achieve high performance.</p>
<p>Developers utilizing CUDA or HIP can tap into an extensive ecosystem of GPU-accelerated libraries, covering various domains, including linear algebra, signal processing, image processing, machine learning, and more. These libraries are highly optimized to take advantage of the parallelism and computational power offered by GPUs, allowing developers to accelerate their applications without having to implement complex algorithms from scratch.</p>
<p>As mentioned before, CUDA and HIP are very similar so it makes sense to cover both at the same time.</p>
<div class="admonition-comparison-to-portable-kernel-based-models callout admonition" id="callout-0">
<p class="admonition-title">Comparison to portable kernel-based models</p>
<p>In code examples below, we will also show examples in the portable kernel-based frameworks Kokkos, SYCL and OpenCL, which will be covered in the next episode.</p>
</div>
<section id="hello-world">
<h4>Hello World<a class="headerlink" href="#hello-world" title="Link to this heading"></a></h4>
<p>Below we have the most basic example of CUDA and HIP, the “Hello World” program:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-Q1VEQQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-Q1VEQQ==" name="Q1VEQQ==" role="tab" tabindex="0">CUDA</button><button aria-controls="panel-0-SElQ" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-SElQ" name="SElQ" role="tab" tabindex="-1">HIP</button><button aria-controls="panel-0-S29ra29z" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-S29ra29z" name="S29ra29z" role="tab" tabindex="-1">Kokkos</button><button aria-controls="panel-0-T3BlbkNM" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-T3BlbkNM" name="T3BlbkNM" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-0-U1lDTA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-U1lDTA==" name="U1lDTA==" role="tab" tabindex="-1">SYCL</button></div><div aria-labelledby="tab-0-Q1VEQQ==" class="sphinx-tabs-panel group-tab" id="panel-0-Q1VEQQ==" name="Q1VEQQ==" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>

<span class="w">  </span><span class="n">cudaGetDeviceCount</span><span class="p">(</span><span class="o">&amp;</span><span class="n">count</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaGetDevice</span><span class="p">(</span><span class="o">&amp;</span><span class="n">device</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Hello! I&#39;m GPU %d out of %d GPUs in total.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-SElQ" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-SElQ" name="SElQ" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;hip/hip_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>

<span class="w">  </span><span class="n">hipGetDeviceCount</span><span class="p">(</span><span class="o">&amp;</span><span class="n">count</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipGetDevice</span><span class="p">(</span><span class="o">&amp;</span><span class="n">device</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Hello! I&#39;m GPU %d out of %d GPUs in total.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-S29ra29z" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-S29ra29z" name="S29ra29z" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">();</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">Cuda</span><span class="p">().</span><span class="n">concurrency</span><span class="p">();</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">Cuda</span><span class="p">().</span><span class="n">impl_internal_space_instance</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">impl_internal_space_id</span><span class="p">();</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Hello! I&#39;m GPU &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; out of &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">count</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; GPUs in total.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-T3BlbkNM" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-T3BlbkNM" name="T3BlbkNM" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/opencl.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">cl_uint</span><span class="w"> </span><span class="n">count</span><span class="p">;</span>
<span class="w">  </span><span class="n">cl_platform_id</span><span class="w"> </span><span class="n">platform</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetPlatformIDs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="n">cl_device_id</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetDeviceIDs</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_TYPE_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">count</span><span class="p">);</span>

<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">deviceName</span><span class="p">[</span><span class="mi">1024</span><span class="p">];</span>
<span class="w">  </span><span class="n">clGetDeviceInfo</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_NAME</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">deviceName</span><span class="p">),</span><span class="w"> </span><span class="n">deviceName</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Hello! I&#39;m GPU %s out of %d GPUs in total.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">deviceName</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-U1lDTA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-U1lDTA==" name="U1lDTA==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">gpu_devices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">get_devices</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device_type</span><span class="o">::</span><span class="n">gpu</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gpu_devices</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Hello! I&#39;m using a SYCL device by &quot;</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">gpu_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">vendor</span><span class="o">&gt;</span><span class="p">()</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;, the first of &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">count</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; devices.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>In both versions, we include the necessary headers: <strong>cuda_runtime.h</strong> and <strong>cuda.h</strong> for CUDA, and <strong>hip_runtime.h</strong> for HIP. These headers provide the required functionality for GPU programming.</p>
<p>To retrieve information about the available devices, we use the functions <strong>&lt;cuda/hip&gt;GetDeviceCount</strong> and <strong>&lt;cuda/hip&gt;GetDevice</strong>. These functions allow us to determine the total number of GPUs and the index of the currently used device. In the code examples, we default to using device 0.</p>
<p>As an exercise, modify the “Hello World” code to explicitly use a specific GPU. Do this by using the <strong>&lt;cuda/hip&gt;SetDevice</strong> function, which allows to set the desired GPU device.
Note that the device number provided has to be within the range of available devices, otherwise, the program may fail to run or produce unexpected results.
To experiment with different GPUs, modify the code to include the following line before retrieving device information:</p>
<blockquote>
<div><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">deviceNumber</span><span class="p">);</span><span class="w"> </span><span class="c1">// For CUDA</span>
<span class="n">hipSetDevice</span><span class="p">(</span><span class="n">deviceNumber</span><span class="p">);</span><span class="w"> </span><span class="c1">// For HIP</span>
</pre></div>
</div>
</div></blockquote>
<p>Replace <strong>deviceNumber</strong> with the desired GPU device index. Run the code with different device numbers to observe the output (more examples for the “Hello World” program are available in the <a class="reference external" href="https://github.com/ENCCS/gpu-programming/tree/main/content/examples/cuda-hip">content/examples/cuda-hip</a> subdirectory of this lesson repository).</p>
</section>
<section id="vector-addition">
<h4>Vector Addition<a class="headerlink" href="#vector-addition" title="Link to this heading"></a></h4>
<p>To demonstrate the fundamental features of CUDA/HIP programming, let’s begin with a straightforward task of element-wise vector addition. The code snippet below demonstrates how to utilize CUDA and HIP for efficiently executing this operation.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-Q1VEQQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-Q1VEQQ==" name="Q1VEQQ==" role="tab" tabindex="0">CUDA</button><button aria-controls="panel-1-SElQ" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-SElQ" name="SElQ" role="tab" tabindex="-1">HIP</button><button aria-controls="panel-1-T3BlbkNM" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-T3BlbkNM" name="T3BlbkNM" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-1-U1lDTA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-U1lDTA==" name="U1lDTA==" role="tab" tabindex="-1">SYCL</button></div><div aria-labelledby="tab-1-Q1VEQQ==" class="sphinx-tabs-panel group-tab" id="panel-1-Q1VEQQ==" name="Q1VEQQ==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">vector_add</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">C</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10000</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Cref</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Cd</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate the arrays on CPU</span>
<span class="w">  </span><span class="n">Ah</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">Bh</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">Ch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">Cref</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// initialise data and calculate reference values on CPU</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">2.3</span><span class="p">;</span>
<span class="w">    </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.1</span><span class="p">;</span>
<span class="w">    </span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Allocate the arrays on GPU</span>
<span class="w">  </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Cd</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// Transfer the data from CPU to GPU</span>
<span class="w">  </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// define grid dimensions + launch the device kernel</span>
<span class="w">  </span><span class="n">dim3</span><span class="w"> </span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">;</span>
<span class="w">  </span><span class="n">threads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dim3</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="n">blocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dim3</span><span class="p">((</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">256</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Launch Kernel</span>
<span class="w">  </span><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="n">Cd</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// copy results back to CPU</span>
<span class="w">  </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="n">Cd</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;reference: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<span class="w">         </span><span class="n">Cref</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;   result: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
<span class="w">         </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// confirm that results are correct</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">tolerance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-6</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fabs</span><span class="p">(</span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">diff</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tolerance</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">error</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;total error: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">error</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;  reference: %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;     result: %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Free the GPU arrays</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">Ad</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">Bd</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">Cd</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Free the CPU arrays</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">Ah</span><span class="p">);</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">Bh</span><span class="p">);</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">Ch</span><span class="p">);</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">Cref</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-SElQ" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-SElQ" name="SElQ" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;hip/hip_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">vector_add</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">C</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10000</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Cref</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Cd</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate the arrays on CPU</span>
<span class="w">  </span><span class="n">Ah</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">Bh</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">Ch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">Cref</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// initialise data and calculate reference values on CPU</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">2.3</span><span class="p">;</span>
<span class="w">    </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.1</span><span class="p">;</span>
<span class="w">    </span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Allocate the arrays on GPU</span>
<span class="w">  </span><span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Cd</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// Transfer the data from CPU to GPU</span>
<span class="w">  </span><span class="n">hipMemcpy</span><span class="p">(</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">hipMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipMemcpy</span><span class="p">(</span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">hipMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// define grid dimensions + launch the device kernel</span>
<span class="w">  </span><span class="n">dim3</span><span class="w"> </span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">;</span>
<span class="w">  </span><span class="n">threads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dim3</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="n">blocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dim3</span><span class="p">((</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">256</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Launch Kernel</span>
<span class="w">  </span><span class="c1">//  use</span>
<span class="w">  </span><span class="c1">// hipLaunchKernelGGL(vector_add, blocks, threads, 0, 0, Ad, Bd, Cd, N); // or</span>
<span class="w">  </span><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="n">Cd</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// copy results back to CPU</span>
<span class="w">  </span><span class="n">hipMemcpy</span><span class="p">(</span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="n">Cd</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">hipMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;reference: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<span class="w">         </span><span class="n">Cref</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;   result: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
<span class="w">         </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// confirm that results are correct</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">tolerance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-6</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">abs</span><span class="p">(</span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">diff</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tolerance</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">error</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;total error: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">error</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;  reference: %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;     result: %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Free the GPU arrays</span>
<span class="w">  </span><span class="n">hipFree</span><span class="p">(</span><span class="n">Ad</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipFree</span><span class="p">(</span><span class="n">Bd</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipFree</span><span class="p">(</span><span class="n">Cd</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Free the CPU arrays</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">Ah</span><span class="p">);</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">Bh</span><span class="p">);</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">Ch</span><span class="p">);</span>
<span class="w">  </span><span class="n">free</span><span class="p">(</span><span class="n">Cref</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-T3BlbkNM" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-T3BlbkNM" name="T3BlbkNM" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using C API here; examples with C++ API can be found in the &quot;Portable</span>
<span class="c1">// kernel models&quot; chapter</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>

<span class="cp">#define N 10000</span>

<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">programSource</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="s">&quot;__kernel void vector_add(__global const float* A, __global const float* &quot;</span>
<span class="w">    </span><span class="s">&quot;B, __global float* C, int N) {</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">    </span><span class="s">&quot;    int tid = get_global_id(0);</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">    </span><span class="s">&quot;    if (tid &lt; N) {</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">    </span><span class="s">&quot;        C[tid] = A[tid] + B[tid];</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">    </span><span class="s">&quot;    }</span><span class="se">\n</span><span class="s">&quot;</span>
<span class="w">    </span><span class="s">&quot;}</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Initialize data and calculate reference values on CPU</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">Ah</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="w"> </span><span class="n">Bh</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">2.3f</span><span class="p">;</span>
<span class="w">    </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.1f</span><span class="p">;</span>
<span class="w">    </span><span class="n">Ch</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">12.f</span><span class="p">;</span>
<span class="w">    </span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Use the default device</span>
<span class="w">  </span><span class="n">cl_platform_id</span><span class="w"> </span><span class="n">platform</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetPlatformIDs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_device_id</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetDeviceIDs</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_TYPE_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_context</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateContext</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_command_queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateCommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Build the kernel from string</span>
<span class="w">  </span><span class="n">cl_program</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">clCreateProgramWithSource</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">programSource</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clBuildProgram</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_kernel</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateKernel</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;vector_add&quot;</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate the arrays on GPU</span>
<span class="w">  </span><span class="n">cl_mem</span><span class="w"> </span><span class="n">d_A</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">clCreateBuffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_mem</span><span class="w"> </span><span class="n">d_B</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">clCreateBuffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_mem</span><span class="w"> </span><span class="n">d_C</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">clCreateBuffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_WRITE_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="n">clEnqueueWriteBuffer</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                       </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clEnqueueWriteBuffer</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                       </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Set arguments and launch the kernel</span>
<span class="w">  </span><span class="n">clSetKernelArg</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">cl_mem</span><span class="p">),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">d_A</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSetKernelArg</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">cl_mem</span><span class="p">),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">d_B</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSetKernelArg</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">cl_mem</span><span class="p">),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">d_C</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_int</span><span class="w"> </span><span class="n">N_as_cl_int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">;</span>
<span class="w">  </span><span class="n">clSetKernelArg</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">cl_int</span><span class="p">),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">N_as_cl_int</span><span class="p">);</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">globalSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">;</span>
<span class="w">  </span><span class="n">clEnqueueNDRangeKernel</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">globalSize</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                         </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Copy the results back</span>
<span class="w">  </span><span class="n">clEnqueueReadBuffer</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                      </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Print reference and result values</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Reference: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<span class="w">         </span><span class="n">Cref</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Result   : %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
<span class="w">         </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Compare results and calculate the total error</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">tolerance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-6f</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fabs</span><span class="p">(</span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">diff</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tolerance</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">error</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Total error: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">error</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Reference:   %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Result   :   %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>

<span class="w">  </span><span class="n">clReleaseMemObject</span><span class="p">(</span><span class="n">d_A</span><span class="p">);</span>
<span class="w">  </span><span class="n">clReleaseMemObject</span><span class="p">(</span><span class="n">d_B</span><span class="p">);</span>
<span class="w">  </span><span class="n">clReleaseMemObject</span><span class="p">(</span><span class="n">d_C</span><span class="p">);</span>
<span class="w">  </span><span class="n">clReleaseKernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">);</span>
<span class="w">  </span><span class="n">clReleaseProgram</span><span class="p">(</span><span class="n">program</span><span class="p">);</span>
<span class="w">  </span><span class="n">clReleaseCommandQueue</span><span class="p">(</span><span class="n">queue</span><span class="p">);</span>
<span class="w">  </span><span class="n">clReleaseContext</span><span class="p">(</span><span class="n">context</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-U1lDTA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-U1lDTA==" name="U1lDTA==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10000</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// The queue will be executed on the best device in the system</span>
<span class="w">  </span><span class="c1">// We use in-order queue for simplicity</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">{{</span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">in_order</span><span class="p">()}};</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Ah</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Bh</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Ch</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize data and calculate reference values on CPU</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">2.3f</span><span class="p">;</span>
<span class="w">    </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">cos</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.1f</span><span class="p">;</span>
<span class="w">    </span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Allocate the arrays on GPU</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Ad</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Bd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Cd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">Ah</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">Bh</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Define grid dimensions</span>
<span class="w">  </span><span class="c1">// We can specify the block size explicitly, but we don&#39;t have to</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">global_size</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">h</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">h</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">VectorAdd</span><span class="o">&gt;</span><span class="p">(</span><span class="n">global_size</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">threadId</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadId</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">      </span><span class="n">Cd</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Ad</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Bd</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">  </span><span class="p">});</span>

<span class="w">  </span><span class="c1">// Copy results back to CPU</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">event</span><span class="w"> </span><span class="n">eventCCopy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">Cd</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="c1">// Wait for the copy to finish</span>
<span class="w">  </span><span class="n">eventCCopy</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Print reference and result values</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Reference: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; ... &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Result   : &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; ... &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Compare results and calculate the total error</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">tolerance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-6f</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">abs</span><span class="p">(</span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">diff</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tolerance</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">error</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Total error: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Reference:   &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">42</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; at (42)&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Result   :   &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">42</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; at (42)&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Free the GPU memory</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">Ad</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">Bd</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">Cd</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>In this case, the CUDA and HIP codes are equivalent one to one so we will only refer to the CUDA version. The CUDA and HIP programming model are host centric programming models. The main program is executed on CPU and controls all the operations, memory allocations, data transfers between CPU and GPU, and launches the kernels to be executed on the GPU. The code starts with defining the GPU kernel function called <strong>vector_add</strong> with attribute <strong>___global__</strong>. It takes three input arrays <cite>A</cite>, <cite>B</cite>, and <cite>C</cite> along with the array size <cite>n</cite>. The kernel function contains the actually code which is executed on the GPU by multiple threads in parallel.</p>
<p>Accelerators in general and GPUs in particular usually have their own dedicated memory separate from the system memory (AMD MI300A is one exception, using the same memory for both CPU and GPU). When programming for GPUs, there are two sets of pointers involved and it’s necessary to manage data movement between the host memory and the accelerator memory. Data needs to be explicitly copied from the host memory to the accelerator memory before it can be processed by the accelerator. Similarly, results or modified data may need to be copied back from the accelerator memory to the host memory to make them accessible to the CPU.</p>
<p>The main function of the code initializes the input arrays <cite>Ah, Bh</cite> on the CPU and computes the reference array <cite>Cref</cite>. It then allocates memory on the GPU for the input and output arrays <cite>Ad, Bd</cite>, and <cite>Cd</cite> using <strong>cudaMalloc</strong>. Herein, <cite>h</cite> is for the ‘host’ (CPU) and <cite>d</cite> for the ‘device’ (GPU). The data is transferred from the CPU to the GPU using hipMemcpy, and then the GPU kernel is launched using the <cite>&lt;&lt;&lt;.&gt;&gt;&gt;</cite> syntax. All kernels launch are asynchronous. After launch the control returns to the <cite>main()</cite> and the code proceeds to the next instructions.</p>
<p>After the kernel execution, the result array <cite>Cd</cite> is copied back to the CPU using <strong>cudaMemcpy</strong>. The code then prints the reference and result arrays, calculates the error by comparing the reference and result arrays. Finally, the GPU and CPU memory are deallocated using <strong>cudaFree</strong> and <strong>free</strong> functions, respectively.</p>
<p>The host functions  <strong>cudaSetDevice</strong>, <strong>cudaMalloc</strong>, <strong>cudaMemcpy</strong>, and <strong>cudaFree</strong> are blocking, i.e. the code does not continues to next instructions until the operations are completed. However this is not the default behaviour, for many operations there are asynchronous equivalents and there are as well many library calls return the control to the <cite>main()</cite> after calling. This allows the developers to launch independent operations and overlap them.</p>
<p>In short, this code demonstrates how to utilize the CUDA and HIP to perform vector addition on a GPU, showcasing the steps involved in allocating memory, transferring data between the CPU and GPU, launching a kernel function, and handling the results. It serves as a starting point for GPU-accelerated computations using CUDA and HIP.
More examples for the vector (array) addition program are available at <a class="reference external" href="https://github.com/ENCCS/gpu-programming/tree/main/content/examples">content/examples</a>.</p>
<p>In order to practice the concepts shown above, edit the skeleton code in the repository and the code corresponding to setting the device, memory allocations and transfers, and the kernel execution.</p>
</section>
<section id="vector-addition-with-unified-memory">
<h4>Vector Addition with Unified Memory<a class="headerlink" href="#vector-addition-with-unified-memory" title="Link to this heading"></a></h4>
<p>For a while already GPUs support unified memory, which allows to use the same pointer for both CPU and GPU data. This simplifies developing codes by removing the explicit data transfers. The data resides on CPU until it is needed on GPU or vice-versa. However the data transfers still happens “under the hood” and the developer needs to construct the code to avoid unnecessary transfers. Below one can see the modified vector addition codes:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-Q1VEQQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-2-Q1VEQQ==" name="Q1VEQQ==" role="tab" tabindex="0">CUDA</button><button aria-controls="panel-2-SElQ" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-SElQ" name="SElQ" role="tab" tabindex="-1">HIP</button><button aria-controls="panel-2-U1lDTA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-U1lDTA==" name="U1lDTA==" role="tab" tabindex="-1">SYCL</button></div><div aria-labelledby="tab-2-Q1VEQQ==" class="sphinx-tabs-panel group-tab" id="panel-2-Q1VEQQ==" name="Q1VEQQ==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">vector_add</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">C</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10000</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Cref</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate the arrays using Unified Memory</span>
<span class="w">  </span><span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Cref</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// initialise data and calculate reference values on CPU</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">2.3</span><span class="p">;</span>
<span class="w">    </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.1</span><span class="p">;</span>
<span class="w">    </span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// define grid dimensions</span>
<span class="w">  </span><span class="n">dim3</span><span class="w"> </span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">;</span>
<span class="w">  </span><span class="n">threads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dim3</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="n">blocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dim3</span><span class="p">((</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">256</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Launch Kernel</span>
<span class="w">  </span><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span><span class="w"> </span><span class="c1">// Wait for the kernel to complete</span>

<span class="w">  </span><span class="c1">// At this point we want to access the data on CPU</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;reference: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<span class="w">         </span><span class="n">Cref</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;   result: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
<span class="w">         </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// confirm that results are correct</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">tolerance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-6</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fabs</span><span class="p">(</span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">diff</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tolerance</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">error</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;total error: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">error</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;  reference: %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;     result: %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Free the GPU arrays</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">Ah</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">Bh</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">Ch</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">Cref</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-SElQ" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-SElQ" name="SElQ" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;hip/hip_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">vector_add</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">C</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10000</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">Cref</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// Allocate the arrays using Unified Memory</span>
<span class="w">  </span><span class="n">hipMallocManaged</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">hipMallocManaged</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">hipMallocManaged</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">hipMallocManaged</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">Cref</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// Initialize data and calculate reference values on CPU</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">2.3</span><span class="p">;</span>
<span class="w">    </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.1</span><span class="p">;</span>
<span class="w">    </span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Ah</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Bh</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// All data at this point is on CPU</span>

<span class="w">  </span><span class="c1">// Define grid dimensions + launch the device kernel</span>
<span class="w">  </span><span class="n">dim3</span><span class="w"> </span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">;</span>
<span class="w">  </span><span class="n">threads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dim3</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="n">blocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dim3</span><span class="p">((</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">256</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Launch Kernel</span>
<span class="w">  </span><span class="c1">//  use</span>
<span class="w">  </span><span class="c1">// hipLaunchKernelGGL(vector_add, blocks, threads, 0, 0, Ah, Bh, Ch, N); // or</span>
<span class="w">  </span><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">Ah</span><span class="p">,</span><span class="w"> </span><span class="n">Bh</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipDeviceSynchronize</span><span class="p">();</span><span class="w"> </span><span class="c1">// Wait for the kernel to complete</span>

<span class="w">  </span><span class="c1">// At this point we want to access the data on the CPU</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;reference: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<span class="w">         </span><span class="n">Cref</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;   result: %f %f %f %f ... %f %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
<span class="w">         </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Confirm that results are correct</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">tolerance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-6</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fabs</span><span class="p">(</span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">diff</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tolerance</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">error</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;total error: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">error</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;  reference: %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;     result: %f at (42)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Ch</span><span class="p">[</span><span class="mi">42</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Free the Unified Memory arrays</span>
<span class="w">  </span><span class="n">hipFree</span><span class="p">(</span><span class="n">Ah</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipFree</span><span class="p">(</span><span class="n">Bh</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipFree</span><span class="p">(</span><span class="n">Ch</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipFree</span><span class="p">(</span><span class="n">Cref</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-U1lDTA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-U1lDTA==" name="U1lDTA==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10000</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// The queue will be executed on the best device in the system</span>
<span class="w">  </span><span class="c1">// We use in-order queue for simplicity</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">{{</span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">in_order</span><span class="p">()}};</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate the shared arrays</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize data and calculate reference values on CPU</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">2.3f</span><span class="p">;</span>
<span class="w">    </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">cos</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.1f</span><span class="p">;</span>
<span class="w">    </span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Define grid dimensions</span>
<span class="w">  </span><span class="c1">// We can specify the block size explicitly, but we don&#39;t have to</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">global_size</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">h</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">h</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">VectorAdd</span><span class="o">&gt;</span><span class="p">(</span><span class="n">global_size</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">threadId</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadId</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">       </span><span class="n">C</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">     </span><span class="p">});</span>
<span class="w">   </span><span class="p">}).</span><span class="n">wait</span><span class="p">();</span><span class="w"> </span><span class="c1">// Wait for the kernel to finish</span>

<span class="w">  </span><span class="c1">// Print reference and result values</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Reference: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; ... &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Result   : &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; ... &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Compare results and calculate the total error</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">tolerance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-6f</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">abs</span><span class="p">(</span><span class="n">Cref</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">diff</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tolerance</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">error</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Total error: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Reference:   &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">Cref</span><span class="p">[</span><span class="mi">42</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; at (42)&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Result   :   &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="mi">42</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; at (42)&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Free the shared memory</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>Now the arrays <cite>Ah</cite>, <cite>Bh</cite>, <cite>Ch</cite>, and <cite>Cref</cite> are using <cite>cudaMallocManaged</cite> to allocate Unified Memory. The <strong>vector_add kernel</strong> is launched by passing these Unified Memory pointers directly. After the kernel launch, <strong>cudaDeviceSynchronize</strong> is used to wait for the kernel to complete execution. Finally, <strong>cudaFree</strong> is used to free the Unified Memory arrays. The Unified Memory allows for transparent data migration between CPU and GPU, eliminating the need for explicit data transfers.</p>
<p>As an exercise modify the skeleton code for vector addition to use Unified Memory.</p>
<div class="dropdown admonition">
<p class="admonition-title">Basics - In short</p>
<ul class="simple">
<li><p>CUDA is developed by NVIDIA, while HIP is an open-source project (from AMD) for multi-platform GPU programming.</p></li>
<li><p>CUDA and HIP are GPU-focused programming models for optimized code execution on NVIDIA and AMD GPUs.</p></li>
<li><p>CUDA and HIP are similar, allowing developers to write GPU code in a syntax similar to CUDA and target multiple platforms.</p></li>
<li><p>CUDA and HIP are programming models focused solely on GPUs</p></li>
<li><p>CUDA and HIP offer high-performance computing capabilities and advanced features specific to GPU architectures, such as shared memory and memory management.</p></li>
<li><p>They provide highly GPU-accelerated libraries in various domains like linear algebra, signal processing, image processing, and machine learning.</p></li>
<li><p>Programming for GPUs involves managing data movement between host and accelerator memory.</p></li>
<li><p>Unified Memory simplifies data transfers by using the same pointer for CPU and GPU data, but code optimization is still necessary.</p></li>
</ul>
</div>
</section>
</section>
<section id="memory-optimizations">
<h3>Memory Optimizations<a class="headerlink" href="#memory-optimizations" title="Link to this heading"></a></h3>
<p>Vector addition is a relatively simple, straight forward case. Each thread reads data from memory, does an addition and then saves the result. Two adjacent threads access memory location in memory close to each other. Also the data is used only once. In practice this not the case. Also sometimes the same data is used several times resulting in additional memory accesses.</p>
<p>Memory optimization is one of the most important type of optimization done to efficiently use the GPUs. Before looking how it is done in practice let’s revisit some basic concepts about GPUs and execution model.</p>
<p>GPUs are comprised many light cores, the so-called Streaming Processors (SP) in CUDA, which are physically group together in units, i.e. Streaming Multi-Processors (SMP) in CUDA architecture (note that in AMD the equivalent is called Computing Units, while in Intel GPUs they are Execution Units). The work is done on GPUs by launching many threads each executing an instance of the same kernel. The order of execution is not defined, and the threads can only exchange information in specific conditions. Because of the way the SPs are grouped the threads are also grouped in <strong>blocks</strong>. Each <strong>block</strong> is assigned to an SMP, and can not be split. An SMP can have more than block residing at a moment, however there is no communications between the threads in different blocks. In addition to the SPs, each SMP contains very fast memory which in CUDA is referred to as <cite>shared memory</cite>. The threads in a block can read and write to the shared memory and use it as a user controlled cache. One thread can for example write to a location in the shared memory while another thread in the same block can read and use that data. In order to be sure that all threads in the block completed writing <strong>__syncthreads()</strong> function has to be used to make the threads in the block wait until all of them reached the specific place in the kernel. Another important aspect in the GPU programming model is that the threads in the block are not executed independently. The threads in a block are physically grouped in warps of size 32 in NVIDIA devices or wavefronts of size 32 or 64 in AMD devices (depending on device architecture). Intel devices are notable in that the warp size, called SIMD width, is highly configurable, with typical possible values of 8, 16, or 32 (depends on the hardware). All memory accesses of the global GPU memory are done per warp. When data is needed for some calculations a warp loads from the GPU memory blocks of specific size (64 or 128 Bytes). These operation is very expensive, it has a latency of hundreds of cycles. This means that the threads in a warp should work with elements of the data located close in the memory. In the vector addition two threads near each other, of index tid and tid+1, access elements adjacent in the GPU memory.</p>
<p>The shared memory can be used to improve performance in two ways. It is possible to avoid extra reads from the memory when several threads in the same block need the same data (see <a class="reference external" href="https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil">stencil</a> code) or it can be used to improve the memory access patterns like in the case of matrix transpose.</p>
<div class="dropdown admonition">
<p class="admonition-title">Memory, Execution - In short</p>
<ul class="simple">
<li><p>GPUs consist of streaming processors (SPs) grouped together in units, such as Streaming Multi-Processors (SMPs) in CUDA architecture.</p></li>
<li><p>Work on GPUs is done by launching threads, with each thread executing an instance of the same kernel, and the execution order is not defined.</p></li>
<li><p>Threads are organized into blocks, assigned to an SMP, and cannot be split, and there is no communication between threads in different blocks.</p></li>
<li><p>Each SMP contains shared memory, which acts as a user-controlled cache for threads within a block, allowing efficient data sharing and synchronization.</p></li>
<li><p>The shared memory can be used to avoid extra memory reads when multiple threads in the same block need the same data or to improve memory access patterns, such as in matrix transpose operations.</p></li>
<li><p>Memory accesses from global GPU memory are performed per warp (groups of threads), and loading data from GPU memory has high latency.</p></li>
<li><p>To optimize memory access, threads within a warp should work with adjacent elements in memory to reduce latency.</p></li>
<li><p>Proper utilization of shared memory can improve performance by reducing memory reads and enhancing memory access patterns.</p></li>
</ul>
</div>
<section id="matrix-transpose">
<h4>Matrix Transpose<a class="headerlink" href="#matrix-transpose" title="Link to this heading"></a></h4>
<p>Matrix transpose is a classic example where shared memory can significantly improve the performance. The use of shared memory reduces global memory accesses and exploits the high bandwidth and low latency of shared memory.</p>
<figure class="align-center">
<img alt="_images/transpose_img.png" src="_images/transpose_img.png" />
</figure>
<p>First as a reference we use a simple kernel which copy the data from one array to the other.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-Q1VEQQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-3-Q1VEQQ==" name="Q1VEQQ==" role="tab" tabindex="0">CUDA</button><button aria-controls="panel-3-SElQ" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-3-SElQ" name="SElQ" role="tab" tabindex="-1">HIP</button><button aria-controls="panel-3-U1lDTA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-3-U1lDTA==" name="U1lDTA==" role="tab" tabindex="-1">SYCL</button></div><div aria-labelledby="tab-3-Q1VEQQ==" class="sphinx-tabs-panel group-tab" id="panel-3-Q1VEQQ==" name="Q1VEQQ==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdlib&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4096</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4096</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">copy_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">x_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_index</span><span class="p">;</span>

<span class="w">  </span><span class="n">out</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">matrix_in</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">matrix_out</span><span class="p">;</span>

<span class="w">  </span><span class="n">matrix_in</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="n">matrix_out</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">matrix_in</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">rand</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">RAND_MAX</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_out</span><span class="p">;</span>

<span class="w">  </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_in</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
<span class="w">             </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Setup complete. Launching kernel </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">block_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">block_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Create events</span>
<span class="w">  </span><span class="n">cudaEvent_t</span><span class="w"> </span><span class="n">start_kernel_event</span><span class="p">;</span>
<span class="w">  </span><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">start_kernel_event</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaEvent_t</span><span class="w"> </span><span class="n">end_kernel_event</span><span class="p">;</span>
<span class="w">  </span><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">end_kernel_event</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Warm up the gpu!</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">copy_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dim3</span><span class="p">(</span><span class="n">block_x</span><span class="p">,</span><span class="w"> </span><span class="n">block_y</span><span class="p">),</span><span class="w"> </span><span class="n">dim3</span><span class="p">(</span><span class="n">tile_dim</span><span class="p">,</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">)</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
<span class="w">        </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">start_kernel_event</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">copy_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dim3</span><span class="p">(</span><span class="n">block_x</span><span class="p">,</span><span class="w"> </span><span class="n">block_y</span><span class="p">),</span><span class="w"> </span><span class="n">dim3</span><span class="p">(</span><span class="n">tile_dim</span><span class="p">,</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">)</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
<span class="w">        </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">end_kernel_event</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaEventSynchronize</span><span class="p">(</span><span class="n">end_kernel_event</span><span class="p">);</span>

<span class="w">  </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">time_kernel</span><span class="p">;</span>
<span class="w">  </span><span class="n">cudaEventElapsedTime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">time_kernel</span><span class="p">,</span><span class="w"> </span><span class="n">start_kernel_event</span><span class="p">,</span><span class="w"> </span><span class="n">end_kernel_event</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Kernel execution complete </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Event timings:</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;  %.6f ms - copy </span><span class="se">\n</span><span class="s">  Bandwidth %.6f GB/s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">time_kernel</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span>
<span class="w">         </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">10000</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(((</span><span class="kt">double</span><span class="p">)(</span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="kt">double</span><span class="p">)</span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">))</span><span class="w"> </span><span class="o">/</span>
<span class="w">             </span><span class="p">(</span><span class="n">time_kernel</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="p">));</span>

<span class="w">  </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">matrix_out</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
<span class="w">             </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-SElQ" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-3-SElQ" name="SElQ" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;hip/hip_runtime.h&gt;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdlib&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4096</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4096</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">copy_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">x_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_index</span><span class="p">;</span>

<span class="w">  </span><span class="n">out</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">matrix_in</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">matrix_out</span><span class="p">;</span>

<span class="w">  </span><span class="n">matrix_in</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="n">matrix_out</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">matrix_in</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">rand</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">RAND_MAX</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_out</span><span class="p">;</span>

<span class="w">  </span><span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="n">hipMemcpy</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">matrix_in</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
<span class="w">            </span><span class="n">hipMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Setup complete. Launching kernel </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">block_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">block_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Create events</span>
<span class="w">  </span><span class="n">hipEvent_t</span><span class="w"> </span><span class="n">start_kernel_event</span><span class="p">;</span>
<span class="w">  </span><span class="n">hipEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">start_kernel_event</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipEvent_t</span><span class="w"> </span><span class="n">end_kernel_event</span><span class="p">;</span>
<span class="w">  </span><span class="n">hipEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">end_kernel_event</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Warm up the gpu!</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">copy_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dim3</span><span class="p">(</span><span class="n">block_x</span><span class="p">,</span><span class="w"> </span><span class="n">block_y</span><span class="p">),</span><span class="w"> </span><span class="n">dim3</span><span class="p">(</span><span class="n">tile_dim</span><span class="p">,</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">)</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
<span class="w">        </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">hipEventRecord</span><span class="p">(</span><span class="n">start_kernel_event</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">copy_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dim3</span><span class="p">(</span><span class="n">block_x</span><span class="p">,</span><span class="w"> </span><span class="n">block_y</span><span class="p">),</span><span class="w"> </span><span class="n">dim3</span><span class="p">(</span><span class="n">tile_dim</span><span class="p">,</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">)</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
<span class="w">        </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">hipEventRecord</span><span class="p">(</span><span class="n">end_kernel_event</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipEventSynchronize</span><span class="p">(</span><span class="n">end_kernel_event</span><span class="p">);</span>

<span class="w">  </span><span class="n">hipDeviceSynchronize</span><span class="p">();</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">time_kernel</span><span class="p">;</span>
<span class="w">  </span><span class="n">hipEventElapsedTime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">time_kernel</span><span class="p">,</span><span class="w"> </span><span class="n">start_kernel_event</span><span class="p">,</span><span class="w"> </span><span class="n">end_kernel_event</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Kernel execution complete </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Event timings:</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;  %.6f ms - copy </span><span class="se">\n</span><span class="s">  Bandwidth %.6f GB/s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">time_kernel</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span>
<span class="w">         </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">10000</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(((</span><span class="kt">double</span><span class="p">)(</span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="kt">double</span><span class="p">)</span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">))</span><span class="w"> </span><span class="o">/</span>
<span class="w">             </span><span class="p">(</span><span class="n">time_kernel</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="p">));</span>

<span class="w">  </span><span class="n">hipMemcpy</span><span class="p">(</span><span class="n">matrix_out</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
<span class="w">            </span><span class="n">hipMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-U1lDTA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-3-U1lDTA==" name="U1lDTA==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4096</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4096</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>

<span class="c1">// Instead of defining kernel lambda at the place of submission,</span>
<span class="c1">// we can define it here:</span>
<span class="k">auto</span><span class="w"> </span><span class="n">copyKernel</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">nd_item</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">item</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_global_id</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_global_id</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_index</span><span class="p">;</span>
<span class="w">    </span><span class="n">out</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">matrix_in</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">matrix_out</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">matrix_in</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">rand</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">RAND_MAX</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Create queue on the default device with profiling enabled</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">queue</span><span class="p">{{</span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">in_order</span><span class="p">(),</span>
<span class="w">                     </span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">enable_profiling</span><span class="p">()}};</span>

<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_in</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">,</span><span class="w"> </span><span class="n">queue</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">,</span><span class="w"> </span><span class="n">queue</span><span class="p">);</span>

<span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">matrix_in</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="p">);</span>
<span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Setup complete. Launching kernel</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">global_size</span><span class="p">{</span><span class="n">height</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">},</span><span class="w"> </span><span class="n">local_size</span><span class="p">{</span><span class="n">tile_dim</span><span class="p">,</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">};</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">nd_range</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">kernel_range</span><span class="p">{</span><span class="n">global_size</span><span class="p">,</span><span class="w"> </span><span class="n">local_size</span><span class="p">};</span>

<span class="w">  </span><span class="c1">// Create events</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Warm up the GPU!</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">kernel_range</span><span class="p">,</span><span class="w"> </span><span class="n">copyKernel</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="p">));</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Unlike in CUDA or HIP, for SYCL we have to store all events</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">event</span><span class="o">&gt;</span><span class="w"> </span><span class="n">kernel_events</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">event</span><span class="w"> </span><span class="n">kernel_event</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">queue</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">kernel_range</span><span class="p">,</span><span class="w"> </span><span class="n">copyKernel</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="p">));</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">    </span><span class="n">kernel_events</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">kernel_event</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">first_kernel_started</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">kernel_events</span><span class="p">.</span><span class="n">front</span><span class="p">()</span>
<span class="w">          </span><span class="p">.</span><span class="n">get_profiling_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">event_profiling</span><span class="o">::</span><span class="n">command_start</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">last_kernel_ended</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">kernel_events</span><span class="p">.</span><span class="n">back</span><span class="p">()</span>
<span class="w">          </span><span class="p">.</span><span class="n">get_profiling_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">event_profiling</span><span class="o">::</span><span class="n">command_end</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">total_kernel_time_ns</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">last_kernel_ended</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">first_kernel_started</span><span class="p">);</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">time_kernels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">total_kernel_time_ns</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e6</span><span class="p">;</span><span class="w"> </span><span class="c1">// convert ns to ms</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">bandwidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">10000</span><span class="w"> </span><span class="o">*</span>
<span class="w">                     </span><span class="p">(((</span><span class="kt">double</span><span class="p">)(</span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="kt">double</span><span class="p">)</span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">))</span><span class="w"> </span><span class="o">/</span>
<span class="w">                     </span><span class="p">(</span><span class="n">time_kernels</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1024</span><span class="p">);</span>

<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Kernel execution complete</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Event timings:</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;  %.6lf ms - copy</span><span class="se">\n</span><span class="s">  Bandwidth %.6lf GB/s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">time_kernels</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span>
<span class="w">         </span><span class="n">bandwidth</span><span class="p">);</span>

<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">queue</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">queue</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>We note that this code does not do any calculations. Each thread reads one element and then writes it to another locations. By measuring the execution time of the kernel we can compute the effective bandwidth achieve by this kernel. We can measure the time using <strong>rocprof</strong> or <strong>cuda/hip events</strong>. On a NVIDIA V100 GPU this code achieves <cite>717 GB/s</cite> out of the theoretical peak <cite>900 GB/s</cite>.</p>
<p>Now we do the first iteration of the code, a naive transpose. The reads have a nice <cite>coalesced</cite> access pattern, but the writing is now very inefficient.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-Q1VEQS9ISVA=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-4-Q1VEQS9ISVA=" name="Q1VEQS9ISVA=" role="tab" tabindex="0">CUDA/HIP</button><button aria-controls="panel-4-U1lDTA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-4-U1lDTA==" name="U1lDTA==" role="tab" tabindex="-1">SYCL</button></div><div aria-labelledby="tab-4-Q1VEQS9ISVA=" class="sphinx-tabs-panel group-tab" id="panel-4-Q1VEQS9ISVA=" name="Q1VEQS9ISVA=" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose_naive_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span>
<span class="w">                                       </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">x_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">in_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_index</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">out_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_index</span><span class="p">;</span>

<span class="w">  </span><span class="n">out</span><span class="p">[</span><span class="n">out_index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">in_index</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-U1lDTA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-4-U1lDTA==" name="U1lDTA==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">transposeKernelNaive</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">nd_item</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">item</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_global_id</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_global_id</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">in_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_index</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">out_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_index</span><span class="p">;</span>
<span class="w">    </span><span class="n">out</span><span class="p">[</span><span class="n">out_index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">in_index</span><span class="p">];</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>Checking the index <cite>in_index</cite> we see that two adjacent threads (<cite>threadIx.x, threadIdx.x+1</cite>) access location in memory near each other. However the writes are not. Threads access data which in a strided way. Two adjacent threads access data separated by <cite>height</cite> elements. This practically results in 32 memory operations, however due to under the hood optimizations the achieved bandwidth is <cite>311 GB/s</cite>.</p>
<p>We can improve the code by reading the data in a <cite>coalesced</cite> way, save it in the shared memory row by row and then write in the global memory column by column.</p>
<blockquote>
<div><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-Q1VEQS9ISVA=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-5-Q1VEQS9ISVA=" name="Q1VEQS9ISVA=" role="tab" tabindex="0">CUDA/HIP</button><button aria-controls="panel-5-U1lDTA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-5-U1lDTA==" name="U1lDTA==" role="tab" tabindex="-1">SYCL</button></div><div aria-labelledby="tab-5-Q1VEQS9ISVA=" class="sphinx-tabs-panel group-tab" id="panel-5-Q1VEQS9ISVA=" name="Q1VEQS9ISVA=" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose_SM_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span>
<span class="w">                                    </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">tile_dim</span><span class="p">][</span><span class="n">tile_dim</span><span class="p">];</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">in_index</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="p">(</span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">out_index</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="p">(</span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

<span class="w">  </span><span class="n">tile</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">in_index</span><span class="p">];</span>

<span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>

<span class="w">  </span><span class="n">out</span><span class="p">[</span><span class="n">out_index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-U1lDTA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-5-U1lDTA==" name="U1lDTA==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">transposeKernelSM</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span>
<span class="w">                       </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">local_accessor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tile</span><span class="p">{{</span><span class="n">tile_dim</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">},</span><span class="w"> </span><span class="n">cgh</span><span class="p">};</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">nd_item</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">item</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x_local_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_local_id</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y_local_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_local_id</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">in_index</span><span class="w"> </span><span class="o">=</span>
<span class="w">        </span><span class="p">(</span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_local_index</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_local_index</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">out_index</span><span class="w"> </span><span class="o">=</span>
<span class="w">        </span><span class="p">(</span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_local_index</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_local_index</span><span class="p">);</span>

<span class="w">    </span><span class="n">tile</span><span class="p">[</span><span class="n">y_local_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_local_index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">in_index</span><span class="p">];</span>
<span class="w">    </span><span class="n">item</span><span class="p">.</span><span class="n">barrier</span><span class="p">();</span>
<span class="w">    </span><span class="n">out</span><span class="p">[</span><span class="n">out_index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">x_local_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_local_index</span><span class="p">];</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</div></blockquote>
<p>We define a <strong>tile_dim</strong> constant to determine the size of the shared memory tile. The matrix transpose kernel uses a 2D grid of thread blocks, where each thread block operates on a <cite>tile_dim x tile_dim</cite> tile of the input matrix.</p>
<p>The kernel first loads data from the global memory into the shared memory tile. Each thread loads a single element from the input matrix into the shared memory tile. Then, a <strong>__syncthreads()</strong> barrier ensures that all threads have finished loading data into shared memory before proceeding.</p>
<p>Next, the kernel writes the transposed data from the shared memory tile back to the output matrix in global memory. Each thread writes a single element from the shared memory tile to the output matrix.
By using shared memory, this optimized implementation reduces global memory accesses and exploits memory coalescence, resulting in improved performance compared to a naive transpose implementation.</p>
<p>This kernel achieved on NVIDIA V100 <cite>674 GB/s</cite>.</p>
<p>This is pretty close to the bandwidth achieved by the simple copy kernel, but there is one more thing to improve.</p>
<p>Shared memory is composed of <cite>banks</cite>. Each banks can service only one request at the time. Bank conflicts happen when more than 1 thread in a specific warp try to access data in bank. The bank conflicts are resolved by serializing the accesses resulting in less performance. In the above example when data is saved to the shared memory, each thread in the warp will save an element of the data in a different one. Assuming that shared memory has 16 banks after writing each bank will contain one column. At the last step when we write from the shared memory to the global memory each warp load data from the same bank. A simple way to avoid this is by just padding the temporary array.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-Q1VEQS9ISVA=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-6-Q1VEQS9ISVA=" name="Q1VEQS9ISVA=" role="tab" tabindex="0">CUDA/HIP</button><button aria-controls="panel-6-U1lDTA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-6-U1lDTA==" name="U1lDTA==" role="tab" tabindex="-1">SYCL</button></div><div aria-labelledby="tab-6-Q1VEQS9ISVA=" class="sphinx-tabs-panel group-tab" id="panel-6-Q1VEQS9ISVA=" name="Q1VEQS9ISVA=" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose_SM_nobc_kernel</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span>
<span class="w">                                         </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">tile_dim</span><span class="p">][</span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">];</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">in_index</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="p">(</span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">out_index</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="p">(</span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

<span class="w">  </span><span class="n">tile</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">in_index</span><span class="p">];</span>

<span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>

<span class="w">  </span><span class="n">out</span><span class="p">[</span><span class="n">out_index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-U1lDTA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-6-U1lDTA==" name="U1lDTA==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">transposeKernelSMNoBC</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">,</span>
<span class="w">                           </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">local_accessor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tile</span><span class="p">{{</span><span class="n">tile_dim</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)},</span><span class="w"> </span><span class="n">cgh</span><span class="p">};</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">nd_item</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">item</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tile_dim</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x_local_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_local_id</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y_local_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_local_id</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">in_index</span><span class="w"> </span><span class="o">=</span>
<span class="w">        </span><span class="p">(</span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_local_index</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_local_index</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">out_index</span><span class="w"> </span><span class="o">=</span>
<span class="w">        </span><span class="p">(</span><span class="n">x_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_local_index</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">y_tile_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_local_index</span><span class="p">);</span>

<span class="w">    </span><span class="n">tile</span><span class="p">[</span><span class="n">y_local_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x_local_index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">in_index</span><span class="p">];</span>
<span class="w">    </span><span class="n">item</span><span class="p">.</span><span class="n">barrier</span><span class="p">();</span>
<span class="w">    </span><span class="n">out</span><span class="p">[</span><span class="n">out_index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">x_local_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">tile_dim</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y_local_index</span><span class="p">];</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>By padding the array the data is slightly shifting it resulting in no bank conflicts. The effective bandwidth for this kernel is <cite>697 GB/s</cite>.</p>
<div class="dropdown admonition">
<p class="admonition-title">Using sharing memory as a cache - In short</p>
<ul class="simple">
<li><p>Shared memory can significantly improve performance in operations like matrix transpose.</p></li>
<li><p>Shared memory reduces global memory accesses and exploits the high bandwidth and low latency of shared memory.</p></li>
<li><p>An optimized implementation utilizes shared memory, loads data coalescedly, and performs transpose operations.</p></li>
<li><p>The optimized implementation uses a 2D grid of thread blocks and a shared memory tile size determined by a constant.</p></li>
<li><p>The kernel loads data from global memory into the shared memory tile and uses a synchronization barrier.</p></li>
<li><p>To avoid bank conflicts in shared memory, padding the temporary array is a simple solution.</p></li>
</ul>
</div>
</section>
<section id="reductions">
<h4>Reductions<a class="headerlink" href="#reductions" title="Link to this heading"></a></h4>
<p><cite>Reductions</cite> refer to operations in which the elements of an array are aggregated in a single value through operations such as summing, finding the maximum or minimum, or performing logical operations.</p>
<p>In the serial approach, the reduction is performed sequentially by iterating through the collection of values and accumulating the result step by step. This will be enough for small sizes, but for big problems this results in significant time spent in this part of an application. On a GPU, this approach is not feasible. Using just one thread to do this operation means the rest of the GPU is wasted. Doing reduction in parallel is a little tricky. In order for a thread to do work, it needs to have some partial result to use. If we launch, for example, a kernel performing a simple vector summation, <code class="docutils literal notranslate"><span class="pre">sum[0]+=a[tid]</span></code>, with <cite>N</cite> threads we notice that this would result in undefined behaviour. GPUs have mechanisms to access the memory and lock the access for other threads while 1 thread is doing some operations to a given data via <strong>atomics</strong>, however this means that the memory access gets again to be serialized. There is not much gain.
We note that when doing reductions the order of the iterations is not important (barring the typical non-associative behavior of floating-point operations). Also we can we might have to divide our problem in several subsets and do the reduction operation for each subset separately. On the GPUs, since the GPU threads are grouped in blocks, the size of the subset based on that. Inside the block, threads can cooperate with each other, they can share data via the shared memory and can be synchronized as well. All threads read the data to be reduced, but now we have significantly less partial results to deal with. In general, the size of the block ranges from 256 to 1024 threads. In case of very large problems, after this procedure if we are left too many partial results this step can be repeated.</p>
<p>At the block level we still have to perform a reduction in an efficient way. Doing it serially means that we are not using all GPU cores (roughly 97% of the computing capacity is wasted). Doing it naively parallel using <strong>atomics</strong>, but on the shared memory is also not a good option. Going back back to the fact the reduction operations are commutative and associative we can set each thread to “reduce” two elements of the local part of the array. Shared memory can be used to store the partial “reductions” as shown below in the code:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-7-Q1VEQS9ISVA=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-7-Q1VEQS9ISVA=" name="Q1VEQS9ISVA=" role="tab" tabindex="0">CUDA/HIP</button><button aria-controls="panel-7-U1lDTA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-7-U1lDTA==" name="U1lDTA==" role="tab" tabindex="-1">SYCL</button></div><div aria-labelledby="tab-7-Q1VEQS9ISVA=" class="sphinx-tabs-panel group-tab" id="panel-7-Q1VEQS9ISVA=" name="Q1VEQS9ISVA=" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#define tpb 512 </span><span class="c1">// size in this case has to be known at compile time</span>
<span class="c1">// this kernel has to be launched with at least N/2 threads</span>
<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">reduction_one</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">sum</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">){</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ibl</span><span class="o">=</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">+</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ind</span><span class="o">=</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">ibl</span><span class="p">;</span>

<span class="w">  </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">shtmp</span><span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">tpb</span><span class="p">];</span>
<span class="w">  </span><span class="n">shtmp</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="c1">// for sums we initiate with 0, for other operations should be different</span>
<span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">ind</span><span class="o">&lt;</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">     </span><span class="n">shtmp</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">ind</span><span class="o">+</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="o">&lt;</span><span class="n">N</span><span class="p">)</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">     </span><span class="n">shtmp</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="n">tpb</span><span class="p">]</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="o">+</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
<span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">s</span><span class="o">=</span><span class="n">tpb</span><span class="p">;</span><span class="n">s</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">;</span><span class="n">s</span><span class="o">&gt;&gt;=</span><span class="mi">1</span><span class="p">){</span>
<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">&lt;</span><span class="n">s</span><span class="p">){</span>
<span class="w">       </span><span class="n">shtmp</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="o">+=</span><span class="n">shtmp</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="n">s</span><span class="p">];}</span>
<span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="n">sum</span><span class="p">[</span><span class="n">ibl</span><span class="p">]</span><span class="o">=</span><span class="n">shtmp</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"> </span><span class="c1">// each block saves its partial result to an array</span>
<span class="w">    </span><span class="c1">// atomicAdd(&amp;sum[0], shene[0]); // alternatively could aggregate everything together at index 0. Only use when there not many partial sums left</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-U1lDTA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-7-U1lDTA==" name="U1lDTA==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// SYCL has built-in sycl::reduction primitive, the use of which is demonstrated</span>
<span class="c1">// in the &quot;Portable kernel models&quot; chapter. Here is how the reduction can be</span>
<span class="c1">// implemented manually:</span>
<span class="k">auto</span><span class="w"> </span><span class="n">redutionKernel</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">sum</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">local_accessor</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">shtmp</span><span class="p">{{</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tpb</span><span class="p">},</span><span class="w"> </span><span class="n">cgh</span><span class="p">};</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">nd_item</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">item</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ibl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_global_id</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_local_id</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">shtmp</span><span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="n">get_local_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ind</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">shtmp</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">shtmp</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ind</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">shtmp</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tpb</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">shtmp</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tpb</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tpb</span><span class="p">;</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">shtmp</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">shtmp</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="p">];</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="n">item</span><span class="p">.</span><span class="n">barrier</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="p">(</span><span class="n">useHostReduction</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">sum</span><span class="p">[</span><span class="n">ibl</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shtmp</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"> </span><span class="c1">// each block saves its partial result to an array</span>
<span class="w">      </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// Alternatively, we could agregate everything together at index 0.</span>
<span class="w">        </span><span class="c1">// Only useful when there not many partial sums left and when the device</span>
<span class="w">        </span><span class="c1">// supports atomic operations on FP64/double operands.</span>
<span class="w">        </span><span class="n">sycl</span><span class="o">::</span><span class="n">atomic_ref</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">memory_order</span><span class="o">::</span><span class="n">relaxed</span><span class="p">,</span>
<span class="w">                         </span><span class="n">sycl</span><span class="o">::</span><span class="n">memory_scope</span><span class="o">::</span><span class="n">device</span><span class="p">,</span>
<span class="w">                         </span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">address_space</span><span class="o">::</span><span class="n">global_space</span><span class="o">&gt;</span>
<span class="w">            </span><span class="n">ref</span><span class="p">(</span><span class="n">sum</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">        </span><span class="n">ref</span><span class="p">.</span><span class="n">fetch_add</span><span class="p">(</span><span class="n">shtmp</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>In the kernel we have each GPU performing thread a reduction of two elements from the local portion of the array. If we have <cite>tpb</cite> GPU threads per block, we utilize them to store <cite>2xtpb elements</cite> in the local shared memory. To ensure synchronization until all data is available in the shared memory, we employ the <cite>syncthreads()</cite> function.</p>
<p>Next, we instruct each thread to “reduce” the element in the array at <cite>threadIdx.x</cite> with the element at <cite>threadIdx.x+tpb</cite>. As this operation saves the result back into the shared memory, we once again employ <cite>syncthreads()</cite>. By doing this, we effectively halve the number of elements to be reduced.</p>
<p>This procedure can be repeated, but now we only utilize <cite>tpb/2 threads</cite>. Each thread is responsible for “reducing” the element in the array at <cite>threadIdx.x</cite> with the element at <cite>threadIdx.x+tpb/2</cite>. After this step, we are left with <cite>tpb/4</cite> numbers to be reduced. We continue applying this procedure until only one number remains.</p>
<p>At this point, we can either “reduce” the final number with a global partial result using atomic read and write operations, or we can save it into an array for further processing.</p>
<figure class="align-center" id="id1">
<img alt="_images/Reduction.png" src="_images/Reduction.png" />
<figcaption>
<p><span class="caption-text">Schematic representation on the reduction algorithm with 8 GPU threads.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>For a detail analysis of how to optimize reduction operations in CUDA/HIP check this presentation <a class="reference external" href="https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf">Optimizing Parallel Reduction in CUDA</a></p>
<div class="dropdown admonition">
<p class="admonition-title">Reductions - In short</p>
<ul class="simple">
<li><p>Reductions refer to aggregating elements of an array into a single value through operations like summing, finding maximum or minimum, or performing logical operations.</p></li>
<li><p>Performing reductions sequentially in a serial approach is inefficient for large problems, while parallel reduction on GPUs offers better performance.</p></li>
<li><p>Parallel reduction on GPUs involves dividing the problem into subsets, performing reductions within blocks of threads using shared memory, and repeatedly reducing the number of elements (two per GPU thread) until only one remains.</p></li>
</ul>
</div>
</section>
<section id="overlapping-computations-and-memory-transfer-cuda-hip-streams">
<h4>Overlapping Computations and Memory transfer. CUDA/HIP Streams<a class="headerlink" href="#overlapping-computations-and-memory-transfer-cuda-hip-streams" title="Link to this heading"></a></h4>
<p>Modern GPUs can overlap independent operations. They can do transfers between CPU and GPU and execute kernels in the same time, or they can execute kernels concurrently. CUDA/HIP streams are independent execution units, a sequence of operations that execute in issue-order on the GPU. The operations issue in different streams can be executed concurrently.</p>
<p>Consider the previous case of vector addition, which involves copying data from CPU to GPU, computations and then copying back the result to GPU. In this way nothing can be overlap.</p>
<p>We can improve the performance by dividing the problem in smaller independent parts. Let’s consider 5 streams and consider the case where copy in one direction and computation take the same amount of time.</p>
<figure class="align-center">
<img alt="_images/StreamsTimeline.png" src="_images/StreamsTimeline.png" />
</figure>
<p>After the first and second stream copy data to the GPU, the GPU is practically occupied all time. We can see that significant performance  improvements can be obtained by eliminating the time in which the GPU is idle, waiting for data to arrive from the CPU. This very useful for problems where there is often communication to the CPU because the GPU memory can not fit all the problem or the application runs in a multi-GPU set up and communication is needed often.</p>
<p>We can apply this to the vector addition problem above.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-8-Q1VEQQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-8-Q1VEQQ==" name="Q1VEQQ==" role="tab" tabindex="0">CUDA</button><button aria-controls="panel-8-SElQ" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-8-SElQ" name="SElQ" role="tab" tabindex="-1">HIP</button></div><div aria-labelledby="tab-8-Q1VEQQ==" class="sphinx-tabs-panel group-tab" id="panel-8-Q1VEQQ==" name="Q1VEQQ==" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Distribute kernel for &#39;n_streams&#39; streams, and record each stream&#39;s timing</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n_streams</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">stream_size</span><span class="p">;</span>
<span class="w">  </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">start_event</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w"> </span><span class="c1">// stamp the moment when the kernel is submitted on stream i</span>

<span class="w">  </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Ad</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w">  </span><span class="o">&amp;</span><span class="n">Ah</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">n_streams</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Bd</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w">  </span><span class="o">&amp;</span><span class="n">Bh</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">n_streams</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="n">gridsize</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_streams</span><span class="p">,</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Ad</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Bd</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Cd</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">n_streams</span><span class="p">);</span><span class="w"> </span><span class="c1">//each call processes N/n_streams elements</span>
<span class="w">  </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Ch</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w">  </span><span class="o">&amp;</span><span class="n">Cd</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">n_streams</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">  </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">stop_event</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w">  </span><span class="c1">// stamp the moment when the kernel on stream i finished</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-SElQ" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-8-SElQ" name="SElQ" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Distribute kernel for &#39;n_streams&#39; streams, and record each stream&#39;s timing</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n_streams</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="n">stream_size</span><span class="p">);</span>
<span class="w">  </span><span class="n">hipEventRecord</span><span class="p">(</span><span class="n">start_event</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w"> </span><span class="c1">// stamp the moment when the kernel is submitted on stream i</span>

<span class="w">  </span><span class="n">hipMemcpyAsync</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Ad</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w">  </span><span class="o">&amp;</span><span class="n">Ah</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">n_streams</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">hipMemcpyHostToDevice</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">hipMemcpyAsync</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Bd</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w">  </span><span class="o">&amp;</span><span class="n">Bh</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">n_streams</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">hipMemcpyHostToDevice</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="n">gridsize</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_streams</span><span class="p">,</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Ad</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Bd</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Cd</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">n_streams</span><span class="p">);</span><span class="w"> </span><span class="c1">//each call processes N/n_streams elements</span>
<span class="w">  </span><span class="n">hipMemcpyAsync</span><span class="p">(</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Ch</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w">  </span><span class="o">&amp;</span><span class="n">Cd</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">n_streams</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">hipMemcpyDeviceToHost</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">  </span><span class="n">hipEventRecord</span><span class="p">(</span><span class="n">stop_event</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w">  </span><span class="c1">// stamp the moment when the kernel on stream i finished</span>
<span class="p">}</span>
<span class="p">...</span>
</pre></div>
</div>
</div></div>
<p>Instead of having one copy to gpu, one execution of the kernel and one copy back, we now have several of these calls independent of each other.</p>
<p>Note that even when streams are not explicitly used it is possible to launch all the GPU operations asynchronous and overlap CPU operations (such I/O) and GPU operations.
In order to learn more about how to improve performance using streams check the NVIDIA blog <a class="reference external" href="https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/">How to Overlap Data Transfers in CUDA C/C++</a>.</p>
<div class="dropdown admonition">
<p class="admonition-title">Streams - In short</p>
<ul class="simple">
<li><p>CUDA/HIP streams are independent execution contexts on the GPU that allow for concurrent execution of operations issued in different streams.</p></li>
<li><p>Using streams can improve GPU performance by overlapping operations such as data transfers between CPU and GPU and kernel executions.</p></li>
<li><p>By dividing a problem into smaller independent parts and utilizing multiple streams, the GPU can avoid idle time, resulting in significant performance improvements, especially for problems with frequent CPU communication or multi-GPU setups.</p></li>
</ul>
</div>
</section>
</section>
<section id="pros-and-cons-of-native-programming-models">
<h3>Pros and cons of native programming models<a class="headerlink" href="#pros-and-cons-of-native-programming-models" title="Link to this heading"></a></h3>
<p>There are advantages and limitations to CUDA and HIP:</p>
<dl class="simple">
<dt>CUDA Pros:</dt><dd><ol class="arabic simple">
<li><p>Performance Boost: CUDA is designed for NVIDIA GPUs and delivers excellent performance.</p></li>
<li><p>Wide Adoption: CUDA is popular, with many resources and tools available.</p></li>
<li><p>Mature Ecosystem: NVIDIA provides comprehensive libraries and tools for CUDA programming.</p></li>
</ol>
</dd>
<dt>HIP Pros:</dt><dd><ol class="arabic simple">
<li><p>Portability: HIP is portable across different GPU architectures.</p></li>
<li><p>Open Standards: HIP is based on open standards, making it more accessible.</p></li>
<li><p>Growing Community: The HIP community is growing, providing more resources and support.</p></li>
</ol>
</dd>
<dt>Cons:</dt><dd><ol class="arabic simple" start="0">
<li><p>Exclusive for GPUs</p></li>
<li><p>Vendor Lock-in: CUDA is exclusive to NVIDIA GPUs, limiting compatibility.</p></li>
<li><p>Learning Curve: Both CUDA and HIP require learning GPU programming concepts.</p></li>
<li><p>Limited Hardware Support: HIP may face limitations on older or less common GPUs.</p></li>
</ol>
</dd>
</dl>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>CUDA and HIP are two GPU programming models</p></li>
<li><p>Memory optimizations are very important</p></li>
<li><p>Asynchronous launching can be used to overlap operations and avoid idle GPU</p></li>
</ul>
</div>
</section>
</section>
<span id="document-8-portable-kernel-models"></span><section id="portable-kernel-based-models">
<span id="portable-kernel-models"></span><h2>Portable kernel-based models<a class="headerlink" href="#portable-kernel-based-models" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>How to program GPUs with alpaka, C++ StdPar, Kokkos, OpenCL, and SYCL?</p></li>
<li><p>What are the differences between these programming models.</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Be able to use portable kernel-based models to write simple codes</p></li>
<li><p>Understand how different approaches to memory and synchronization in Kokkos and SYCL work</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>60 min teaching</p></li>
<li><p>30 min exercises</p></li>
</ul>
</div>
<p>The goal of the cross-platform portability ecosystems is to allow the same code to run on multiple architectures, therefore reducing code duplication. They are usually based on C++, and use function objects/lambda functions to define the loop body (i.e., the kernel), which can run on multiple architectures like CPU, GPU, and FPGA from different vendors. An exception to this is OpenCL, which originally offered only a C API (although currently also C++ API is available), and uses a separate-source model for the kernel code. However, unlike in many conventional CUDA or HIP implementations, the portability ecosystems require kernels to be written only once if one prefers to run it on CPU and GPU for example. Some notable cross-platform portability ecosystems are alpaka, Kokkos, OpenCL, RAJA, and SYCL. Kokkos, alpaka, and RAJA are individual projects whereas OpenCL and SYCL are standards followed by several projects implementing (and extending) them. For example, some notable SYCL implementations include <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html">Intel oneAPI DPC++</a>, <a class="reference external" href="https://github.com/AdaptiveCpp/AdaptiveCpp/">AdaptiveCpp</a> (previously known as hipSYCL or Open SYCL), <a class="reference external" href="https://github.com/triSYCL/triSYCL">triSYCL</a>, and <a class="reference external" href="https://developer.codeplay.com/products/computecpp/ce/home/">ComputeCPP</a>.</p>
<section id="c-stdpar">
<h3>C++ StdPar<a class="headerlink" href="#c-stdpar" title="Link to this heading"></a></h3>
<p>In C++17, the initial support for parallel execution of standard algorithms has been introduced.
Most algorithms available via the standard <code class="docutils literal notranslate"><span class="pre">&lt;algorithms&gt;</span></code> header were given an overload accepting with an <a class="reference external" href="https://en.cppreference.com/w/cpp/algorithm">*execution policy*</a> argument which allows the programmer to request parallel execution of the standard library function.
While the main goal was to allow low-effort, high-level interface to run existing algorithms like <code class="docutils literal notranslate"><span class="pre">std::sort</span></code> on many CPU cores, implementations are allowed to use other hardware, and functions like <code class="docutils literal notranslate"><span class="pre">std::for_each</span></code> or <code class="docutils literal notranslate"><span class="pre">std::transform</span></code> offer great flexibility in writing the algorithm.</p>
<p>C++ StdPar, also called Parallel STL or PSTL, could be considered similar to directive-based models, as it is very high-level and does not give the programmer fine-grained control over data movement or any access to hardware-specific features like shared (local) memory.
Even the GPU to run on is selected automatically, since standard C++ does not have the concept of a <em>device</em> (but there are vendor extensions allowing the programmer more control)
However, for applications that already relies on algorithms from C++ standard library, StdPar can be a good way to reap the performance benefits of both CPUs and GPUs with minimal code modifications.</p>
<p>For GPU programming, all three vendors offer their implementations of StdPar with the ability to offload code to the GPU: NVIDIA has <code class="docutils literal notranslate"><span class="pre">nvc++</span></code>, AMD has experimental <a class="reference external" href="https://github.com/ROCm/roc-stdpar">roc-stdpar</a>, and Intel offers StdPar offload with their oneAPI compiler. <a class="reference external" href="https://github.com/AdaptiveCpp/AdaptiveCpp/">AdaptiveCpp</a> offers an independent StdPar implementation, able to target devices from all three vendors. While being a part of the C++ standard, the level of support and the maturity of StdPar implementations varies a lot between different compilers: not all compilers support all algorithms, and different heuristics for mapping the algorithm to hardware and for managing data movement can have effect on performance.</p>
<section id="stdpar-compilation">
<h4>StdPar compilation<a class="headerlink" href="#stdpar-compilation" title="Link to this heading"></a></h4>
<p>The build process depends a lot on the used compiler:</p>
<ul class="simple">
<li><p>AdaptiveCpp: Add <code class="docutils literal notranslate"><span class="pre">--acpp-stdpar</span></code> flag when calling <code class="docutils literal notranslate"><span class="pre">acpp</span></code>.</p></li>
<li><p>Intel oneAPI: Add <code class="docutils literal notranslate"><span class="pre">-fsycl</span> <span class="pre">-fsycl-pstl-offload=gpu</span></code> flags when calling <code class="docutils literal notranslate"><span class="pre">icpx</span></code>.</p></li>
<li><p>NVIDIA NVC++: Add <code class="docutils literal notranslate"><span class="pre">-stdpar</span></code> flag when calling <code class="docutils literal notranslate"><span class="pre">nvc++</span></code> (not supported with plain <code class="docutils literal notranslate"><span class="pre">nvcc</span></code>).</p></li>
</ul>
</section>
<section id="stdpar-programming">
<h4>StdPar programming<a class="headerlink" href="#stdpar-programming" title="Link to this heading"></a></h4>
<p>In its simplest form, using C++ standard parallelism requires including an additional <code class="docutils literal notranslate"><span class="pre">&lt;execution&gt;</span></code> header and adding one argument to a supported standard library function.</p>
<p>For example, let’s look at the following sequential code sorting a vector:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To make it run sorting on the GPU, only a minor modification is needed:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span><span class="c1"> // To get std::execution</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par_unseq</span><span class="p">,</span><span class="w"> </span><span class="c1">// This algorithm can be run in parallel</span>
<span class="w">      </span><span class="n">a</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">end</span><span class="p">()</span>
<span class="w">    </span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Now, when compiled with one of the supported compilers, the code will run the sorting on a GPU.</p>
<p>While the can initially seem very limiting, many standard algorithms, such as <code class="docutils literal notranslate"><span class="pre">std::transform</span></code>, <code class="docutils literal notranslate"><span class="pre">std::accumulate</span></code>, <code class="docutils literal notranslate"><span class="pre">std::transform_reduce</span></code>, and <code class="docutils literal notranslate"><span class="pre">std::for_each</span></code> can run custom functions over an array, thus allowing one to offload an arbitrary algorithm, as long as it does not violate typical limitations of GPU kernels, such as not throwing any exceptions and not doing system calls.</p>
</section>
<section id="stdpar-execution-policies">
<h4>StdPar execution policies<a class="headerlink" href="#stdpar-execution-policies" title="Link to this heading"></a></h4>
<p>In C++, there are four different execution policies to choose from:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">std::execution::seq</span></code>: run algorithm serially, don’t parallelize it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">std::execution::par</span></code>: allow parallelizing the algorithm (as if using multiple threads),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">std::execution::unseq</span></code>: allow vectorizing the algorithm (as if using SIMD),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">std::execution::par_unseq</span></code>: allow both vectorizing and parallelizing the algorithm.</p></li>
</ul>
<p>The main difference between <code class="docutils literal notranslate"><span class="pre">par</span></code> and <code class="docutils literal notranslate"><span class="pre">unseq</span></code> is related to thread progress and locks: using <code class="docutils literal notranslate"><span class="pre">unseq</span></code> or <code class="docutils literal notranslate"><span class="pre">par_unseq</span></code> requires that the algorithms does not contain mutexes and other locks between the processes, while <code class="docutils literal notranslate"><span class="pre">par</span></code> does not have this limitation.</p>
<p>For GPU, the optimal choice is <code class="docutils literal notranslate"><span class="pre">par_unseq</span></code>, since this places the least requirement on the compiler in terms of operation ordering.
While <code class="docutils literal notranslate"><span class="pre">par</span></code> is also supported in some cases, it is best avoided, both due to limited compiler support and as an indication that the algorithm is likely a poor fit for the hardware.</p>
</section>
</section>
<section id="kokkos">
<h3>Kokkos<a class="headerlink" href="#kokkos" title="Link to this heading"></a></h3>
<p>Kokkos is an open-source performance portability ecosystem for parallelization on large heterogeneous hardware architectures of which development has mostly taken place on Sandia National Laboratories. The project started in 2011 as a parallel C++ programming model, but have since expanded into a more broad ecosystem including Kokkos Core (the programming model), Kokkos Kernels (math library), and Kokkos Tools (debugging, profiling and tuning tools). By preparing proposals for the C++ standard committee, the project also aims to influence the ISO/C++ language standard such that, eventually, Kokkos capabilities will become native to the language standard. A more detailed introduction is found <a class="reference external" href="https://www.sandia.gov/news/publications/hpc-annual-reports/article/kokkos/">HERE</a>.</p>
<p>The Kokkos library provides an abstraction layer for a variety of different parallel programming models, currently CUDA, HIP, SYCL, HPX, OpenMP, and C++ threads. Therefore, it allows better portability across different hardware manufactured by different vendors, but introduces an additional dependency to the software stack. For example, when using CUDA, only CUDA installation is required, but when using Kokkos with NVIDIA GPUs, Kokkos and CUDA installation are both required. Kokkos is not a very popular choice for parallel programming, and therefore, learning and using Kokkos can be more difficult compared to more established programming models such as CUDA, for which a much larger amount of search results and Stack Overflow discussions can be found.</p>
<section id="kokkos-compilation">
<h4>Kokkos compilation<a class="headerlink" href="#kokkos-compilation" title="Link to this heading"></a></h4>
<p>Furthermore, one challenge with some cross-platform portability libraries is that even on the same system, different projects may require different combinations of compilation settings for the portability library. For example, in Kokkos, one project may wish the default execution space to be a CUDA device, whereas another requires a CPU. Even if the projects prefer the same execution space, one project may desire the Unified Memory to be the default memory space and the other may wish to use pinned GPU memory. It may be burdensome to maintain a large number of library instances on a single system.</p>
<p>However, Kokkos offers a simple way to compile Kokkos library simultaneously with the user project. This is achieved by specifying Kokkos compilation settings (see <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html">HERE</a>) and including the Kokkos Makefile in the user Makefile. CMake is also supported. This way, the user application and Kokkos library are compiled together. The following is an example Makefile for a single-file Kokkos project (hello.cpp) that uses CUDA (Volta architecture) as the backend (default execution space) and Unified Memory as the default memory space:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Makefile for hello.cpp</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-makefile notranslate"><div class="highlight"><pre><span></span><span class="nf">default</span><span class="o">:</span><span class="w"> </span><span class="n">build</span>

<span class="c"># Set compiler</span>
<span class="nv">KOKKOS_PATH</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">$(</span>shell<span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>/kokkos
<span class="nv">CXX</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>hipcc
<span class="c"># CXX = ${KOKKOS_PATH}/bin/nvcc_wrapper</span>

<span class="c"># Variables for the Makefile.kokkos</span>
<span class="nv">KOKKOS_DEVICES</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;HIP&quot;</span>
<span class="c"># KOKKOS_DEVICES = &quot;Cuda&quot;</span>
<span class="nv">KOKKOS_ARCH</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;VEGA90A&quot;</span>
<span class="c"># KOKKOS_ARCH = &quot;Volta70&quot;</span>
<span class="nv">KOKKOS_CUDA_OPTIONS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;enable_lambda,force_uvm&quot;</span>

<span class="c"># Include Makefile.kokkos</span>
<span class="cp">include $(KOKKOS_PATH)/Makefile.kokkos</span>

<span class="nf">build</span><span class="o">:</span><span class="w"> </span><span class="k">$(</span><span class="nv">KOKKOS_LINK_DEPENDS</span><span class="k">)</span> <span class="k">$(</span><span class="nv">KOKKOS_CPP_DEPENDS</span><span class="k">)</span> <span class="n">hello</span>.<span class="n">cpp</span>
<span class="w"> </span><span class="k">$(</span>CXX<span class="k">)</span><span class="w"> </span><span class="k">$(</span>KOKKOS_CPPFLAGS<span class="k">)</span><span class="w"> </span><span class="k">$(</span>KOKKOS_CXXFLAGS<span class="k">)</span><span class="w"> </span><span class="k">$(</span>KOKKOS_LDFLAGS<span class="k">)</span><span class="w"> </span>hello.cpp<span class="w"> </span><span class="k">$(</span>KOKKOS_LIBS<span class="k">)</span><span class="w"> </span>-o<span class="w"> </span>hello
</pre></div>
</div>
</div></div>
<p>To build a <strong>hello.cpp</strong> project with the above Makefile, no steps other than cloning the Kokkos project into the current directory is required.</p>
</section>
<section id="kokkos-programming">
<h4>Kokkos programming<a class="headerlink" href="#kokkos-programming" title="Link to this heading"></a></h4>
<p>When starting to write a project using Kokkos, the first step is understand Kokkos initialization and finalization. Kokkos must be initialized by calling <code class="docutils literal notranslate"><span class="pre">Kokkos::initialize(int&amp;</span> <span class="pre">argc,</span> <span class="pre">char*</span> <span class="pre">argv[])</span></code> and finalized by calling <code class="docutils literal notranslate"><span class="pre">Kokkos::finalize()</span></code>. More details are given in <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html">HERE</a>.</p>
<p>Kokkos uses an execution space model to abstract the details of parallel hardware. The execution space instances map to the available backend options such as CUDA, OpenMP, HIP, or SYCL. If the execution space is not explicitly chosen by the programmer in the source code, the default execution space <code class="docutils literal notranslate"><span class="pre">Kokkos::DefaultExecutionSpace</span></code> is used. This is chosen when the Kokkos library is compiled. The Kokkos execution space model is described in more detail in <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces">HERE</a>.</p>
<p>Similarly, Kokkos uses a memory space model for different types of memory, such as host memory or device memory. If not defined explicitly, Kokkos uses the default memory space specified during Kokkos compilation as described <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces">HERE</a>.</p>
<p>The following is an example of a Kokkos program that initializes Kokkos and prints the execution space and memory space instances:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">hello.cpp</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Execution Space: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span>
<span class="w">    </span><span class="k">typeid</span><span class="p">(</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">DefaultExecutionSpace</span><span class="p">).</span><span class="n">name</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Memory Space: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span>
<span class="w">    </span><span class="k">typeid</span><span class="p">(</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">DefaultExecutionSpace</span><span class="o">::</span><span class="n">memory_space</span><span class="p">).</span><span class="n">name</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<p>With Kokkos, the data can be accessed either through raw pointers or through Kokkos Views. With raw pointers, the memory allocation into the default memory space can be done using <code class="docutils literal notranslate"><span class="pre">Kokkos::kokkos_malloc(n</span> <span class="pre">*</span> <span class="pre">sizeof(int))</span></code>. Kokkos Views are a data type that provides a way to access data more efficiently in memory corresponding to a certain Kokkos memory space, such as host memory or device memory. A 1-dimensional view of type int* can be created by <code class="docutils literal notranslate"><span class="pre">Kokkos::View&lt;int*&gt;</span> <span class="pre">a(&quot;a&quot;,</span> <span class="pre">n)</span></code>, where <code class="docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code> is a label, and <code class="docutils literal notranslate"><span class="pre">n</span></code> is the size of the allocation in the number of integers. Kokkos determines the optimal layout for the data at compile time for best overall performance as a function of the computer architecture. Furthermore, Kokkos handles the deallocation of such memory automatically. More details about Kokkos Views are found <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html">HERE</a>.</p>
<p>Finally, Kokkos provides three different parallel operations: <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code>, <code class="docutils literal notranslate"><span class="pre">parallel_reduce</span></code>, and <code class="docutils literal notranslate"><span class="pre">parallel_scan</span></code>. The <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> operation is used to execute a loop in parallel. The <code class="docutils literal notranslate"><span class="pre">parallel_reduce</span></code> operation is used to execute a loop in parallel and reduce the results to a single value. The <code class="docutils literal notranslate"><span class="pre">parallel_scan</span></code> operation implements a prefix scan. The usage of <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> and <code class="docutils literal notranslate"><span class="pre">parallel_reduce</span></code> are demonstrated in the examples later in this chapter. More detail about the parallel operations are found <a class="reference external" href="https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html">HERE</a>.</p>
</section>
<section id="run-kokkos-hello-cpp-example-in-simple-steps">
<h4>Run Kokkos hello.cpp example in simple steps<a class="headerlink" href="#run-kokkos-hello-cpp-example-in-simple-steps" title="Link to this heading"></a></h4>
<p>The following should work on AMD VEGA90A devices straight out of the box (needs ROCm installation). On NVIDIA Volta V100 devices (needs CUDA installation), use the variables commented out on the Makefile.</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://github.com/kokkos/kokkos.git</span></code></p></li>
<li><p>Copy the above Makefile into the current folder (make sure the indentation of the last line is tab, and not space)</p></li>
<li><p>Copy the above hello.cpp file into the current folder</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">make</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">./hello</span></code></p></li>
</ol>
</section>
</section>
<section id="opencl">
<h3>OpenCL<a class="headerlink" href="#opencl" title="Link to this heading"></a></h3>
<p>OpenCL is a cross-platform, open-standard API for writing parallel programs that execute across heterogeneous platforms consisting of CPUs, GPUs, FPGAs and other devices. The first version of OpenCL (1.0) was released in December 2008, and the latest version of OpenCL (3.0) was released in September 2020. OpenCL is supported by a number of vendors, including AMD, ARM, Intel, NVIDIA, and Qualcomm. It is a royalty-free standard, and the OpenCL specification is maintained by the Khronos Group. OpenCL provides a low-level programming interface initially based on C, but more recently also a C++ interface has become available.</p>
<section id="opencl-compilation">
<h4>OpenCL compilation<a class="headerlink" href="#opencl-compilation" title="Link to this heading"></a></h4>
<p>OpenCL supports two modes for compiling the programs: online and offline. Online compilation occurs at runtime, when the host program calls a function to compile the source code. Online mode allows dynamic generation and loading of kernels, but may incur some overhead due to compilation time and possible errors. Offline compilation occurs before runtime, when the source code of a kernel is compiled into a binary format that can be loaded by the host program. This mode allows faster execution and better optimization of kernels, but may limit the portability of the program, because the binary can only run on the architectures it was compiled for.</p>
<p>OpenCL comes bundled with several parallel programming ecosystems, such as NVIDIA CUDA and Intel oneAPI. For example, after successfully installing such packages and setting up the environment, one may simply compile an OpenCL program by the commands such as <code class="docutils literal notranslate"><span class="pre">icx</span> <span class="pre">cl_devices.c</span> <span class="pre">-lOpenCL</span></code> (Intel oneAPI) or <code class="docutils literal notranslate"><span class="pre">nvcc</span> <span class="pre">cl_devices.c</span> <span class="pre">-lOpenCL</span></code> (NVIDIA CUDA), where <code class="docutils literal notranslate"><span class="pre">cl_devices.c</span></code> is the compiled file. Unlike most other programming models, OpenCL stores kernels as text and compiles them for the device in runtime (JIT-compilation), and thus does not require any special compiler support: one can compile the code using simply <code class="docutils literal notranslate"><span class="pre">gcc</span> <span class="pre">cl_devices.c</span> <span class="pre">-lOpenCL</span></code> (or <code class="docutils literal notranslate"><span class="pre">g++</span></code> when using C++ API), as long as the required libraries and headers are installed in a standard locations.</p>
<p>The AMD compiler installed on LUMI supports both OpenCL C and C++ API, the latter with some limitations.
To compile a program, you can use the AMD compilers on a GPU partition:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>PrgEnv-cray-amd
<span class="gp">$ </span>CC<span class="w"> </span>program.cpp<span class="w"> </span>-lOpenCL<span class="w"> </span>-o<span class="w"> </span>program<span class="w"> </span><span class="c1"># C++ program</span>
<span class="gp">$ </span>cc<span class="w"> </span>program.c<span class="w"> </span>-lOpenCL<span class="w"> </span>-o<span class="w"> </span>program<span class="w"> </span><span class="c1"># C program</span>
</pre></div>
</div>
</section>
<section id="opencl-programming">
<h4>OpenCL programming<a class="headerlink" href="#opencl-programming" title="Link to this heading"></a></h4>
<p>OpenCL programs consist of two parts: a host program that runs on the host device (usually a CPU) and one or more kernels that run on compute devices (such as GPUs). The host program is responsible for the tasks such as managing the devices for the selected platform, allocating memory objects, building and enqueueing kernels, and managing memory objects.</p>
<p>The first steps when writing an OpenCL program are to initialize the OpenCL environment by selecting the platform and devices, creating a context or contexts associated with the selected device(s), and creating a command queue for each device. A simple example of selecting the default device, creating a context and a queue associated with the device is show below.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">OpenCL initialization (C++ API)</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">OpenCL initialization (C API)</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Initialize OpenCL</span>
<span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="o">::</span><span class="n">getDefault</span><span class="p">();</span>
<span class="n">cl</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="nf">context</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
<span class="n">cl</span><span class="o">::</span><span class="n">CommandQueue</span><span class="w"> </span><span class="nf">queue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="c1">// Initialize OpenCL</span>
<span class="n">cl_int</span><span class="w"> </span><span class="n">err</span><span class="p">;</span><span class="w"> </span><span class="c1">// Error code returned by API calls</span>
<span class="n">cl_platform_id</span><span class="w"> </span><span class="n">platform</span><span class="p">;</span>
<span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clGetPlatformIDs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="n">assert</span><span class="p">(</span><span class="n">err</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">CL_SUCCESS</span><span class="p">);</span><span class="w"> </span><span class="c1">// Checking error codes is skipped later for brevity</span>
<span class="n">cl_device_id</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clGetDeviceIDs</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_TYPE_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="n">cl_context</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateContext</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">err</span><span class="p">);</span>
<span class="n">cl_command_queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateCommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">err</span><span class="p">);</span>
</pre></div>
</div>
</div></div>
<p>OpenCL provides two main programming models to manage the memory hierarchy of host and accelerator devices: buffers and shared virtual memory (SVM). Buffers are the traditional memory model of OpenCL, where the host and the devices have separate address spaces and the programmer has to explicitly specify the memory allocations and how and where the memory is accessed. This can be done with class <code class="docutils literal notranslate"><span class="pre">cl::Buffer</span></code> and functions such as <code class="docutils literal notranslate"><span class="pre">cl::CommandQueue::enqueueReadBuffer()</span></code>. Buffers are supported since early versions of OpenCL, and work well across different architectures. Buffers can also take advantage of device-specific memory features, such as constant or local memory.</p>
<p>SVM is a newer memory model of OpenCL, introduced in version 2.0, where the host and the devices share a single virtual address space. Thus, the programmer can use the same pointers to access the data from host and devices simplifying the programming effort. In OpenCL, SVM comes in different levels such as coarse-grained buffer SVM, fine-grained buffer SVM, and fine-grained system SVM. All levels allow using the same pointers across a host and devices, but they differ in their granularity and synchronization requirements for the memory regions. Furthermore, the support for SVM is not universal across all OpenCL platforms and devices, and for example, GPUs such as NVIDIA V100 and A100 only support the coarse-grained SVM buffer. This level requires explicit synchronization for memory accesses from a host and devices (using functions such as <code class="docutils literal notranslate"><span class="pre">cl::CommandQueue::enqueueMapSVM()</span></code> and <code class="docutils literal notranslate"><span class="pre">cl::CommandQueue::enqueueUnmapSVM()</span></code>), making the usage of SVM less convenient. It is further noted that this is unlike the regular Unified Memory offered by CUDA, which is closer to the fine-grained system SVM level in OpenCL.</p>
<p>OpenCL uses a separate-source kernel model where the kernel code is often kept in separate files that may be compiled during runtime. The model allows the kernel source code to be passed as a string to the OpenCL driver after which the program object can be executed on a specific device. Although referred to as the separate-source kernel model, the kernels can still be defined as a string in the host program compilation units as well, which may be a more convenient approach in some cases.</p>
<p>The online compilation with the separate-source kernel model has several advantages over the binary model, which requires offline compilation of kernels into device-specific binaries that can are loaded by the application at runtime. Online compilation preserves the portability and flexibility of OpenCL, as the same kernel source code can run on any supported device. Furthermore, dynamic optimization of kernels based on runtime information, such as input size, work-group size, or device capabilities, is possible. An example of an OpenCL kernel, defined by a string in the host compilation unit, and assigning the global thread index into a global device memory is shown below.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">OpenCL kernel example</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sa">R</span><span class="s">&quot;</span><span class="dl">(</span>
<span class="s">  __kernel void dot(__global int *a) {</span>
<span class="s">    int i = get_global_id(0);</span>
<span class="s">    a[i] = i;</span>
<span class="s">  }</span>
<span class="dl">)</span><span class="s">&quot;</span><span class="p">;</span>
</pre></div>
</div>
</div></div>
<p>The above kernel named <code class="docutils literal notranslate"><span class="pre">dot</span></code> and stored in the string <code class="docutils literal notranslate"><span class="pre">kernel_source</span></code> can be set to build in the host code as follows:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">OpenCL kernel build example (C++ API)</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1">OpenCL kernel build example (C API)</button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">cl</span><span class="o">::</span><span class="n">Program</span><span class="w"> </span><span class="nf">program</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_source</span><span class="p">);</span>
<span class="n">program</span><span class="p">.</span><span class="n">build</span><span class="p">({</span><span class="n">device</span><span class="p">});</span>
<span class="n">cl</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="n">kernel_dot</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;dot&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">cl_int</span><span class="w"> </span><span class="n">err</span><span class="p">;</span>
<span class="n">cl_program</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateProgramWithSource</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernel_source</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">err</span><span class="p">);</span>
<span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clBuildProgram</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="n">cl_kernel</span><span class="w"> </span><span class="n">kernel_dot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateKernel</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;vector_add&quot;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">err</span><span class="p">);</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="sycl">
<h3>SYCL<a class="headerlink" href="#sycl" title="Link to this heading"></a></h3>
<p><a class="reference external" href="https://www.khronos.org/sycl/">SYCL</a> is a royalty-free, open-standard C++ programming model for multi-device programming. It provides a high-level, single-source programming model for heterogeneous systems, including GPUs. There are several implementations of the standard. For GPU programming, <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html">Intel oneAPI DPC++</a> and <a class="reference external" href="https://github.com/AdaptiveCpp/AdaptiveCpp/">AdaptiveCpp</a> (also known as hipSYCL) are the most popular for desktop and HPC GPUs; <a class="reference external" href="https://developer.codeplay.com/products/computecpp/ce/home/">ComputeCPP</a> is a good choice for embedded devices. The same standard-compliant SYCL code should work with any implementation, but they are not binary-compatible.</p>
<p>The most recent version of the SYCL standard is SYCL 2020, and it is the version we will be using in this course.</p>
<section id="sycl-compilation">
<h4>SYCL compilation<a class="headerlink" href="#sycl-compilation" title="Link to this heading"></a></h4>
<section id="id1">
<h5>Intel oneAPI DPC++<a class="headerlink" href="#id1" title="Link to this heading"></a></h5>
<p>For targeting Intel GPUs, it is enough to install <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html">Intel oneAPI Base Toolkit</a>. Then, the compilation is as simple as <code class="docutils literal notranslate"><span class="pre">icpx</span> <span class="pre">-fsycl</span> <span class="pre">file.cpp</span></code>.</p>
<p>It is also possible to use oneAPI for NVIDIA and AMD GPUs. In addition to oneAPI Base Toolkit, the vendor-provided runtime (CUDA or HIP) and the corresponding <a class="reference external" href="https://codeplay.com/solutions/oneapi/">Codeplay oneAPI plugin</a> must be installed.
Then, the code can be compiled using Intel LLVM compiler bundled with oneAPI:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">clang++</span> <span class="pre">-fsycl</span> <span class="pre">-fsycl-targets=nvidia_gpu_sm_86</span> <span class="pre">file.cpp</span></code> for targeting CUDA 8.6 NVIDIA GPU,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clang++</span> <span class="pre">-fsycl</span> <span class="pre">-fsycl-targets=amd_gpu_gfx90a</span></code> for targeting GFX90a AMD GPU.</p></li>
</ul>
</section>
<section id="id2">
<h5>AdaptiveCpp<a class="headerlink" href="#id2" title="Link to this heading"></a></h5>
<p>Using AdaptiveCpp for NVIDIA or AMD GPUs also requires having CUDA or HIP installed first. Then <code class="docutils literal notranslate"><span class="pre">acpp</span></code> can be used for compiling the code, specifying the target devices. For example, here is how to compile the program supporting an AMD and an NVIDIA device:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">acpp</span> <span class="pre">--acpp-targets='hip:gfx90a;cuda:sm_70'</span> <span class="pre">file.cpp</span></code></p></li>
</ul>
</section>
<section id="using-sycl-on-lumi">
<h5>Using SYCL on LUMI<a class="headerlink" href="#using-sycl-on-lumi" title="Link to this heading"></a></h5>
<p>LUMI does not have a system-wide installation of any SYCL framework, but a recent AdaptiveCpp installation is
available in CSC modules:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3
<span class="gp">$ </span>module<span class="w"> </span>use<span class="w"> </span>/appl/local/csc/modulefiles
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>acpp/24.06.0
</pre></div>
</div>
<p>The default compilation target is preset to MI250 GPUs, so to compile a single C++ file it is enough to call <code class="docutils literal notranslate"><span class="pre">acpp</span> <span class="pre">-O2</span> <span class="pre">file.cpp</span></code>.</p>
<p>When running applications built with AdaptiveCpp, one can often see the warning “dag_direct_scheduler: Detected a requirement that is neither of discard access mode”, reflecting the lack of an optimization hint when using buffer-accessor model. The warning is harmless and can be ignored.</p>
</section>
</section>
<section id="sycl-programming">
<h4>SYCL programming<a class="headerlink" href="#sycl-programming" title="Link to this heading"></a></h4>
<p>SYCL is, in many aspects, similar to OpenCL, but uses, like Kokkos, a single-source model with kernel lambdas.</p>
<p>To submit a task to device, first a <cite>sycl::queue</cite> must be created, which is used as a way to manage the
task scheduling and execution. In the simplest case, that’s all the initialization one needs:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Create an out-of-order queue on the default device:</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// Now we can submit tasks to q!</span>
<span class="p">}</span>
</pre></div>
</div>
<p>If one wants more control, the device can be explicitly specified, or additional properties can be passed to
a queue:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Iterate over all available devices</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">get_devices</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Print the device name</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Creating a queue on &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">name</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// Create an in-order queue for the current device</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="nf">q</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">in_order</span><span class="p">()});</span>
<span class="w">  </span><span class="c1">// Now we can submit tasks to q!</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Memory management can be done in two different ways: <em>buffer-accessor</em> model and <em>unified shared memory</em> (USM).
The choice of the memory management models also influences how the GPU tasks are synchronized.</p>
<p>In the <em>buffer-accessor</em> model, a <code class="docutils literal notranslate"><span class="pre">sycl::buffer</span></code> objects are used to represent arrays of data. A buffer is
not mapped to any single one memory space, and can be migrated between the GPU and the CPU memory
transparently. The data in <code class="docutils literal notranslate"><span class="pre">sycl::buffer</span></code> cannot be read or written directly, an accessor must be created.
<code class="docutils literal notranslate"><span class="pre">sycl::accessor</span></code> objects specify the location of data access (host or a certain GPU kernel) and the access
mode (read-only, write-only, read-write).
Such approach allows optimizing task scheduling by building a directed acyclic graph (DAG) of data dependencies:
if kernel <em>A</em> creates a write-only accessor to a buffer, and then kernel <em>B</em> is submitted with a read-only
accessor to the same buffer, and then a host-side read-only accessor is requested, then it can be deduced that
<em>A</em> must complete before <em>B</em> is launched and also that the results must be copied to the host
before the host task can proceed, but the host task can run in parallel with kernel <em>B</em>.
Since the dependencies between tasks can be built automatically, by default SYCL uses <em>out-of-order queues</em>:
when two tasks are submitted to the same <code class="docutils literal notranslate"><span class="pre">sycl::queue</span></code>, it is not guaranteed that the second one will launch
only after the first one completes.
When launching a kernel, accessors must be created:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create a buffer of n integers</span>
<span class="k">auto</span><span class="w"> </span><span class="n">buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">));</span>
<span class="c1">// Submit a kernel into a queue; cgh is a helper object</span>
<span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Create write-only accessor for buf</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">write</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">  </span><span class="c1">// Define a kernel: n threads execute the following lambda</span>
<span class="w">  </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">KernelName</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="c1">// The data is written to the buffer via acc</span>
<span class="w">      </span><span class="n">acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/*...*/</span>
<span class="w">  </span><span class="p">});</span>
<span class="p">});</span>
<span class="cm">/* If we now submit another kernel with accessor to buf, it will not</span>
<span class="cm"> * start running until the kernel above is done */</span>
</pre></div>
</div>
<p>Buffer-accessor model simplifies many aspects of heterogeneous programming and prevents many synchronization-related
bugs, but it only allows very coarse control of data movement and kernel execution.</p>
<p>The <em>USM</em> model is similar to how NVIDIA CUDA or AMD HIP manage memory. The programmer has to explicitly allocate
the memory on the device (<code class="docutils literal notranslate"><span class="pre">sycl::malloc_device</span></code>), on the host (<code class="docutils literal notranslate"><span class="pre">sycl::malloc_host</span></code>), or in the shared memory
space (<code class="docutils literal notranslate"><span class="pre">sycl::malloc_shared</span></code>). Despite its name, unified shared memory, and the similarity to OpenCL’s SVM, not
all USM allocations are shared: for example, a memory allocated by <code class="docutils literal notranslate"><span class="pre">sycl::malloc_device</span></code> cannot be accessed
from the host. The allocation functions return memory pointers that can be used directly, without accessors.
This means that the programmer have to ensure the correct synchronization between host and device tasks to avoid
data races. With USM, it is often convenient to use <em>in-order queues</em> with USM, instead of the default <em>out-of-order</em> queues.
More information on USM can be found in the <a class="reference external" href="https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm">Section 4.8 of SYCL 2020 specification</a>.</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create a shared (migratable) allocation of n integers</span>
<span class="c1">// Unlike with buffers, we need to specify a queue (or, explicitly, a device and a context)</span>
<span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="c1">// Submit a kernel into a queue; cgh is a helper object</span>
<span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Define a kernel: n threads execute the following lambda</span>
<span class="w">  </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">KernelName</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="c1">// The data is directly written to v</span>
<span class="w">      </span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/*...*/</span>
<span class="w">  </span><span class="p">});</span>
<span class="p">});</span>
<span class="c1">// If we want to access v, we have to ensure that the kernel has finished</span>
<span class="n">q</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>
<span class="c1">// After we&#39;re done, the memory must be deallocated</span>
<span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="exercise">
<h4>Exercise<a class="headerlink" href="#exercise" title="Link to this heading"></a></h4>
<div class="admonition-exercise-implement-saxpy-in-sycl exercise important admonition" id="exercise-0">
<p class="admonition-title">Exercise: Implement SAXPY in SYCL</p>
<p>In this exercise we would like to write (fill-in-the-blanks) a simple code doing SAXPY (vector addition).</p>
<p>To compile and run the code interactively, first make an allocation and load the AdaptiveCpp module:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>salloc<span class="w"> </span>-A<span class="w"> </span>project_465002387<span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>-t<span class="w"> </span><span class="m">1</span>:00:00<span class="w"> </span>-p<span class="w"> </span>standard-g<span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">1</span>
<span class="go">....</span>
<span class="go">salloc: Granted job allocation 123456</span>

<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>use<span class="w"> </span>/appl/local/csc/modulefiles
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3<span class="w"> </span>acpp/24.06.0
</pre></div>
</div>
<p>Now you can run a simple device-detection utility to check that a GPU is available (note <code class="docutils literal notranslate"><span class="pre">srun</span></code>):</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>acpp-info<span class="w"> </span>-l
<span class="go">=================Backend information===================</span>
<span class="go">Loaded backend 0: HIP</span>
<span class="go">  Found device: AMD Instinct MI250X</span>
<span class="go">Loaded backend 1: OpenMP</span>
<span class="go">  Found device: hipSYCL OpenMP host device</span>
</pre></div>
</div>
</div></blockquote>
<p>If you have not done it already, clone the repository using <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://github.com/ENCCS/gpu-programming.git</span></code> or <strong>update it</strong> using <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">pull</span> <span class="pre">origin</span> <span class="pre">main</span></code>.</p>
<p>Now, let’s look at the example code in <code class="docutils literal notranslate"><span class="pre">content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp</span></code>:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Create an in-order queue</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">{</span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">in_order</span><span class="p">()};</span>
<span class="w">  </span><span class="c1">// Print the device name, just for fun</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Running on &quot;</span>
<span class="w">            </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">q</span><span class="p">.</span><span class="n">get_device</span><span class="p">().</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">name</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1024</span><span class="p">;</span><span class="w"> </span><span class="c1">// Vector size</span>

<span class="w">  </span><span class="c1">// Allocate device and host memory for the first input vector</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_host</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="hll"><span class="w">  </span><span class="c1">// Bonus question: Can we use `std::vector` here instead of `malloc_host`?</span>
</span><span class="hll"><span class="w">  </span><span class="c1">// TODO: Allocate second input vector on device and host, d_y and h_y</span>
</span><span class="w">  </span><span class="c1">// Allocate device and host memory for the output vector</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_host</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">h_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="hll"><span class="w">    </span><span class="c1">// TODO: Initialize h_y somehow</span>
</span><span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.42f</span><span class="p">;</span>

<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">h_x</span><span class="p">,</span><span class="w"> </span><span class="n">d_x</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="hll"><span class="w">  </span><span class="c1">// TODO: Copy h_y to d_y</span>
</span><span class="hll"><span class="w">  </span><span class="c1">// Bonus question: Why don&#39;t we need to wait before using the data?</span>
</span>
<span class="w">  </span><span class="c1">// Run the kernel</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="hll"><span class="w">    </span><span class="c1">// TODO: Modify the code to compute z[i] = alpha * x[i] + y[i]</span>
</span><span class="w">    </span><span class="n">d_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">d_x</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">});</span>

<span class="hll"><span class="w">  </span><span class="c1">// TODO: Copy d_z to h_z</span>
</span><span class="hll"><span class="w">  </span><span class="c1">// TODO: Wait for the copy to complete</span>
</span>
<span class="w">  </span><span class="c1">// Check the results</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">ok</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">ref</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">h_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">h_y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"> </span><span class="c1">// Reference value</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">tol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-5</span><span class="p">;</span><span class="w">                    </span><span class="c1">// Relative tolerance</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">abs</span><span class="p">((</span><span class="n">h_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">ref</span><span class="p">))</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tol</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">abs</span><span class="p">(</span><span class="n">ref</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">h_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">h_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">h_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">                </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">      </span><span class="n">ok</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">      </span><span class="k">break</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ok</span><span class="p">)</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Results are correct!&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="k">else</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Results are NOT correct!&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Free allocated memory</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">d_x</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">h_x</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="hll"><span class="w">  </span><span class="c1">// TODO: Free d_y, h_y.</span>
</span><span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">d_y</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">h_y</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To compile and run the code, use the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>acpp<span class="w"> </span>-O3<span class="w"> </span>exercise-sycl-saxpy.cpp<span class="w"> </span>-o<span class="w"> </span>exercise-sycl-saxpy
<span class="gp">$ </span>srun<span class="w"> </span>./exercise-sycl-saxpy
<span class="go">Running on AMD Instinct MI250X</span>
<span class="go">Results are correct!</span>
</pre></div>
</div>
<p>The code will not compile as-is!
Your task is to fill in missing bits indicated by <code class="docutils literal notranslate"><span class="pre">TODO</span></code> comments.
You can also test your understanding using the “Bonus questions” in the code.</p>
<p>If you feel stuck, take a look at the <code class="docutils literal notranslate"><span class="pre">exercise-sycl-saxpy-solution.cpp</span></code> file.</p>
</div>
</section>
</section>
<section id="alpaka">
<h3>alpaka<a class="headerlink" href="#alpaka" title="Link to this heading"></a></h3>
<p>The <a class="reference external" href="https://github.com/alpaka-group/alpaka3">alpaka</a> library is an open-source header-only C++20 abstraction library for accelerator development.</p>
<p>Its aim is to provide performance portability across accelerators by abstracting the underlying levels of parallelism. The project provides a single-source C++ API that enables developers to write parallel code once and run it on different hardware architectures without modification.
The name “alpaka” comes from <strong>A</strong>bstractions for <strong>L</strong>evels of <strong>P</strong>arallelism, <strong>A</strong>lgorithms, and <strong>K</strong>ernels for <strong>A</strong>ccelerators.
The library is platform-independent and supports the concurrent and cooperative use of multiple devices, including host CPUs (x86, ARM, and RISC-V) and GPUs from different vendors (NVIDIA, AMD, and Intel).
A variety of accelerator backends, CUDA, HIP, SYCL, OpenMP, and serial execution, are available and can be selected based on the target device.
Only a single implementation of a user kernel is required, expressed as a function object with a standardized interface.
This eliminates the need to write specialized CUDA, HIP, SYCL, OpenMP, Intel TBB or threading code.
Moreover, multiple accelerator backends can be combined to target different vendor hardware within a single system and even within a single application.</p>
<p>The abstraction is based on a virtual index domain decomposed into equally sized chunks called frames.
<strong>alpaka</strong> provides a uniform abstraction to traverse these frames, independent of the underlying hardware.
Algorithms to be parallelized map the chunked index domain and native worker threads onto the data, expressing the computation as kernels that are executed in parallel threads (SIMT), thereby also leveraging SIMD units.
Unlike native parallelism models such as CUDA, HIP, and SYCL, <strong>alpaka</strong> kernels are not restricted to three dimensions.
Explicit caching of data within a frame via shared memory allows developers to fully unleash the performance of the compute device.
Additionally, <strong>alpaka</strong> offers primitive functions such as iota, transform, transform-reduce, reduce, and concurrent, simplifying the development of portable high-performance applications.
Host, device, mapped, and managed multi-dimensional views provide a natural way to operate on data.</p>
<p>Here we demonstrate the usage of <strong>alpaka3</strong>, which is a complete rewrite of <a class="reference external" href="https://github.com/alpaka-group/alpaka">alpaka</a>.
It is planned to merge this separate codebase back into the mainline alpaka repository before the first release in Q2/Q3 of 2026.
Nevertheless, the code is well-tested and can be used for development today.</p>
<section id="installing-alpaka-on-your-system">
<h4>Installing alpaka on your system<a class="headerlink" href="#installing-alpaka-on-your-system" title="Link to this heading"></a></h4>
<p>For ease of use, we recommend installing alpaka using CMake as described below. For other ways to use alpaka in your projects, see the <a class="reference external" href="https://alpaka3.readthedocs.io/en/latest/basic/install.html">alpaka3 documentation</a>.</p>
<ol class="arabic">
<li><p><strong>Clone the repository</strong></p>
<p>Clone the alpaka source code from GitHub to a directory of your choice:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/alpaka-group/alpaka3.git
<span class="nb">cd</span><span class="w"> </span>alpaka
</pre></div>
</div>
</li>
<li><p><strong>Set installation directory</strong></p>
<p>Set the <code class="docutils literal notranslate"><span class="pre">ALPAKA_DIR</span></code> environment variable to the directory where you want to install alpaka. This can be any directory you choose where you have write access.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">ALPAKA_DIR</span><span class="o">=</span>/path/to/your/alpaka/install/dir
</pre></div>
</div>
</li>
<li><p><strong>Build and install</strong></p>
<p>Create a build directory and use CMake to build and install alpaka. We use <code class="docutils literal notranslate"><span class="pre">CMAKE_INSTALL_PREFIX</span></code> to tell CMake where to install the library.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>build
cmake<span class="w"> </span>-B<span class="w"> </span>build<span class="w"> </span>-S<span class="w"> </span>.<span class="w"> </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span><span class="nv">$ALPAKA_DIR</span>
cmake<span class="w"> </span>--build<span class="w"> </span>build<span class="w"> </span>--parallel
</pre></div>
</div>
</li>
<li><p><strong>Update environment</strong></p>
<p>To make sure that other projects can find your alpaka installation, you should add the installation directory to your <code class="docutils literal notranslate"><span class="pre">CMAKE_PREFIX_PATH</span></code>. You can do this by adding the following line to your shell configuration file (e.g. <code class="docutils literal notranslate"><span class="pre">~/.bashrc</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">CMAKE_PREFIX_PATH</span><span class="o">=</span><span class="nv">$ALPAKA_DIR</span>:<span class="nv">$CMAKE_PREFIX_PATH</span>
</pre></div>
</div>
<p>You will need to source your shell configuration file or open a new terminal for the changes to take effect.</p>
</li>
</ol>
</section>
<section id="alpaka-compilation">
<h4>alpaka Compilation<a class="headerlink" href="#alpaka-compilation" title="Link to this heading"></a></h4>
<p>We recommend building your projects which use alpaka using CMake. A variety of strategies can be used to deal with building your application for a specific device or set of devices. Here we show a minimal way to get started, but this is by no means the only way to set up your projects.
Please refer to the <a class="reference external" href="https://alpaka3.readthedocs.io/en/latest/basic/install.html">alpaka3 documentation</a> for alternative ways to use alpaka in your project, including a way to make your source code agnostic to the accelerator being targeted by defining a device specification in CMake.</p>
<p>The following example demonstrates a <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> for a single-file project using alpaka3 (<code class="docutils literal notranslate"><span class="pre">main.cpp</span></code> which is presented in the section below):</p>
<blockquote>
<div><div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span><span class="w"> </span><span class="s">3.25</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">myAlpakaApp</span><span class="w"> </span><span class="s">VERSION</span><span class="w"> </span><span class="s">1.0</span><span class="p">)</span>

<span class="c"># Find installed alpaka</span>
<span class="nb">find_package</span><span class="p">(</span><span class="s">alpaka</span><span class="w"> </span><span class="s">REQUIRED</span><span class="p">)</span>

<span class="c"># Build the executable</span>
<span class="nb">add_executable</span><span class="p">(</span><span class="s">myAlpakaApp</span><span class="w"> </span><span class="s">main.cpp</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">myAlpakaApp</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s">alpaka::alpaka</span><span class="p">)</span>
<span class="nb">alpaka_finalize</span><span class="p">(</span><span class="s">myAlpakaApp</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<section id="using-alpaka-on-lumi">
<h5>Using alpaka on LUMI<a class="headerlink" href="#using-alpaka-on-lumi" title="Link to this heading"></a></h5>
<p>To load the environment for using the AMD GPUs on LUMI with HIP, one can use the following modules -</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>buildtools/24.03
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>PrgEnv-amd
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>craype-accel-amd-gfx90a
<span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">CXX</span><span class="o">=</span>hipcc
</pre></div>
</div>
</section>
</section>
<section id="alpaka-programming">
<h4>alpaka Programming<a class="headerlink" href="#alpaka-programming" title="Link to this heading"></a></h4>
<p>When starting with alpaka3, the first step is understanding the <strong>device selection model</strong>. Unlike frameworks that require explicit initialization calls, alpaka3 uses a device specification to determine which backend and hardware to use. The device specification consists of two components:</p>
<ul class="simple">
<li><p><strong>API</strong>: The parallel programming interface (host, cuda, hip, oneApi)</p></li>
<li><p><strong>Device Kind</strong>: The type of hardware (cpu, nvidiaGpu, amdGpu, intelGpu)</p></li>
</ul>
<p>Here we specify and use these at runtime to select and initialize devices. The device selection process is described in detail in the alpaka3 documentation.</p>
<p>alpaka3 uses an <strong>execution space model</strong> to abstract parallel hardware details. A device selector is created using <code class="docutils literal notranslate"><span class="pre">alpaka::onHost::makeDeviceSelector(devSpec)</span></code>, which returns an object that can query available devices and create device instances for the selected backend.</p>
<p>The following example demonstrates a basic alpaka program that initializes a device and prints information about it:</p>
<blockquote>
<div><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdlib&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">getDeviceSpec</span><span class="p">()</span>
<span class="p">{</span>
<span class="w">    </span><span class="cm">/* Select a device, possible combinations of api+deviceKind:</span>
<span class="cm">     * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">     * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">     */</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">DeviceSpec</span><span class="p">{</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">};</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="o">**</span><span class="w"> </span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Initialize device specification and selector</span>
<span class="w">    </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">DeviceSpec</span><span class="w"> </span><span class="n">devSpec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getDeviceSpec</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">deviceSelector</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">devSpec</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Query available devices</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">num_devices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">deviceSelector</span><span class="p">.</span><span class="n">getDeviceCount</span><span class="p">();</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Number of available devices: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">num_devices</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">num_devices</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;No devices found for the selected backend</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Select and initialize the first device</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">deviceSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Using device: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">getName</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">EXIT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
<p>alpaka3 provides memory management abstractions through buffers and views. Memory can be allocated on host or device using <code class="docutils literal notranslate"><span class="pre">alpaka::allocBuf&lt;T,</span> <span class="pre">Idx&gt;(device,</span> <span class="pre">extent)</span></code>. Data transfers between host and device are handled through <code class="docutils literal notranslate"><span class="pre">alpaka::memcpy(queue,</span> <span class="pre">dst,</span> <span class="pre">src)</span></code>. The library automatically manages memory layouts for optimal performance on different architectures.</p>
<p>For parallel execution, alpaka3 provides kernel abstractions. Kernels are defined as functors or lambda functions and executed using work division specifications that define the parallelization strategy. The framework supports various parallel patterns including element-wise operations, reductions, and scans.</p>
<section id="tour-of-alpaka-features">
<h5>Tour of <strong>alpaka</strong> Features<a class="headerlink" href="#tour-of-alpaka-features" title="Link to this heading"></a></h5>
<p>Now we will quickly explore the most commonly used features of alpaka and go over some basic usage. A quick reference of commonly used alpaka features is available <a class="reference external" href="https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html">here.</a></p>
<p><strong>General setup</strong>: Include the consolidated header once and you are ready to start using alpaka.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">myProject</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// Your code here</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Accelerator, platform, and device management</strong>: Select devices by combining the desired API with the appropriate hardware kind using the device selector.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">devSelector</span><span class="p">.</span><span class="n">getDeviceCount</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">throw</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">runtime_error</span><span class="p">(</span><span class="s">&quot;No device found!&quot;</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">auto</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</pre></div>
</div>
<p><strong>Queues and events</strong>: Create blocking or non-blocking queues per device, record events, and synchronize work as needed.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">nonBlockingQueue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">nonBlocking</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">blockingQueue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">event</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">makeEvent</span><span class="p">();</span>
<span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">event</span><span class="p">);</span>
<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">wait</span><span class="p">(</span><span class="n">event</span><span class="p">);</span>
<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">wait</span><span class="p">(</span><span class="n">queue</span><span class="p">);</span>
</pre></div>
</div>
<p><strong>Memory management</strong>: Allocate host, device, mapped, unified, or deferred buffers, create non-owning views, and move data portably with <cite>memcpy</cite>, <cite>memset</cite>, and <cite>fill</cite>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">hostBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHost</span><span class="o">&lt;</span><span class="n">DataType</span><span class="o">&gt;</span><span class="p">(</span><span class="n">extent3D</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">devBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">alloc</span><span class="o">&lt;</span><span class="n">DataType</span><span class="o">&gt;</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">extentMd</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">devMappedBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocMapped</span><span class="o">&lt;</span><span class="n">DataType</span><span class="o">&gt;</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">extentMd</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">hostView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">makeView</span><span class="p">(</span><span class="n">api</span><span class="o">::</span><span class="n">host</span><span class="p">,</span><span class="w"> </span><span class="n">externPtr</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">Vec</span><span class="p">{</span><span class="n">numElements</span><span class="p">});</span>
<span class="k">auto</span><span class="w"> </span><span class="n">devNonOwningView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devBuffer</span><span class="p">.</span><span class="n">getView</span><span class="p">();</span>

<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memset</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">devBuffer</span><span class="p">,</span><span class="w"> </span><span class="kt">uint8_t</span><span class="p">{</span><span class="mi">0</span><span class="p">});</span>
<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">devBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">hostBuffer</span><span class="p">);</span>
<span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">fill</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">devBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">DataType</span><span class="p">{</span><span class="mi">42</span><span class="p">});</span>
</pre></div>
</div>
<p><strong>Kernel execution</strong>: Build a <cite>FrameSpec</cite> manually or request one tuned for your data type, then enqueue kernels with automatic or explicit executors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">constexpr</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2u</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">IdxType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">size_t</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">DataType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">int</span><span class="p">;</span>

<span class="n">IdxType</span><span class="w"> </span><span class="n">valueX</span><span class="p">,</span><span class="w"> </span><span class="n">valueY</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">extentMD</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">Vec</span><span class="p">{</span><span class="n">valueY</span><span class="p">,</span><span class="w"> </span><span class="n">valueX</span><span class="p">};</span>

<span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">FrameSpec</span><span class="p">{</span><span class="n">numFramesMd</span><span class="p">,</span><span class="w"> </span><span class="n">frameExtentMd</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tunedSpec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">getFrameSpec</span><span class="o">&lt;</span><span class="n">DataType</span><span class="o">&gt;</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">extentMd</span><span class="p">);</span>

<span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">tunedSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="n">kernelArgs</span><span class="p">...});</span>

<span class="k">auto</span><span class="w"> </span><span class="n">executor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">exec</span><span class="o">::</span><span class="n">cpuSerial</span><span class="p">;</span>
<span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span><span class="w"> </span><span class="n">tunedSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="n">kernelArgs</span><span class="p">...});</span>
</pre></div>
</div>
<p><strong>Kernel implementation</strong>: Write kernels as functors annotated with <cite>ALPAKA_FN_ACC</cite>, use shared memory, synchronization, atomics, and math helpers directly inside the kernel body.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">MyKernel</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">ALPAKA_FN_ACC</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="k">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="o">&amp;</span><span class="w"> </span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="k">auto</span><span class="p">...</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="k">const</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">idxMd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc</span><span class="p">.</span><span class="n">getIdxWithin</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">origin</span><span class="o">::</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">unit</span><span class="o">::</span><span class="n">blocks</span><span class="p">);</span>

<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">sharedMdArray</span><span class="w"> </span><span class="o">=</span>
<span class="w">            </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">declareSharedMdArray</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">uniqueId</span><span class="p">()</span><span class="o">&gt;</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">CVec</span><span class="o">&lt;</span><span class="kt">uint32_t</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="o">&gt;</span><span class="p">{});</span>

<span class="w">        </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">syncBlockThreads</span><span class="p">(</span><span class="n">acc</span><span class="p">);</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">old</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">onAcc</span><span class="o">::</span><span class="n">atomicAdd</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="p">...);</span>
<span class="w">        </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">memFence</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">scope</span><span class="o">::</span><span class="n">block</span><span class="p">);</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">sinValue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">math</span><span class="o">::</span><span class="n">sin</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="run-alpaka3-example-in-simple-steps">
<h5>Run alpaka3 Example in Simple Steps<a class="headerlink" href="#run-alpaka3-example-in-simple-steps" title="Link to this heading"></a></h5>
<p>The following example works on systems with CMake 3.25+ and an appropriate C++ compiler. For GPU execution, ensure the corresponding runtime (CUDA, ROCm, or oneAPI) is installed.</p>
<ol class="arabic">
<li><p>Create a directory for your project:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>my_alpaka_project<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>my_alpaka_project
</pre></div>
</div>
</li>
<li><p>Copy the CMakeLists.txt from above into the current folder</p></li>
<li><p>Copy the main.cpp file into the current folder</p></li>
<li><p>Configure and build:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cmake<span class="w"> </span>-B<span class="w"> </span>build<span class="w"> </span>-S<span class="w"> </span>.<span class="w"> </span>-Dalpaka_DEP_HIP<span class="o">=</span>ON
cmake<span class="w"> </span>--build<span class="w"> </span>build<span class="w"> </span>--parallel
</pre></div>
</div>
</li>
<li><p>Run the executable:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/myAlpakaApp
</pre></div>
</div>
</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The device specification system allows you to select the target device at CMake configuration time. The format is <code class="docutils literal notranslate"><span class="pre">&quot;api:deviceKind&quot;</span></code>, where:</p>
<ul class="simple">
<li><p><strong>api</strong>: The parallel programming interface (<code class="docutils literal notranslate"><span class="pre">host</span></code>, <code class="docutils literal notranslate"><span class="pre">cuda</span></code>, <code class="docutils literal notranslate"><span class="pre">hip</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi</span></code>)</p></li>
<li><p><strong>deviceKind</strong>: The type of device (<code class="docutils literal notranslate"><span class="pre">cpu</span></code>, <code class="docutils literal notranslate"><span class="pre">nvidiaGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">amdGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">intelGpu</span></code>)</p></li>
</ul>
<p>Available combinations are: <code class="docutils literal notranslate"><span class="pre">host:cpu</span></code>, <code class="docutils literal notranslate"><span class="pre">cuda:nvidiaGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">hip:amdGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi:cpu</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi:intelGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi:nvidiaGpu</span></code>, <code class="docutils literal notranslate"><span class="pre">oneApi:amdGpu</span></code></p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The CUDA, HIP, or Intel backends only work if the CUDA SDK, HIP SDK, or OneAPI SDK are available respectively</p>
</div>
</section>
<section id="expected-output">
<h5>Expected output<a class="headerlink" href="#expected-output" title="Link to this heading"></a></h5>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of available devices: 1
Using device: [Device Name]
</pre></div>
</div>
<p>The device name will vary depending on your hardware (e.g., “NVIDIA A100”, “AMD MI250X”, or your CPU model).</p>
</section>
</section>
<section id="compile-and-execute-examples">
<h4>Compile and Execute Examples<a class="headerlink" href="#compile-and-execute-examples" title="Link to this heading"></a></h4>
<p>You can test the <strong>alpaka</strong> provided examples from the <a class="reference external" href="#examples">example section</a>.
The examples have hard coded the usage of the AMD ROCm platform required on LUMI.
To switch to CPU usage only you can simply replace <code class="docutils literal notranslate"><span class="pre">ap::onHost::makeDeviceSelector(ap::api::hip,</span> <span class="pre">ap::deviceKind::amdGpu);</span></code> with <code class="docutils literal notranslate"><span class="pre">ap::onHost::makeDeviceSelector(ap::api::host,</span> <span class="pre">ap::deviceKind::cpu);</span></code></p>
<p>The following steps assume you have downloaded alpaka already and the path to the <strong>alapka</strong> source code is stored in the environment variable <code class="docutils literal notranslate"><span class="pre">ALPAKA_DIR</span></code>.
To test the example copy the code into a file <code class="docutils literal notranslate"><span class="pre">main.cpp</span></code></p>
<p>Alternatively, <a class="reference external" href="https://godbolt.org/z/69exnG4xb">click here</a> to try the first example using in the godbolt compiler explorer.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-5-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-5-5-0" name="5-0" role="tab" tabindex="0">HIP for AMD GPUs</button><button aria-controls="panel-5-5-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-1" name="5-1" role="tab" tabindex="-1">Host compiler for CPU</button><button aria-controls="panel-5-5-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-2" name="5-2" role="tab" tabindex="-1">CUDA for NVIDIA GPUs</button><button aria-controls="panel-5-5-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-3" name="5-3" role="tab" tabindex="-1">oneAPI SYCL for CPU</button><button aria-controls="panel-5-5-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-4" name="5-4" role="tab" tabindex="-1">oneAPI SYCL for Intel GPUs</button><button aria-controls="panel-5-5-5" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-5" name="5-5" role="tab" tabindex="-1">oneAPI SYCL for AMD GPUs</button><button aria-controls="panel-5-5-6" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-6" name="5-6" role="tab" tabindex="-1">oneAPI SYCL for NVIDIA GPUs</button></div><div aria-labelledby="tab-5-5-0" class="sphinx-tabs-panel" id="panel-5-5-0" name="5-0" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::hip, ap::deviceKind::amdGpu);</span>
<span class="c1"># We use CC to refer to the compiler to work smoothly with the LUMI environment</span>
CC<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-x<span class="w"> </span>hip<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-1" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-1" name="5-1" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::host, ap::deviceKind::cpu);</span>
<span class="c1"># We use CC to refer to the compiler to work smoothly with the LUMI environment</span>
CC<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-2" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-2" name="5-2" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::cuda, ap::deviceKind::nvidiaGpu);</span>
nvcc<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>--expt-relaxed-constexpr<span class="w"> </span>-x<span class="w"> </span>cuda<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-3" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-3" name="5-3" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::oneApi, ap::deviceKind::cpu);</span>
icpx<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>spir64_x86_64<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-4" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-4" name="5-4" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::oneApi, ap::deviceKind::intelGpu);</span>
icpx<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>spir64<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-5" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-5" name="5-5" role="tabpanel" tabindex="0"><div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding Codeplay oneAPI plugin as described <a class="reference external" href="https://codeplay.com/solutions/oneapi/plugins/">here</a>.</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::oneApi, ap::deviceKind::amdGpu);</span>
icpx<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>amd_gpu_gfx90a<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-6" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-6" name="5-6" role="tabpanel" tabindex="0"><div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding Codeplay oneAPI plugin as described <a class="reference external" href="https://codeplay.com/solutions/oneapi/plugins/">here</a>.</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># use the following in C++ code</span>
<span class="c1"># auto devSelector = ap::onHost::makeDeviceSelector(ap::api::oneApi, ap::deviceKind::nvidiaGpu);</span>
icpx<span class="w"> </span>-I<span class="w"> </span><span class="nv">$ALPAKA_DIR</span>/include/<span class="w"> </span>-std<span class="o">=</span>c++20<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>nvptx64-nvidia-cuda<span class="w"> </span>-Xsycl-target-backend<span class="o">=</span>nvptx64-nvidia-cuda<span class="w"> </span>--offload-arch<span class="o">=</span>sm_80<span class="w"> </span>main.cpp
./a.out
</pre></div>
</div>
</div></div>
</section>
<section id="id3">
<h4>Exercise<a class="headerlink" href="#id3" title="Link to this heading"></a></h4>
<div class="admonition-exercise-write-a-vector-add-kernel-in-alpaka exercise important admonition" id="exercise-1">
<p class="admonition-title">Exercise: Write a vector add kernel in alpaka</p>
<p>In this exercise we would like to write (fill-in-the-blanks) a simple kernel to add two vectors.</p>
<p>To compile and run the code interactively, first we first need to get an allocation on a GPU node and load the modules for alpaka:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>-p<span class="w"> </span>dev-g<span class="w"> </span>--gpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>--time<span class="o">=</span><span class="m">00</span>:20:00<span class="w"> </span>--account<span class="o">=</span>project_465002387<span class="w"> </span>--pty<span class="w"> </span>bash
<span class="go">....</span>
<span class="go">srun: job 1234 queued and waiting for resources</span>
<span class="go">srun: job 1234 has been allocated resources</span>

<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>LUMI/24.03<span class="w"> </span>partition/G
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/6.0.3
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>buildtools/24.03
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>PrgEnv-amd
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>craype-accel-amd-gfx90a
<span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">CXX</span><span class="o">=</span>hipcc
</pre></div>
</div>
<p>Now you can run a simple device-detection utility to check that a GPU is available (note <code class="docutils literal notranslate"><span class="pre">srun</span></code>):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>rocm-smi

<span class="go">======================================= ROCm System Management Interface =======================================</span>
<span class="go">================================================= Concise Info =================================================</span>
<span class="go">Device  [Model : Revision]    Temp    Power  Partitions      SCLK    MCLK     Fan  Perf    PwrCap  VRAM%  GPU%</span>
<span class="go">        Name (20 chars)       (Edge)  (Avg)  (Mem, Compute)</span>
<span class="go">================================================================================================================</span>
<span class="go">0       [0x0b0c : 0x00]       45.0°C  N/A    N/A, N/A        800Mhz  1600Mhz  0%   manual  0.0W      0%   0%</span>
<span class="go">        AMD INSTINCT MI200 (</span>
<span class="go">================================================================================================================</span>
<span class="go">============================================= End of ROCm SMI Log ==============================================</span>
</pre></div>
</div>
<p>Now, let’s look at the code to set up the exercise:</p>
<p>Below we use fetch content with our CMake to get started with alpaka quickly.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">CMakeLists.txt</span><a class="headerlink" href="#id4" title="Link to this code"></a></div>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span><span class="w"> </span><span class="s">3.25</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">vectorAdd</span><span class="w"> </span><span class="s">LANGUAGES</span><span class="w"> </span><span class="s">CXX</span><span class="w"> </span><span class="s">VERSION</span><span class="w"> </span><span class="s">1.0</span><span class="p">)</span>
<span class="c">#Use CMake&#39;s FetchContent to download and integrate alpaka3 directly from GitHub</span>
<span class="nb">include</span><span class="p">(</span><span class="s">FetchContent</span><span class="p">)</span>
<span class="c">#Declare where to fetch alpaka3 from</span>
<span class="c">#This will download the library at configure time</span>
<span class="nb">FetchContent_Declare</span><span class="p">(</span><span class="s">alpaka3</span><span class="w"> </span><span class="s">GIT_REPOSITORY</span><span class="w"> </span><span class="s">https://github.com/alpaka-group/alpaka3.git</span><span class="w"> </span><span class="s">GIT_TAG</span><span class="w"> </span><span class="s">dev</span><span class="p">)</span>
<span class="c">#Make alpaka3 available for use in this project</span>
<span class="c">#This downloads, configures, and makes the library targets available</span>
<span class="nb">FetchContent_MakeAvailable</span><span class="p">(</span><span class="s">alpaka3</span><span class="p">)</span>
<span class="c">#Finalize the alpaka FetchContent setup</span>
<span class="hll"><span class="nb">alpaka_FetchContent_Finalize</span><span class="p">()</span>
</span><span class="c">#Create the executable target from the source file</span>
<span class="nb">add_executable</span><span class="p">(</span><span class="s">vectorAdd</span><span class="w"> </span><span class="s">main.cpp</span><span class="p">)</span>
<span class="c">#Link the alpaka library to the executable</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">vectorAdd</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s">alpaka::alpaka</span><span class="p">)</span>
<span class="c">#Finalize the alpaka configuration for this target</span>
<span class="c">#This sets up backend - specific compiler flags and dependencies</span>
<span class="hll"><span class="nb">alpaka_finalize</span><span class="p">(</span><span class="s">vectorAdd</span><span class="p">)</span>
</span></pre></div>
</div>
</div>
<p>Below we have the main alpaka code doing a vector addition on device using a high level transform function</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">main.cpp</span><a class="headerlink" href="#id5" title="Link to this code"></a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>

<span class="w">  </span><span class="c1">// auto devSelector = ap::onHost::makeDeviceSelector(ap::api::host,</span>
<span class="w">  </span><span class="c1">// ap::deviceKind::cpu);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run element-wise vector addition on device</span>
<span class="hll"><span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="p">{},</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>
</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<p>To set up our project, we create a folder and place our CMakeLists.txt and main.cpp in there.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mkdir<span class="w"> </span>alpakaExercise<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>alpakaExercise
<span class="gp">$ </span>vim<span class="w"> </span>CMakeLists.txt
<span class="go">and now paste the CMakeLsits here (Press i, followed by Ctrl+Shift+V)</span>
<span class="go">Press esc and then :wq to exit vim</span>
<span class="gp">$ </span>vim<span class="w"> </span>main.cpp
<span class="go">Similarly, paste the C++ code here</span>
</pre></div>
</div>
<p>To compile and run the code, use the following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">configure step, we additionaly specify that HIP is available</span>
<span class="gp">$ </span>cmake<span class="w"> </span>-B<span class="w"> </span>build<span class="w"> </span>-S<span class="w"> </span>.<span class="w"> </span>-Dalpaka_DEP_HIP<span class="o">=</span>ON
<span class="go">build</span>
<span class="gp">$ </span>cmake<span class="w"> </span>--build<span class="w"> </span>build<span class="w"> </span>--parallel
<span class="go">run</span>
<span class="gp">$ </span>./build/vectorAdd
<span class="go">Using alpaka device: AMD Instinct MI250X id=0</span>
<span class="go">c[0] = 1</span>
<span class="go">c[1] = 2</span>
<span class="go">c[2] = 3</span>
<span class="go">c[3] = 4</span>
<span class="go">c[4] = 5</span>
</pre></div>
</div>
<p>Now your task will be to write and launch your first alpaka kernel.
This kernel will do the vector addition and we will use this instead of the transform helper.</p>
<div class="admonition-writing-the-vector-add-kernel solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Writing the vector add kernel</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="hll"><span class="k">struct</span><span class="w"> </span><span class="nc">AddKernel</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="n">acc</span><span class="p">,</span>
</span><span class="hll"><span class="w">                            </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="p">,</span>
</span><span class="hll"><span class="w">                            </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">a</span><span class="p">,</span>
</span><span class="hll"><span class="w">                            </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">makeIdxMap</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">worker</span><span class="o">::</span><span class="n">threadsInGrid</span><span class="p">,</span>
</span><span class="hll"><span class="w">                                          </span><span class="n">ap</span><span class="o">::</span><span class="n">IdxRange</span><span class="p">{</span><span class="n">c</span><span class="p">.</span><span class="n">getExtents</span><span class="p">()}))</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">      </span><span class="n">c</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
</span><span class="hll"><span class="w">    </span><span class="p">}</span>
</span><span class="hll"><span class="w">  </span><span class="p">}</span>
</span><span class="hll"><span class="p">};</span>
</span>
<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>

<span class="w">  </span><span class="c1">// auto devSelector = ap::onHost::makeDeviceSelector(ap::api::host,</span>
<span class="w">  </span><span class="c1">// ap::deviceKind::cpu);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="hll"><span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">getFrameSpec</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">getExtents</span><span class="p">());</span>
</span>
<span class="hll"><span class="w">  </span><span class="c1">// Call the element-wise addition kernel on device</span>
</span><span class="hll"><span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">frameSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">AddKernel</span><span class="p">{},</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">});</span>
</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h3>
<section id="parallel-for-with-unified-memory">
<h4>Parallel for with Unified Memory<a class="headerlink" href="#parallel-for-with-unified-memory" title="Link to this heading"></a></h4>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-6-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-6-6-0" name="6-0" role="tab" tabindex="0">StdPar</button><button aria-controls="panel-6-6-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-1" name="6-1" role="tab" tabindex="-1">Kokkos</button><button aria-controls="panel-6-6-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-2" name="6-2" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-6-6-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-3" name="6-3" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-6-6-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-4" name="6-4" role="tab" tabindex="-1">alpaka-algorithms</button><button aria-controls="panel-6-6-5" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-5" name="6-5" role="tab" tabindex="-1">alpaka</button></div><div aria-labelledby="tab-6-6-0" class="sphinx-tabs-panel" id="panel-6-6-0" name="6-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdio&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate arrays</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">b</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">c</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par_unseq</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
<span class="w">                 </span><span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="p">[](</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">j</span><span class="p">;</span><span class="w"> </span><span class="p">});</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-1" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-1" name="6-1" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate on Kokkos default memory space (Unified Memory)</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_malloc</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

<span class="w">    </span><span class="c1">// Initialize values on host</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">      </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">KOKKOS_LAMBDA</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"> </span><span class="p">});</span>

<span class="w">    </span><span class="c1">// Kokkos synchronization</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">fence</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">    </span><span class="c1">// Free Kokkos allocation (Unified Memory)</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_free</span><span class="p">(</span><span class="n">b</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_free</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Finalize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-2" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-2" name="6-2" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using OpenCL C API here, since SVM support in C++ API is unstable on</span>
<span class="c1">// ROCm</span>
<span class="cp">#define CL_TARGET_OPENCL_VERSION 220</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="c1">// For larger kernels, we can store source in a separate file</span>
<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="s">&quot;                                                 \</span>
<span class="s">           __kernel void dot(__global const int *a, __global const int *b, __global int *c) { \</span>
<span class="s">             int i = get_global_id(0);                                                        \</span>
<span class="s">             c[i] = a[i] * b[i];                                                              \</span>
<span class="s">           }                                                                                  \</span>
<span class="s">         &quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize OpenCL</span>
<span class="w">  </span><span class="n">cl_platform_id</span><span class="w"> </span><span class="n">platform</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetPlatformIDs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_device_id</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetDeviceIDs</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_TYPE_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_context</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateContext</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_command_queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateCommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Compile OpenCL program for found device.</span>
<span class="w">  </span><span class="n">cl_program</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">clCreateProgramWithSource</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernel_source</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clBuildProgram</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_kernel</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateKernel</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;dot&quot;</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Set problem dimensions</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Create SVM buffer objects on host side</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clSVMAlloc</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clSVMAlloc</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clSVMAlloc</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_WRITE_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Pass arguments to device kernel</span>
<span class="w">  </span><span class="n">clSetKernelArgSVMPointer</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSetKernelArgSVMPointer</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSetKernelArgSVMPointer</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Create mappings for host and initialize values</span>
<span class="w">  </span><span class="n">clEnqueueSVMMap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MAP_WRITE</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                  </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clEnqueueSVMMap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MAP_WRITE</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                  </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">clEnqueueSVMUnmap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clEnqueueSVMUnmap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">globalSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">;</span>
<span class="w">  </span><span class="n">clEnqueueNDRangeKernel</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">globalSize</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                         </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Create mapping for host and print results</span>
<span class="w">  </span><span class="n">clEnqueueSVMMap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MAP_READ</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                  </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">clEnqueueSVMUnmap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Free SVM buffers</span>
<span class="w">  </span><span class="n">clSVMFree</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSVMFree</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>
<span class="w">  </span><span class="n">clSVMFree</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-3" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-3" name="6-3" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate shared memory (Unified Shared Memory)</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">   </span><span class="p">}).</span><span class="n">wait</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Free shared memory allocation (Unified Memory)</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-4" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-4" name="6-4" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">multiplies</span><span class="p">{},</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-5" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-5" name="6-5" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">MulKernel</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="o">&amp;</span><span class="w"> </span><span class="n">acc</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">a</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">makeIdxMap</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">worker</span><span class="o">::</span><span class="n">threadsInGrid</span><span class="p">,</span>
<span class="w">             </span><span class="n">ap</span><span class="o">::</span><span class="n">IdxRange</span><span class="p">{</span><span class="n">c</span><span class="p">.</span><span class="n">getExtents</span><span class="p">()}))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">c</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">frameExtent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32u</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">FrameSpec</span><span class="p">{</span><span class="n">ap</span><span class="o">::</span><span class="n">divExZero</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">),</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">};</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">frameSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">MulKernel</span><span class="p">{},</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">});</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</section>
<section id="parallel-for-with-gpu-buffers">
<h4>Parallel for with GPU buffers<a class="headerlink" href="#parallel-for-with-gpu-buffers" title="Link to this heading"></a></h4>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-7-7-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-7-7-0" name="7-0" role="tab" tabindex="0">Kokkos</button><button aria-controls="panel-7-7-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-1" name="7-1" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-7-7-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-2" name="7-2" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-7-7-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-3" name="7-3" role="tab" tabindex="-1">alpaka-algorithms</button><button aria-controls="panel-7-7-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-4" name="7-4" role="tab" tabindex="-1">alpaka</button></div><div aria-labelledby="tab-7-7-0" class="sphinx-tabs-panel" id="panel-7-7-0" name="7-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate space for 5 ints on Kokkos host memory space</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">HostSpace</span><span class="o">&gt;</span><span class="w"> </span><span class="n">h_a</span><span class="p">(</span><span class="s">&quot;h_a&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">HostSpace</span><span class="o">&gt;</span><span class="w"> </span><span class="n">h_b</span><span class="p">(</span><span class="s">&quot;h_b&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">HostSpace</span><span class="o">&gt;</span><span class="w"> </span><span class="n">h_c</span><span class="p">(</span><span class="s">&quot;h_c&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Allocate space for 5 ints on Kokkos default memory space (eg, GPU memory)</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="s">&quot;a&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">(</span><span class="s">&quot;b&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">View</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="o">*&gt;</span><span class="w"> </span><span class="n">c</span><span class="p">(</span><span class="s">&quot;c&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Initialize values on host</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">      </span><span class="n">h_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Copy from host to device</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">deep_copy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">deep_copy</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">h_b</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">KOKKOS_LAMBDA</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"> </span><span class="p">});</span>

<span class="w">    </span><span class="c1">// Copy from device to host</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">deep_copy</span><span class="p">(</span><span class="n">h_c</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Finalize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-1" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-1" name="7-1" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using OpenCL C++ API here; there is also C API in &lt;CL/cl.h&gt;</span>
<span class="cp">#define CL_TARGET_OPENCL_VERSION 110</span>
<span class="cp">#define CL_HPP_TARGET_OPENCL_VERSION 110</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.hpp&gt;</span>

<span class="c1">// For larger kernels, we can store source in a separate file</span>
<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sa">R</span><span class="s">&quot;</span><span class="dl">(</span>
<span class="s">            __kernel void dot(__global const int *a, __global const int *b, __global int *c) {</span>
<span class="s">              int i = get_global_id(0);</span>
<span class="s">              c[i] = a[i] * b[i];</span>
<span class="s">            }</span>
<span class="s">          </span><span class="dl">)</span><span class="s">&quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize OpenCL</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="o">::</span><span class="n">getDefault</span><span class="p">();</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="n">context</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">CommandQueue</span><span class="w"> </span><span class="n">queue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Compile OpenCL program for found device.</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Program</span><span class="w"> </span><span class="n">program</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_source</span><span class="p">);</span>
<span class="w">  </span><span class="n">program</span><span class="p">.</span><span class="n">build</span><span class="p">({</span><span class="n">device</span><span class="p">});</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="n">kernel_dot</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;dot&quot;</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Set problem dimensions</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">b</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">c</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Initialize values on host</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">      </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Create buffers and copy input data to device.</span>
<span class="w">    </span><span class="n">cl</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="n">dev_a</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">CL_MEM_COPY_HOST_PTR</span><span class="p">,</span>
<span class="w">                     </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
<span class="w">    </span><span class="n">cl</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="n">dev_b</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_ONLY</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">CL_MEM_COPY_HOST_PTR</span><span class="p">,</span>
<span class="w">                     </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">b</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
<span class="w">    </span><span class="n">cl</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="n">dev_c</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_WRITE_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

<span class="w">    </span><span class="c1">// Pass arguments to device kernel</span>
<span class="w">    </span><span class="n">kernel_dot</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">dev_a</span><span class="p">);</span>
<span class="w">    </span><span class="n">kernel_dot</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">dev_b</span><span class="p">);</span>
<span class="w">    </span><span class="n">kernel_dot</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">dev_c</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// We don&#39;t need to apply any offset to thread IDs</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueueNDRangeKernel</span><span class="p">(</span><span class="n">kernel_dot</span><span class="p">,</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">,</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NDRange</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
<span class="w">                               </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Read result</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueueReadBuffer</span><span class="p">(</span><span class="n">dev_c</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-2" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-2" name="7-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate space for 5 ints</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a_buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">));</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b_buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">));</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c_buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// Initialize values</span>
<span class="w">  </span><span class="c1">// We should use curly braces to limit host accessors&#39; lifetime</span>
<span class="w">  </span><span class="c1">//    and indicate when we&#39;re done working with them:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">a_host_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a_buf</span><span class="p">.</span><span class="n">get_host_access</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">b_host_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b_buf</span><span class="p">.</span><span class="n">get_host_access</span><span class="p">();</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">a_host_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">      </span><span class="n">b_host_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Submit a SYCL kernel into a queue</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Create read accessors over a_buf and b_buf</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">a_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">read</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">b_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">read</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// Create write accesor over c_buf</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">c_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">write</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">    </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">vec_add</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">c_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b_acc</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">  </span><span class="p">});</span>

<span class="w">  </span><span class="c1">// No need to synchronize, creating the accessor for c_buf will do it</span>
<span class="w">  </span><span class="c1">// automatically</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">c_host_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c_buf</span><span class="p">.</span><span class="n">get_host_access</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">c_host_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-3" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-3" name="7-3" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate memory that is accessible on host</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHost</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHostLike</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHostLike</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate memory on the device and inherit the extents from h_a</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">h_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Copy host memory element wise to the device memory</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">h_b</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">multiplies</span><span class="p">{},</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Copy the device result back to host memory</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-4" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-4" name="7-4" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">MulKernel</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="o">&amp;</span><span class="w"> </span><span class="n">acc</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">a</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">makeIdxMap</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">worker</span><span class="o">::</span><span class="n">threadsInGrid</span><span class="p">,</span>
<span class="w">             </span><span class="n">ap</span><span class="o">::</span><span class="n">IdxRange</span><span class="p">{</span><span class="n">c</span><span class="p">.</span><span class="n">getExtents</span><span class="p">()}))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">c</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate memory that is accessible on host</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHost</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHostLike</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">h_c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocHostLike</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// allocate memory on the device and inherit the extents from a</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocLike</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize values on host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">h_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Copy host memory element wise to the device memory</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">h_a</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">h_b</span><span class="p">);</span>

<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">frameExtent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32u</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">FrameSpec</span><span class="p">{</span><span class="n">ap</span><span class="o">::</span><span class="n">divExZero</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">),</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">};</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">frameSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">MulKernel</span><span class="p">{},</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">});</span>

<span class="w">  </span><span class="c1">// Copy the device result back to host memory</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;c[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">h_c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</section>
<section id="asynchronous-parallel-for-kernels">
<h4>Asynchronous parallel for kernels<a class="headerlink" href="#asynchronous-parallel-for-kernels" title="Link to this heading"></a></h4>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-8-8-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-8-8-0" name="8-0" role="tab" tabindex="0">Kokkos</button><button aria-controls="panel-8-8-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-1" name="8-1" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-8-8-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-2" name="8-2" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-8-8-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-3" name="8-3" role="tab" tabindex="-1">alpaka-algorithms</button><button aria-controls="panel-8-8-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-4" name="8-4" role="tab" tabindex="-1">alpaka</button></div><div aria-labelledby="tab-8-8-0" class="sphinx-tabs-panel" id="panel-8-8-0" name="8-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate on Kokkos default memory space (Unified Memory)</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_malloc</span><span class="p">(</span><span class="n">nx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

<span class="w">    </span><span class="c1">// Create &#39;n&#39; execution space instances (maps to streams in CUDA/HIP)</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">ex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">Experimental</span><span class="o">::</span><span class="n">partition_space</span><span class="p">(</span>
<span class="w">        </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">DefaultExecutionSpace</span><span class="p">(),</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Launch &#39;n&#39; potentially asynchronous kernels</span>
<span class="w">    </span><span class="c1">// Each kernel has their own execution space instances</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">parallel_for</span><span class="p">(</span>
<span class="w">          </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">RangePolicy</span><span class="o">&lt;</span><span class="n">Kokkos</span><span class="o">::</span><span class="n">DefaultExecutionSpace</span><span class="o">&gt;</span><span class="p">(</span>
<span class="w">              </span><span class="n">ex</span><span class="p">[</span><span class="n">region</span><span class="p">],</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">region</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)),</span>
<span class="w">          </span><span class="n">KOKKOS_LAMBDA</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span><span class="w"> </span><span class="p">});</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Sync execution space instances (maps to streams in CUDA/HIP)</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">ex</span><span class="p">[</span><span class="n">region</span><span class="p">].</span><span class="n">fence</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">    </span><span class="c1">// Free Kokkos allocation (Unified Memory)</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">kokkos_free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Finalize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-1" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-1" name="8-1" role="tabpanel" tabindex="0"><div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using OpenCL C API here, since SVM support in C++ API is unstable on</span>
<span class="c1">// ROCm</span>
<span class="cp">#define CL_TARGET_OPENCL_VERSION 200</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="c1">// For larger kernels, we can store source in a separate file</span>
<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;              \</span>
<span class="s">                    __kernel void async(__global int *a) { \</span>
<span class="s">                      int i = get_global_id(0);            \</span>
<span class="s">                      int region = i / get_global_size(0); \</span>
<span class="s">                      a[i] = region + i;                   \</span>
<span class="s">                    }                                      \</span>
<span class="s">         &quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Initialize OpenCL</span>
<span class="w">  </span><span class="n">cl_platform_id</span><span class="w"> </span><span class="n">platform</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetPlatformIDs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_device_id</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="w">  </span><span class="n">clGetDeviceIDs</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span><span class="w"> </span><span class="n">CL_DEVICE_TYPE_GPU</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_context</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateContext</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_command_queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateCommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Compile OpenCL program for found device.</span>
<span class="w">  </span><span class="n">cl_program</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">clCreateProgramWithSource</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernel_source</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">clBuildProgram</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl_kernel</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clCreateKernel</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;async&quot;</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Set problem dimensions</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Create SVM buffer objects on host side</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clSVMAlloc</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_WRITE_ONLY</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Pass arguments to device kernel</span>
<span class="w">  </span><span class="n">clSetKernelArgSVMPointer</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Launch multiple potentially asynchronous kernels on different parts of the</span>
<span class="w">  </span><span class="c1">// array</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">;</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="p">;</span>
<span class="w">    </span><span class="n">clEnqueueNDRangeKernel</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                           </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Create mapping for host and print results</span>
<span class="w">  </span><span class="n">clEnqueueSVMMap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MAP_READ</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span>
<span class="w">                  </span><span class="nb">NULL</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">clEnqueueSVMUnmap</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Free SVM buffers</span>
<span class="w">  </span><span class="n">clSVMFree</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-2" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-2" name="8-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate shared memory (Unified Shared Memory)</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_shared</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Launch multiple potentially asynchronous kernels on different parts of the</span>
<span class="w">  </span><span class="c1">// array</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">q</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">iShifted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">;</span>
<span class="w">      </span><span class="n">a</span><span class="p">[</span><span class="n">iShifted</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">iShifted</span><span class="p">;</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Synchronize</span>
<span class="w">  </span><span class="n">q</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">  </span><span class="c1">// Free shared memory allocation (Unified Memory)</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-3" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-3" name="8-3" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Non-blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">QueueType</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="o">&lt;</span><span class="n">ALPAKA_TYPEOF</span><span class="p">(</span><span class="n">devAcc</span><span class="p">),</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">NonBlocking</span><span class="o">&gt;</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">QueueType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">queues</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">queues</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">nonBlocking</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nPerRegion</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="p">;</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">regionOffset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nPerRegion</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">;</span>
<span class="w">    </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">iota</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">queues</span><span class="p">[</span><span class="n">region</span><span class="p">],</span><span class="w"> </span><span class="n">regionOffset</span><span class="p">,</span>
<span class="w">        </span><span class="n">a</span><span class="p">.</span><span class="n">getSubView</span><span class="p">(</span><span class="n">regionOffset</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">regionOffset</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Wait for the device, includes all queues</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">wait</span><span class="p">(</span><span class="n">devAcc</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-4" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-4" name="8-4" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">IdxAssignKernel</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">Acc</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="k">const</span><span class="o">&amp;</span><span class="w"> </span><span class="n">acc</span><span class="p">,</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">concepts</span><span class="o">::</span><span class="n">IMdSpan</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="p">,</span>
<span class="w">      </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="p">,</span>
<span class="w">      </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nPerRegion</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">getExtents</span><span class="p">().</span><span class="n">x</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n</span><span class="p">;</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">regionOffset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nPerRegion</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">region</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">:</span>
<span class="w">        </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">makeIdxMap</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onAcc</span><span class="o">::</span><span class="n">worker</span><span class="o">::</span><span class="n">threadsInGrid</span><span class="p">,</span>
<span class="w">            </span><span class="n">ap</span><span class="o">::</span><span class="n">IdxRange</span><span class="p">{</span><span class="n">regionOffset</span><span class="p">,</span><span class="w"> </span><span class="n">regionOffset</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">nPerRegion</span><span class="p">}))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">a</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Non-blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">QueueType</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="o">&lt;</span><span class="n">ALPAKA_TYPEOF</span><span class="p">(</span><span class="n">devAcc</span><span class="p">),</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">NonBlocking</span><span class="o">&gt;</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">QueueType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">queues</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">queues</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">nonBlocking</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="p">);</span>

<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">frameExtent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32u</span><span class="p">;</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">frameSpec</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">FrameSpec</span><span class="p">{</span><span class="n">ap</span><span class="o">::</span><span class="n">divExZero</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">),</span><span class="w"> </span><span class="n">frameExtent</span><span class="p">};</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">region</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">queues</span><span class="p">[</span><span class="n">region</span><span class="p">].</span><span class="n">enqueue</span><span class="p">(</span>
<span class="w">        </span><span class="n">frameSpec</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">KernelBundle</span><span class="p">{</span><span class="n">IdxAssignKernel</span><span class="p">{},</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">region</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Wait for the device, includes all queues</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">wait</span><span class="p">(</span><span class="n">devAcc</span><span class="p">);</span>

<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;a[%d] = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</section>
<section id="reduction">
<h4>Reduction<a class="headerlink" href="#reduction" title="Link to this heading"></a></h4>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-9-9-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-9-9-0" name="9-0" role="tab" tabindex="0">StdPar</button><button aria-controls="panel-9-9-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-1" name="9-1" role="tab" tabindex="-1">Kokkos</button><button aria-controls="panel-9-9-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-2" name="9-2" role="tab" tabindex="-1">OpenCL</button><button aria-controls="panel-9-9-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-3" name="9-3" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-9-9-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-4" name="9-4" role="tab" tabindex="-1">alpaka-algorithms</button></div><div aria-labelledby="tab-9-9-0" class="sphinx-tabs-panel" id="panel-9-9-0" name="9-0" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdio&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;numeric&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">iota</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="c1">// Fill the array</span>

<span class="w">  </span><span class="c1">// Run reduction on the device</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par_unseq</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">cbegin</span><span class="p">(),</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">cend</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">                        </span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">{});</span>

<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-1" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-1" name="9-1" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Kokkos_Core.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Initialize sum variable</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Run sum reduction kernel</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">parallel_reduce</span><span class="p">(</span>
<span class="w">        </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">KOKKOS_LAMBDA</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lsum</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">lsum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span><span class="w"> </span><span class="p">},</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Kokkos synchronization</span>
<span class="w">    </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">fence</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Finalize Kokkos</span>
<span class="w">  </span><span class="n">Kokkos</span><span class="o">::</span><span class="n">finalize</span><span class="p">();</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-2" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-2" name="9-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// We&#39;re using OpenCL C++ API here; there is also C API in &lt;CL/cl.h&gt;</span>
<span class="cp">#define CL_TARGET_OPENCL_VERSION 110</span>
<span class="cp">#define CL_HPP_TARGET_OPENCL_VERSION 110</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;CL/cl.hpp&gt;</span>

<span class="c1">// For larger kernels, we can store source in a separate file</span>
<span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">kernel_source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sa">R</span><span class="s">&quot;</span><span class="dl">(</span>
<span class="s">           __kernel void reduce(__global int* sum, __local int* local_mem) {</span>
<span class="s">             </span>
<span class="s">             // Get work group and work item information</span>
<span class="s">             int gsize = get_global_size(0); // global work size</span>
<span class="s">             int gid = get_global_id(0); // global work item index</span>
<span class="s">             int lsize = get_local_size(0); // local work size</span>
<span class="s">             int lid = get_local_id(0); // local work item index</span>
<span class="s">             </span>
<span class="s">             // Store reduced item into local memory</span>
<span class="s">             local_mem[lid] = gid; // initialize local memory</span>
<span class="s">             barrier(CLK_LOCAL_MEM_FENCE); // synchronize local memory</span>
<span class="s">             </span>
<span class="s">             // Perform reduction across the local work group</span>
<span class="s">             for (int s = 1; s &lt; lsize; s *= 2) { // loop over local memory with stride doubling each iteration</span>
<span class="s">               if (lid % (2 * s) == 0 &amp;&amp; (lid + s) &lt; lsize) {</span>
<span class="s">                 local_mem[lid] += local_mem[lid + s];</span>
<span class="s">               }</span>
<span class="s">               barrier(CLK_LOCAL_MEM_FENCE); // synchronize local memory</span>
<span class="s">             }</span>
<span class="s">             </span>
<span class="s">             if (lid == 0) { // only one work item per work group</span>
<span class="s">               atomic_add(sum, local_mem[0]); // add partial sum to global sum atomically</span>
<span class="s">             }</span>
<span class="s">           }</span>
<span class="s">         </span><span class="dl">)</span><span class="s">&quot;</span><span class="p">;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Initialize OpenCL</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">Device</span><span class="o">::</span><span class="n">getDefault</span><span class="p">();</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Context</span><span class="w"> </span><span class="n">context</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">CommandQueue</span><span class="w"> </span><span class="n">queue</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Compile OpenCL program for found device</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Program</span><span class="w"> </span><span class="n">program</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">kernel_source</span><span class="p">);</span>
<span class="w">  </span><span class="n">program</span><span class="p">.</span><span class="n">build</span><span class="p">({</span><span class="n">device</span><span class="p">});</span>
<span class="w">  </span><span class="n">cl</span><span class="o">::</span><span class="n">Kernel</span><span class="w"> </span><span class="n">kernel_reduce</span><span class="p">(</span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;reduce&quot;</span><span class="p">);</span>

<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Set problem dimensions</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Initialize sum variable</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Create buffer for sum</span>
<span class="w">    </span><span class="n">cl</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="n">buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">CL_MEM_READ_WRITE</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">CL_MEM_COPY_HOST_PTR</span><span class="p">,</span>
<span class="w">                      </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">sum</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Pass arguments to device kernel</span>
<span class="w">    </span><span class="n">kernel_reduce</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">buffer</span><span class="p">);</span><span class="w">            </span><span class="c1">// pass buffer to device</span>
<span class="w">    </span><span class="n">kernel_reduce</span><span class="p">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="nb">NULL</span><span class="p">);</span><span class="w"> </span><span class="c1">// allocate local memory</span>

<span class="w">    </span><span class="c1">// Enqueue kernel</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueueNDRangeKernel</span><span class="p">(</span><span class="n">kernel_reduce</span><span class="p">,</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">,</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">NDRange</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
<span class="w">                               </span><span class="n">cl</span><span class="o">::</span><span class="n">NullRange</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Read result</span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">enqueueReadBuffer</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">CL_TRUE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">sum</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Print result</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-3" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-3" name="9-3" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// We use built-in sycl::reduction mechanism in this example.</span>
<span class="c1">// The manual implementation of the reduction kernel can be found in</span>
<span class="c1">// the &quot;Non-portable kernel models&quot; chapter.</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Initialize sum</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Create a buffer for sum to get the reduction results</span>
<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sum_buf</span><span class="p">{</span><span class="o">&amp;</span><span class="n">sum</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">};</span>

<span class="w">    </span><span class="c1">// Submit a SYCL kernel into a queue</span>
<span class="w">    </span><span class="n">q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="c1">// Create temporary object describing variables with reduction semantics</span>
<span class="w">       </span><span class="k">auto</span><span class="w"> </span><span class="n">sum_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access_mode</span><span class="o">::</span><span class="n">read_write</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">       </span><span class="c1">// We can use built-in reduction primitive</span>
<span class="w">       </span><span class="k">auto</span><span class="w"> </span><span class="n">sum_reduction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">reduction</span><span class="p">(</span><span class="n">sum_acc</span><span class="p">,</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">());</span>

<span class="w">       </span><span class="c1">// A reference to the reducer is passed to the lambda</span>
<span class="w">       </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span>
<span class="w">           </span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="n">sum_reduction</span><span class="p">,</span>
<span class="w">           </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">idx</span><span class="p">,</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">reducer</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">reducer</span><span class="p">.</span><span class="n">combine</span><span class="p">(</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span><span class="w"> </span><span class="p">});</span>
<span class="w">     </span><span class="p">}).</span><span class="n">wait</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// The contents of sum_buf are copied back to sum by the destructor of</span>
<span class="w">    </span><span class="c1">// sum_buf</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-4" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-4" name="9-4" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;alpaka/alpaka.hpp&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">ap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">alpaka</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="w">  </span><span class="cm">/* Select a device, possible combinations:</span>
<span class="cm">   * host+cpu, cuda+nvidiaGpu, hip+amdGpu, oneApi+intelGpu, oneApi+cpu,</span>
<span class="cm">   * oneApi+amdGpu, oneApi+nvidiaGpu</span>
<span class="cm">   */</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">devSelector</span><span class="w"> </span><span class="o">=</span>
<span class="w">      </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">makeDeviceSelector</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">api</span><span class="o">::</span><span class="n">hip</span><span class="p">,</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">deviceKind</span><span class="o">::</span><span class="n">amdGpu</span><span class="p">);</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">devAcc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devSelector</span><span class="p">.</span><span class="n">makeDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Using alpaka device: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">getName</span><span class="p">().</span><span class="n">c_str</span><span class="p">());</span>

<span class="w">  </span><span class="c1">// Blocking device queue (requires synchronization)</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">Queue</span><span class="w"> </span><span class="n">queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">devAcc</span><span class="p">.</span><span class="n">makeQueue</span><span class="p">(</span><span class="n">ap</span><span class="o">::</span><span class="n">queueKind</span><span class="o">::</span><span class="n">blocking</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Allocate unified memory that is accessible on host and device</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">allocUnified</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">devAcc</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Run element-wise multiplication on device</span>
<span class="w">  </span><span class="n">ap</span><span class="o">::</span><span class="n">onHost</span><span class="o">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="p">{},</span><span class="w"> </span><span class="n">ap</span><span class="o">::</span><span class="n">LinearizedIdxGenerator</span><span class="p">{</span><span class="n">n</span><span class="p">});</span>

<span class="w">  </span><span class="c1">// Print results</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;sum = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="pros-and-cons-of-cross-platform-portability-ecosystems">
<h3>Pros and cons of cross-platform portability ecosystems<a class="headerlink" href="#pros-and-cons-of-cross-platform-portability-ecosystems" title="Link to this heading"></a></h3>
<section id="general-observations">
<h4>General observations<a class="headerlink" href="#general-observations" title="Link to this heading"></a></h4>
<blockquote>
<div><ul class="simple">
<li><p>The amount of code duplication is minimized.</p></li>
<li><p>The same code can be compiled to multiple architectures from different vendors.</p></li>
<li><p>Limited learning resources compared to CUDA (Stack Overflow, course material, documentation).</p></li>
</ul>
</div></blockquote>
</section>
<section id="lambda-based-kernel-models-kokkos-sycl">
<h4>Lambda-based kernel models (Kokkos, SYCL)<a class="headerlink" href="#lambda-based-kernel-models-kokkos-sycl" title="Link to this heading"></a></h4>
<blockquote>
<div><ul class="simple">
<li><p>Higher level of abstraction.</p></li>
<li><p>Less knowledge of the underlying architecture is needed for initial porting.</p></li>
<li><p>Very nice and readable source code (C++ API).</p></li>
<li><p>The models are relatively new and not very popular yet.</p></li>
</ul>
</div></blockquote>
</section>
<section id="functor-based-kernel-model-alpaka">
<h4>Functor-based kernel model (alpaka)<a class="headerlink" href="#functor-based-kernel-model-alpaka" title="Link to this heading"></a></h4>
<blockquote>
<div><ul class="simple">
<li><p>Very good portability.</p></li>
<li><p>Higher level of abstraction.</p></li>
<li><p>Low-level API always awailable which gives more control and allows fine tuning.</p></li>
<li><p>User friendly C++ API for both the host and kernel code.</p></li>
<li><p>Small community and ecosystem.</p></li>
</ul>
</div></blockquote>
</section>
<section id="separate-source-kernel-models-opencl">
<h4>Separate-source kernel models (OpenCL)<a class="headerlink" href="#separate-source-kernel-models-opencl" title="Link to this heading"></a></h4>
<blockquote>
<div><ul class="simple">
<li><p>Very good portability.</p></li>
<li><p>Mature ecosystem.</p></li>
<li><p>Limited number of vendor-provided libraries.</p></li>
<li><p>Low-level API gives more control and allows fine tuning.</p></li>
<li><p>Both C and C++ APIs available (C++ API is less well supported).</p></li>
<li><p>The low-level API and separate-source kernel model are less user friendly.</p></li>
</ul>
</div></blockquote>
</section>
<section id="c-standard-parallelism-stdpar-pstl">
<h4>C++ Standard Parallelism (StdPar, PSTL)<a class="headerlink" href="#c-standard-parallelism-stdpar-pstl" title="Link to this heading"></a></h4>
<blockquote>
<div><ul class="simple">
<li><p>Very high level of abstraction.</p></li>
<li><p>Easy to speed up code which already relying on STL algorithms.</p></li>
<li><p>Very little control over hardware.</p></li>
<li><p>Support by compilers is improving, but is far from mature.</p></li>
</ul>
</div></blockquote>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>General code organization is similar to non-portable kernel-based models.</p></li>
<li><p>As long as no vendor-specific functionality is used, the same code can run on any GPU.</p></li>
</ul>
</div>
</section>
</section>
</section>
<span id="document-9-language-support"></span><section id="high-level-language-support">
<h2>High-level language support<a class="headerlink" href="#high-level-language-support" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>Can I port code in high-level languages to run on GPUs?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Get an overview of libraries for GPU programming in Python and Julia</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>40 min teaching</p></li>
<li><p>20 min exercises</p></li>
</ul>
</div>
<section id="julia">
<h3>Julia<a class="headerlink" href="#julia" title="Link to this heading"></a></h3>
<p>Julia has first-class support for GPU programming through the following
packages that target GPUs from all three major vendors:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://cuda.juliagpu.org/stable/">CUDA.jl</a> for NVIDIA GPUs</p></li>
<li><p><a class="reference external" href="https://amdgpu.juliagpu.org/stable/">AMDGPU.jl</a> for AMD GPUs</p></li>
<li><p><a class="reference external" href="https://github.com/JuliaGPU/oneAPI.jl">oneAPI.jl</a> for Intel GPUs</p></li>
<li><p><a class="reference external" href="https://github.com/JuliaGPU/Metal.jl">Metal.jl</a> for Apple M-series GPUs</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">CUDA.jl</span></code> is the most mature, <code class="docutils literal notranslate"><span class="pre">AMDGPU.jl</span></code> is somewhat behind but still
ready for general use, while <code class="docutils literal notranslate"><span class="pre">oneAPI.jl</span></code> and <code class="docutils literal notranslate"><span class="pre">Metal.jl</span></code> are functional but might
contain bugs, miss some features and provide suboptimal performance.</p>
<p>The APIs of these libraries are completely analogous and translation between them is
normally straightforward. The libraries offer both user-friendly <strong>high-level abstractions</strong>
(the array interface and higher-level abstractions) that require little programming effort,
and a <strong>lower level</strong> approach for writing kernels for fine-grained control.</p>
<p>Installing these packages is done with the Julia package manager:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-TlZJRElB" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-TlZJRElB" name="TlZJRElB" role="tab" tabindex="0">NVIDIA</button><button aria-controls="panel-0-QU1E" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-QU1E" name="QU1E" role="tab" tabindex="-1">AMD</button><button aria-controls="panel-0-SW50ZWw=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-SW50ZWw=" name="SW50ZWw=" role="tab" tabindex="-1">Intel</button><button aria-controls="panel-0-QXBwbGU=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-QXBwbGU=" name="QXBwbGU=" role="tab" tabindex="-1">Apple</button></div><div aria-labelledby="tab-0-TlZJRElB" class="sphinx-tabs-panel group-tab" id="panel-0-TlZJRElB" name="TlZJRElB" role="tabpanel" tabindex="0"><p>Installing <code class="docutils literal notranslate"><span class="pre">CUDA.jl</span></code>:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;CUDA&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-QU1E" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-QU1E" name="QU1E" role="tabpanel" tabindex="0"><p>Installing <code class="docutils literal notranslate"><span class="pre">AMDGPU.jl</span></code>:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;AMDGPU&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-SW50ZWw=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-SW50ZWw=" name="SW50ZWw=" role="tabpanel" tabindex="0"><p>Installing <code class="docutils literal notranslate"><span class="pre">oneAPI.jl</span></code>:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;oneAPI&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-QXBwbGU=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-QXBwbGU=" name="QXBwbGU=" role="tabpanel" tabindex="0"><p>Installing <code class="docutils literal notranslate"><span class="pre">Metal.jl</span></code>:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;Metal&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>To use the Julia GPU stack, one needs to have the relevant GPU drivers and
programming toolkits installed. GPU drivers are already installed on HPC systems
while on your own machine you will need to install them yourself (see e.g. these
<a class="reference external" href="https://www.nvidia.com/Download/index.aspx">instructions from NVIDIA</a>).
Programming toolkits for CUDA can be installed automatically through
Julia’s artifact system upon the first usage:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">CUDA</span>
<span class="n">CUDA</span><span class="o">.</span><span class="n">versioninfo</span><span class="p">()</span>
</pre></div>
</div>
<section id="the-array-interface">
<h4>The array interface<a class="headerlink" href="#the-array-interface" title="Link to this heading"></a></h4>
<p>GPU programming with Julia can be as simple as using a different array type
instead of regular <code class="docutils literal notranslate"><span class="pre">Base.Array</span></code> arrays:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CuArray</span></code> from CUDA.jl for NVIDIA GPUs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ROCArray</span></code> from AMDGPU.jl for AMD GPUs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">oneArray</span></code> from oneAPI.jl for Intel GPUs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MtlArray</span></code> from Metal.jl for Apple GPUs</p></li>
</ul>
<p>These array types closely resemble <code class="docutils literal notranslate"><span class="pre">Base.Array</span></code> which enables
us to write generic code which works on both types.</p>
<p>The following code copies an array to the GPU and executes a simple operation on
the GPU:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-TlZJRElB" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-TlZJRElB" name="TlZJRElB" role="tab" tabindex="0">NVIDIA</button><button aria-controls="panel-1-QU1E" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-QU1E" name="QU1E" role="tab" tabindex="-1">AMD</button><button aria-controls="panel-1-SW50ZWw=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-SW50ZWw=" name="SW50ZWw=" role="tab" tabindex="-1">Intel</button><button aria-controls="panel-1-QXBwbGU=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-QXBwbGU=" name="QXBwbGU=" role="tab" tabindex="-1">Apple</button></div><div aria-labelledby="tab-1-TlZJRElB" class="sphinx-tabs-panel group-tab" id="panel-1-TlZJRElB" name="TlZJRElB" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">CUDA</span>

<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CuArray</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">.+=</span><span class="w"> </span><span class="mi">1</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-QU1E" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-QU1E" name="QU1E" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">AMDGPU</span>

<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">.+=</span><span class="w"> </span><span class="mi">1</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-SW50ZWw=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-SW50ZWw=" name="SW50ZWw=" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">oneAPI</span>

<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">oneArray</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">.+=</span><span class="w"> </span><span class="mi">1</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-QXBwbGU=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-QXBwbGU=" name="QXBwbGU=" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Metal</span>

<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MtlArray</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">.+=</span><span class="w"> </span><span class="mi">1</span>
</pre></div>
</div>
</div></div>
<p>Moving an array back from the GPU to the CPU is simple:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Array</span><span class="p">(</span><span class="n">A_d</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s have a look at a more realistic example: matrix multiplication. We
create two random arrays, one on the CPU and one on the GPU, and compare the
performance using the <a class="reference external" href="https://github.com/JuliaCI/BenchmarkTools.jl">BenchmarkTools package</a>:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-TlZJRElB" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-2-TlZJRElB" name="TlZJRElB" role="tab" tabindex="0">NVIDIA</button><button aria-controls="panel-2-QU1E" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-QU1E" name="QU1E" role="tab" tabindex="-1">AMD</button><button aria-controls="panel-2-SW50ZWw=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-SW50ZWw=" name="SW50ZWw=" role="tab" tabindex="-1">Intel</button><button aria-controls="panel-2-QXBwbGU=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-QXBwbGU=" name="QXBwbGU=" role="tab" tabindex="-1">Apple</button></div><div aria-labelledby="tab-2-TlZJRElB" class="sphinx-tabs-panel group-tab" id="panel-2-TlZJRElB" name="TlZJRElB" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">BenchmarkTools</span>
<span class="k">using</span><span class="w"> </span><span class="n">CUDA</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">);</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CuArray</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="nd">@btime</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="p">;</span>
<span class="nd">@btime</span><span class="w"> </span><span class="n">CUDA</span><span class="o">.</span><span class="nd">@sync</span><span class="w"> </span><span class="o">$</span><span class="n">A_d</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A_d</span><span class="p">;</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-QU1E" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-QU1E" name="QU1E" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">BenchmarkTools</span>
<span class="k">using</span><span class="w"> </span><span class="n">AMDGPU</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">);</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="nd">@btime</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="p">;</span>
<span class="nd">@btime</span><span class="w"> </span><span class="k">begin</span>
<span class="w">   </span><span class="o">$</span><span class="n">A_d</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A_d</span><span class="p">;</span>
<span class="w">   </span><span class="n">AMDGPU</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="k">end</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-SW50ZWw=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-SW50ZWw=" name="SW50ZWw=" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">BenchmarkTools</span>
<span class="k">using</span><span class="w"> </span><span class="n">oneAPI</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">);</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">oneArray</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="nd">@btime</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="p">;</span>
<span class="nd">@btime</span><span class="w"> </span><span class="o">$</span><span class="n">A_d</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A_d</span><span class="p">;</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-QXBwbGU=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-QXBwbGU=" name="QXBwbGU=" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">BenchmarkTools</span>
<span class="k">using</span><span class="w"> </span><span class="n">Metal</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">);</span>
<span class="n">A_d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MtlArray</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="nd">@btime</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A</span><span class="p">;</span>
<span class="nd">@btime</span><span class="w"> </span><span class="o">$</span><span class="n">A_d</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="o">$</span><span class="n">A_d</span><span class="p">;</span>
</pre></div>
</div>
</div></div>
</section>
<section id="vendor-libraries">
<h4>Vendor libraries<a class="headerlink" href="#vendor-libraries" title="Link to this heading"></a></h4>
<p>Support for using GPU vendor libraries from Julia is currently most mature on
NVIDIA GPUs. NVIDIA libraries contain precompiled kernels for common
operations like matrix multiplication (<cite>cuBLAS</cite>), fast Fourier transforms
(<cite>cuFFT</cite>), linear solvers (<cite>cuSOLVER</cite>), etc. These kernels are wrapped
in <code class="docutils literal notranslate"><span class="pre">CUDA.jl</span></code> and can be used directly with <code class="docutils literal notranslate"><span class="pre">CuArrays</span></code>:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># create a 100x100 Float32 random array and an uninitialized array</span>
<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUDA</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">);</span>
<span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">CuArray</span><span class="p">{</span><span class="kt">Float32</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">}(</span><span class="nb">undef</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">);</span>

<span class="c"># regular matrix multiplication uses cuBLAS under the hood</span>
<span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">A</span>

<span class="c"># use LinearAlgebra for matrix multiplication</span>
<span class="k">using</span><span class="w"> </span><span class="n">LinearAlgebra</span>
<span class="n">mul!</span><span class="p">(</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">)</span>

<span class="c"># use cuSOLVER for QR factorization</span>
<span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c"># solve equation A*X == B</span>
<span class="n">A</span><span class="w"> </span><span class="o">\</span><span class="w"> </span><span class="n">B</span>

<span class="c"># use cuFFT for FFT</span>
<span class="k">using</span><span class="w"> </span><span class="n">CUDA</span><span class="o">.</span><span class="n">CUFFT</span>
<span class="n">fft</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">AMDGPU.jl</span></code> currently supports some of the ROCm libraries:</p>
<ul class="simple">
<li><p><cite>rocBLAS</cite> for BLAS support</p></li>
<li><p><cite>rocFFT</cite> for FFT support</p></li>
<li><p><cite>rocRAND</cite> for RNG support</p></li>
<li><p><cite>MIOpen</cite> for DNN support</p></li>
</ul>
</section>
<section id="higher-order-abstractions">
<h4>Higher-order abstractions<a class="headerlink" href="#higher-order-abstractions" title="Link to this heading"></a></h4>
<p>A powerful way to program GPUs with arrays is through Julia’s higher-order array
abstractions. The simple element-wise addition we saw above, <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">.+=</span> <span class="pre">1</span></code>, is
an example of this, but more general constructs can be created with
<code class="docutils literal notranslate"><span class="pre">broadcast</span></code>, <code class="docutils literal notranslate"><span class="pre">map</span></code>, <code class="docutils literal notranslate"><span class="pre">reduce</span></code>, <code class="docutils literal notranslate"><span class="pre">accumulate</span></code> etc:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">broadcast</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1">map</button><button aria-controls="panel-3-3-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-2" name="3-2" role="tab" tabindex="-1">reduce</button><button aria-controls="panel-3-3-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-3" name="3-3" role="tab" tabindex="-1">accumulate</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">broadcast</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>
<span class="k">end</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">map</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="k">end</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-2" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-2" name="3-2" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">reduce</span><span class="p">(</span><span class="o">+</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-3" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-3" name="3-3" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">accumulate</span><span class="p">(</span><span class="o">+</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
</section>
<section id="writing-your-own-kernels">
<h4>Writing your own kernels<a class="headerlink" href="#writing-your-own-kernels" title="Link to this heading"></a></h4>
<p>Not all algorithms can be made to work with the higher-level abstractions
in <code class="docutils literal notranslate"><span class="pre">CUDA.jl</span></code>. In such cases it’s necessary to explicitly write our own GPU kernel.</p>
<p>Similarly to writing kernels in CUDA or HIP, we use a special function to
return the index of the GPU thread which executes it (e.g., <code class="docutils literal notranslate"><span class="pre">threadIdx().x</span></code> for NVIDIA
and <code class="docutils literal notranslate"><span class="pre">workitemIdx().x</span></code> for AMD), and two additional functions to parallelise over multiple blocks
(e.g., <code class="xref py py-meth docutils literal notranslate"><span class="pre">blockDim().x()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">blockIdx().x()</span></code> for NVIDIA, and <code class="xref py py-meth docutils literal notranslate"><span class="pre">workgroupDim().x()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">workgroupIdx().x()</span></code> for AMD).</p>
<figure class="align-center">
<img alt="_images/MappingBlocksToSMs.png" src="_images/MappingBlocksToSMs.png" />
</figure>
<p>Here’s an example of vector addition kernels for NVIDIA, AMD, Intel and Apple GPUs:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-TlZJRElB" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-4-TlZJRElB" name="TlZJRElB" role="tab" tabindex="0">NVIDIA</button><button aria-controls="panel-4-QU1E" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-4-QU1E" name="QU1E" role="tab" tabindex="-1">AMD</button><button aria-controls="panel-4-SW50ZWw=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-4-SW50ZWw=" name="SW50ZWw=" role="tab" tabindex="-1">Intel</button><button aria-controls="panel-4-QXBwbGU=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-4-QXBwbGU=" name="QXBwbGU=" role="tab" tabindex="-1">Apple</button></div><div aria-labelledby="tab-4-TlZJRElB" class="sphinx-tabs-panel group-tab" id="panel-4-TlZJRElB" name="TlZJRElB" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">CUDA</span>

<span class="k">function</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">)</span>
<span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">()</span><span class="o">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">blockIdx</span><span class="p">()</span><span class="o">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">()</span><span class="o">.</span><span class="n">x</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">    </span><span class="k">end</span>
<span class="w">    </span><span class="k">return</span>
<span class="k">end</span>

<span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUDA</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">CUDA</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">;</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">similar</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="n">nthreads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">256</span>
<span class="c"># smallest integer larger than or equal to length(A)/threads</span>
<span class="n">numblocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cld</span><span class="p">(</span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">),</span><span class="w"> </span><span class="n">nthreads</span><span class="p">)</span>

<span class="c"># run using 256 threads</span>
<span class="nd">@cuda</span><span class="w"> </span><span class="n">threads</span><span class="o">=</span><span class="n">nthreads</span><span class="w"> </span><span class="n">blocks</span><span class="o">=</span><span class="n">numblocks</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">)</span>

<span class="nd">@assert</span><span class="w"> </span><span class="n">all</span><span class="p">(</span><span class="kt">Array</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">.==</span><span class="w"> </span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-QU1E" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-4-QU1E" name="QU1E" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">AMDGPU</span>

<span class="k">function</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">)</span>
<span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">workitemIdx</span><span class="p">()</span><span class="o">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">workgroupIdx</span><span class="p">()</span><span class="o">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">workgroupDim</span><span class="p">()</span><span class="o">.</span><span class="n">x</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">    </span><span class="k">end</span>
<span class="w">    </span><span class="k">return</span>
<span class="k">end</span>

<span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">);</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">similar</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="n">nthreads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">256</span>
<span class="c"># smallest integer larger than or equal to length(A)/threads</span>
<span class="n">numblocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cld</span><span class="p">(</span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">),</span><span class="w"> </span><span class="n">nthreads</span><span class="p">)</span>

<span class="c"># run using 256 threads</span>
<span class="nd">@roc</span><span class="w"> </span><span class="n">groupsize</span><span class="o">=</span><span class="n">nthreads</span><span class="w"> </span><span class="n">gridsize</span><span class="o">=</span><span class="n">numblocks</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">)</span>

<span class="nd">@assert</span><span class="w"> </span><span class="n">all</span><span class="p">(</span><span class="kt">Array</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">.==</span><span class="w"> </span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-SW50ZWw=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-4-SW50ZWw=" name="SW50ZWw=" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">oneAPI</span>
<span class="c"># WARNING: this is still untested on Intel GPUs</span>
<span class="k">function</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">)</span>
<span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_global_id</span><span class="p">()</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="w">        </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">    </span><span class="k">end</span>
<span class="w">    </span><span class="k">return</span>
<span class="k">end</span>

<span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">oneArray</span><span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span><span class="w"> </span><span class="n">oneArray</span><span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">);</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">similar</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="n">nthreads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">256</span>
<span class="c"># smallest integer larger than or equal to length(A)/threads</span>
<span class="n">numgroups</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cld</span><span class="p">(</span><span class="n">length</span><span class="p">(</span><span class="n">a</span><span class="p">),</span><span class="mi">256</span><span class="p">)</span>

<span class="nd">@oneapi</span><span class="w"> </span><span class="n">items</span><span class="o">=</span><span class="n">nthreads</span><span class="w"> </span><span class="n">groups</span><span class="o">=</span><span class="n">numgroups</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">)</span>

<span class="nd">@assert</span><span class="w"> </span><span class="n">all</span><span class="p">(</span><span class="kt">Array</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">.==</span><span class="w"> </span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-QXBwbGU=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-4-QXBwbGU=" name="QXBwbGU=" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Metal</span>

<span class="k">function</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">)</span>
<span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thread_position_in_grid_1d</span><span class="p">()</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">    </span><span class="k">end</span>
<span class="w">    </span><span class="k">return</span>
<span class="k">end</span>

<span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MtlArray</span><span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="kt">Float32</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span><span class="w"> </span><span class="n">MtlArray</span><span class="p">(</span><span class="kt">Float32</span><span class="p">,</span><span class="w"> </span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">);</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">similar</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>

<span class="n">nthreads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">256</span>
<span class="c"># smallest integer larger than or equal to length(A)/threads</span>
<span class="n">numblocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cld</span><span class="p">(</span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">),</span><span class="w"> </span><span class="n">nthreads</span><span class="p">)</span>

<span class="c"># run using 256 threads</span>
<span class="nd">@metal</span><span class="w"> </span><span class="n">threads</span><span class="o">=</span><span class="n">nthreads</span><span class="w"> </span><span class="n">grid</span><span class="o">=</span><span class="n">numblocks</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">)</span>

<span class="nd">@assert</span><span class="w"> </span><span class="n">all</span><span class="p">(</span><span class="kt">Array</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">.==</span><span class="w"> </span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<div class="admonition-restrictions-in-kernel-programming callout admonition" id="callout-0">
<p class="admonition-title">Restrictions in kernel programming</p>
<p>Within kernels, most of the Julia language is supported with the exception of functionality
that requires the Julia runtime library. This means one cannot allocate memory or perform
dynamic function calls, both of which are easy to do accidentally!</p>
</div>
<div class="admonition-d-2d-and-3d callout admonition" id="callout-1">
<p class="admonition-title">1D, 2D and 3D</p>
<p>CUDA.jl and AMDGPU.jl support indexing in up to 3 dimensions (x, y and z, e.g.
<code class="docutils literal notranslate"><span class="pre">threadIdx().x</span></code> and <code class="docutils literal notranslate"><span class="pre">workitemIdx().x</span></code>). This is convenient
for multidimensional data where thread blocks can be organised into 1D, 2D or 3D arrays of
threads.</p>
</div>
</section>
<section id="writing-protable-kernels">
<h4>Writing protable kernels<a class="headerlink" href="#writing-protable-kernels" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://github.com/JuliaGPU/KernelAbstractions.jl">KernelAbstractions.jl</a>  allows you to write
generic GPU code and run it on GPUs from Nvidia, AMD, Intel or Apple, similar to alpaka and Kokkos
for C++. The backend is the object that decides where the code will be executed. A specific
backend such as <code class="docutils literal notranslate"><span class="pre">ROCBackend()</span></code> becomes available when the corresponding package is loaded.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-TlZJRElB" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-5-TlZJRElB" name="TlZJRElB" role="tab" tabindex="0">NVIDIA</button><button aria-controls="panel-5-QU1E" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-5-QU1E" name="QU1E" role="tab" tabindex="-1">AMD</button><button aria-controls="panel-5-SW50ZWw=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-5-SW50ZWw=" name="SW50ZWw=" role="tab" tabindex="-1">Intel</button><button aria-controls="panel-5-QXBwbGU=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-5-QXBwbGU=" name="QXBwbGU=" role="tab" tabindex="-1">Apple</button></div><div aria-labelledby="tab-5-TlZJRElB" class="sphinx-tabs-panel group-tab" id="panel-5-TlZJRElB" name="TlZJRElB" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">KernelAbstractions</span>

<span class="k">using</span><span class="w"> </span><span class="n">CUDA</span>
<span class="n">backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUDABackend</span><span class="p">()</span>

<span class="nd">@kernel</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="nd">@Const</span><span class="p">(</span><span class="n">A</span><span class="p">),</span><span class="w"> </span><span class="nd">@Const</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
<span class="w">   </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@index</span><span class="p">(</span><span class="n">Global</span><span class="p">)</span>
<span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="w">      </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">   </span><span class="k">end</span>
<span class="k">end</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="kt">Float64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">;</span>
<span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="kt">Float64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">;</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">similar</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">kernel!</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
<span class="n">kernel!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">ndrange</span><span class="o">=</span><span class="n">size</span><span class="p">(</span><span class="n">C</span><span class="p">))</span>
<span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">synchronize</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>

<span class="nd">@assert</span><span class="w"> </span><span class="n">all</span><span class="p">(</span><span class="kt">Array</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">.==</span><span class="w"> </span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-QU1E" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-5-QU1E" name="QU1E" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">KernelAbstractions</span>

<span class="k">using</span><span class="w"> </span><span class="n">AMDGPU</span>
<span class="n">backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROCBackend</span><span class="p">()</span>

<span class="nd">@kernel</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="nd">@Const</span><span class="p">(</span><span class="n">A</span><span class="p">),</span><span class="w"> </span><span class="nd">@Const</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
<span class="w">   </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@index</span><span class="p">(</span><span class="n">Global</span><span class="p">)</span>
<span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="w">      </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">   </span><span class="k">end</span>
<span class="k">end</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="kt">Float64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">;</span>
<span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="kt">Float64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">;</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">similar</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">kernel!</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
<span class="n">kernel!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">ndrange</span><span class="o">=</span><span class="n">size</span><span class="p">(</span><span class="n">C</span><span class="p">))</span>
<span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">synchronize</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>

<span class="nd">@assert</span><span class="w"> </span><span class="n">all</span><span class="p">(</span><span class="kt">Array</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">.==</span><span class="w"> </span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-SW50ZWw=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-5-SW50ZWw=" name="SW50ZWw=" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">KernelAbstractions</span>

<span class="k">using</span><span class="w"> </span><span class="n">oneAPI</span>
<span class="n">backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">oneAPIBackend</span><span class="p">()</span>

<span class="nd">@kernel</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="nd">@Const</span><span class="p">(</span><span class="n">A</span><span class="p">),</span><span class="w"> </span><span class="nd">@Const</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
<span class="w">   </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@index</span><span class="p">(</span><span class="n">Global</span><span class="p">)</span>
<span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="w">      </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">   </span><span class="k">end</span>
<span class="k">end</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="kt">Float64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">;</span>
<span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="kt">Float64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">;</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">similar</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">kernel!</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
<span class="n">kernel!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">ndrange</span><span class="o">=</span><span class="n">size</span><span class="p">(</span><span class="n">C</span><span class="p">))</span>
<span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">synchronize</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>

<span class="nd">@assert</span><span class="w"> </span><span class="n">all</span><span class="p">(</span><span class="kt">Array</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">.==</span><span class="w"> </span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-QXBwbGU=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-5-QXBwbGU=" name="QXBwbGU=" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">KernelAbstractions</span>

<span class="k">using</span><span class="w"> </span><span class="n">Metal</span>
<span class="n">backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MetalBackend</span><span class="p">()</span>

<span class="nd">@kernel</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="nd">@Const</span><span class="p">(</span><span class="n">A</span><span class="p">),</span><span class="w"> </span><span class="nd">@Const</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
<span class="w">   </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@index</span><span class="p">(</span><span class="n">Global</span><span class="p">)</span>
<span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">length</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="w">      </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">   </span><span class="k">end</span>
<span class="k">end</span>

<span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="kt">Float64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">;</span>
<span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="kt">Float64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">9</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">;</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">similar</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">kernel!</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vadd!</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
<span class="n">kernel!</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">ndrange</span><span class="o">=</span><span class="n">size</span><span class="p">(</span><span class="n">C</span><span class="p">))</span>
<span class="n">KernelAbstractions</span><span class="o">.</span><span class="n">synchronize</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>

<span class="nd">@assert</span><span class="w"> </span><span class="n">all</span><span class="p">(</span><span class="kt">Array</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">.==</span><span class="w"> </span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="python">
<h3>Python<a class="headerlink" href="#python" title="Link to this heading"></a></h3>
<p>There has been a lot of progress in GPU programming using Python and the ecosystem is still evolving.
There are a couple of options available to work with GPU.</p>
<section id="cupy">
<h4>CuPy<a class="headerlink" href="#cupy" title="Link to this heading"></a></h4>
<p>CuPy is a NumPy/SciPy-compatible data array library used on GPU. It has been developed for NVIDIA GPUs
but as experimental support for AMD GPUs.
CuPy has a highly compatible interface with NumPy and SciPy. As stated on its official website,
“All you need to do is just replace <em>numpy</em> and <em>scipy</em> with <em>cupy</em> and <em>cupyx.scipy</em> in your Python code.”
If you know NumPy, CuPy is a very easy way to get started on the GPU.</p>
</section>
<section id="cudf">
<h4>cuDF<a class="headerlink" href="#cudf" title="Link to this heading"></a></h4>
<p>RAPIDS is a high level packages collections which implement CUDA functionalities and API with Python bindings.
It only supports NVIDIA GPUs.
cuDF belongs to RAPIDS and is the library for manipulating data frames on GPU.
cuDF provides a pandas-like API, so if you are familiar with Pandas, you can accelerate your work
without knowing too much CUDA programming.</p>
</section>
<section id="pycuda">
<h4>PyCUDA<a class="headerlink" href="#pycuda" title="Link to this heading"></a></h4>
<p>PyCUDA is a Python programming environment for CUDA. It allows users to access to NVIDIA’s CUDA API from Python.
PyCUDA is powerful library but only runs on NVIDIA GPUs. Knowledge of CUDA programming is needed.</p>
</section>
<section id="numba">
<h4>Numba<a class="headerlink" href="#numba" title="Link to this heading"></a></h4>
<p>Numba allows users to just-in-time (JIT) compile Python code to run fast on CPUs, but can also
be used for JIT compiling for GPUs.
In the following we will focus on using Numba, which supports GPUs from both NVIDIA and AMD.</p>
<div class="admonition-amd-support-deprecated callout admonition" id="callout-2">
<p class="admonition-title">AMD support deprecated</p>
<p>Numba supported AMD GPUs up until version 0.53 but has since deprecated the support.</p>
</div>
<p>Numba supports GPU programming by directly compiling a restricted subset of Python code
into kernels and device functions following the execution model.
Kernels written in Numba appear to have direct access to NumPy arrays.
NumPy arrays are transferred between the CPU and the GPU automatically.</p>
<section id="ufunc-gufunc-decorator">
<h5>ufunc (gufunc) decorator<a class="headerlink" href="#ufunc-gufunc-decorator" title="Link to this heading"></a></h5>
<p>Using ufuncs (and generalized ufuncs) is the easiest way to run on a GPU with Numba,
and it requires minimal understanding of GPU programming. Numba <code class="docutils literal notranslate"><span class="pre">&#64;vectorize</span></code>
will produce a ufunc-like object. This object is a close analog but not fully compatible
with a regular NumPy ufunc. Generating a ufunc for GPU requires the explicit
type signature and  target attribute.</p>
</section>
<section id="examples">
<h5>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h5>
<div class="admonition-demo-numba-ufunc demo admonition" id="demo-0">
<p class="admonition-title">Demo: Numba ufunc</p>
<p>Let’s look at a simple mathematical problem:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-6-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-6-6-0" name="6-0" role="tab" tabindex="0">python</button><button aria-controls="panel-6-6-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-1" name="6-1" role="tab" tabindex="-1">Numba ufunc cpu</button><button aria-controls="panel-6-6-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-2" name="6-2" role="tab" tabindex="-1">Numba ufunc gpu</button></div><div aria-labelledby="tab-6-6-0" class="sphinx-tabs-panel" id="panel-6-6-0" name="6-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-1" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-1" name="6-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">vectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f_numba_cpu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-2" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-2" name="6-2" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">vectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f_numba_gpu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>Let’s benchmark:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-7-7-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-7-7-0" name="7-0" role="tab" tabindex="0">python</button><button aria-controls="panel-7-7-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-1" name="7-1" role="tab" tabindex="-1">Numba cpu</button><button aria-controls="panel-7-7-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-2" name="7-2" role="tab" tabindex="-1">Numba gpu</button></div><div aria-labelledby="tab-7-7-0" class="sphinx-tabs-panel" id="panel-7-7-0" name="7-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%timeit</span> -r 1
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000000</span><span class="p">):</span>
    <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="c1"># 6.75 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-1" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-1" name="7-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> res=f_numba_cpu(x, x)
<span class="c1"># 734 ms ± 435 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-2" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-2" name="7-2" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> res=f_numba_gpu(x, x)
<span class="c1"># 78.4 ms ± 6.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
</div></div>
</div>
<p>Numba <code class="docutils literal notranslate"><span class="pre">&#64;vectorize</span></code> is limited to scalar arguments in the core function, for multi-dimensional arrays arguments,
<code class="docutils literal notranslate"><span class="pre">&#64;guvectorize</span></code> is used. Consider the following example which does matrix multiplication.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>One should never implement things like matrix multiplication by oneself
since there are plenty of highly optimized libraries available!</p>
</div>
<div class="admonition-numba-gufunc demo admonition" id="demo-1">
<p class="admonition-title">Numba gufunc</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-8-8-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-8-8-0" name="8-0" role="tab" tabindex="0">python</button><button aria-controls="panel-8-8-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-1" name="8-1" role="tab" tabindex="-1">numba gufunc cpu</button><button aria-controls="panel-8-8-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-2" name="8-2" role="tab" tabindex="-1">numba gufunc gpu</button></div><div aria-labelledby="tab-8-8-0" class="sphinx-tabs-panel" id="panel-8-8-0" name="8-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">matmul_cpu</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-1" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-1" name="8-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="c1">#@numba.guvectorize([&#39;(float64[:,:], float64[:,:], float64[:,:])&#39;], &#39;(m,l),(l,n)-&gt;(m,n)&#39;, target=&#39;cpu&#39;)</span>
<span class="nd">@numba</span><span class="o">.</span><span class="n">guvectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">void</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:])],</span> <span class="s1">&#39;(m,l),(l,n)-&gt;(m,n)&#39;</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_numba_cpu</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-2" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-2" name="8-2" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="c1">#@numba.guvectorize([&#39;(float64[:,:], float64[:,:], float64[:,:])&#39;], &#39;(m,l),(l,n)-&gt;(m,n)&#39;, target=&#39;cuda&#39;)</span>
<span class="nd">@numba</span><span class="o">.</span><span class="n">guvectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">void</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:])],</span> <span class="s1">&#39;(m,l),(l,n)-&gt;(m,n)&#39;</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_numba_gpu</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div></div>
<p>Benchmark:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-9-9-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-9-9-0" name="9-0" role="tab" tabindex="0">Numba gufunc cpu</button><button aria-controls="panel-9-9-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-1" name="9-1" role="tab" tabindex="-1">Numba gufunc gpu</button></div><div aria-labelledby="tab-9-9-0" class="sphinx-tabs-panel" id="panel-9-9-0" name="9-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> matmul_numba_cpu(A,B,C)
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-1" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-1" name="9-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> matmul_numba_gpu(A,B,C)
</pre></div>
</div>
</div></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Numba automatically did a lot of things for us:</p>
<ul class="simple">
<li><p>Memory was allocated on GPU</p></li>
<li><p>Data was copied from CPU and GPU</p></li>
<li><p>The kernel was configured and launched</p></li>
<li><p>Data was copied back from GPU to CPU</p></li>
</ul>
</div>
<p>Using ufuncs (or gfuncs) for GPU processing can be straightforward, but this approach may not always yield optimal performance due to automatic handling of data transfer to and from the GPU, as well as kernel launching. Additionally, in practice, not every function can be constructed as a ufunc.</p>
<p>To gain greater control and flexibility, one may need to craft their own kernels and manually manage data transfer. Refer to the <em>Python for HPDA</em> resource linked below for guidance on implementing such techniques using Numba.</p>
</section>
</section>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-play-around-yourself exercise important admonition" id="exercise-0">
<p class="admonition-title">Play around yourself</p>
<p>Are you a Julian or a Pythonista? Maybe neither, but take a pick between Python and Julia and play around with the code examples provided above.</p>
<p>You can find instructions for running Julia on LUMI and Python on Google Colab in the <a class="reference internal" href="#document-0-setup"><span class="doc">Setup</span></a> episode.</p>
</div>
</section>
<section id="see-also">
<h3>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://enccs.github.io/julia-intro/">Introduction to programming in Julia (ENCCS)</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/julia-for-hpc/">Julia for High-Performance Scientific Computing (ENCCS)</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/julia-for-hpda/">Julia for high-performance data analytics (ENCCS)</a></p></li>
<li><p><a class="reference external" href="https://uppmax.github.io/R-python-julia-matlab-HPC/">Introduction to running R, Python, Julia, and Matlab in HPC (NAISS-LUNARC-HPC2N-UPPMAX)</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/hpda-python/">High Performance Data Analytics in Python (ENCCS)</a></p></li>
<li><p><a class="reference external" href="https://github.com/ENCCS/webinar_documents/tree/main/2024-oct-24-python">Practical Intro to GPU Programming using Python (ENCCS)</a></p></li>
<li><p><a class="reference external" href="https://uppmax.github.io/HPC-python/">Using Python in an HPC environment (UPPMAX-HPC2N)</a></p></li>
<li><p><a class="reference external" href="https://aaltoscicomp.github.io/python-for-scicomp/">Python for Scientific Computing (Aalto Scientific Computing)</a></p></li>
</ul>
</section>
</section>
<span id="document-10-multiple_gpu"></span><section id="multiple-gpu-programming-with-mpi">
<span id="multiple-gpus"></span><h2>Multiple GPU programming with MPI<a class="headerlink" href="#multiple-gpu-programming-with-mpi" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What approach should be adopted to extend the synchronous OpenACC and OpenMP offloading models to utilise multiple GPUs across multiple nodes?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>To learn about combining MPI with either OpenACC or OpenMP offloading models.</p></li>
<li><p>To learn about implementing GPU-awareness MPI approach.</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>30 min teaching</p></li>
<li><p>30 min exercises</p></li>
</ul>
</div>
<section id="introduction">
<h3>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h3>
<p>Exploring multiple GPUs (Graphics Processing Units) across distributed nodes offers the potential to fully leveraging the capacity of modern HPC (High-Performance Computing) systems at a large scale. Here one of the approaches to accelerate computing on distributed systems is to combine MPI (Message Passing Interface) with a GPU programming model such as OpenACC and OpenMP application programming interfaces (APIs). This combination is motivated by both the simplicity of these APIs, and the widespread use of MPI.</p>
<p>In this guide we provide readers, who are familiar with MPI, with insights on implementing a hybrid model in which the MPI communication framework is combined with either OpenACC or OpenMP APIs. A special focus will be on performing point-to-point (e.g. <cite>MPI_Send</cite> and <cite>MPI_Recv</cite>) and collective operations (e.g. <cite>MPI_Allreduce</cite>) from OpenACC and OpenMP APIs. Here we address two scenarios: (i) a scenario in which MPI operations are performed in the CPU-host followed by an offload to the GPU-device; and (ii) a scenario in which MPI operations are performed between a pair of GPUs without involving the CPU-host memory. The latter scenario is referred to as GPU-awareness MPI, and has the advantage of reducing the computing time caused by transferring data via the host-memory during heterogeneous communications, thus rendering HPC applications efficient.</p>
<p>This guide is organized as follows: we first introduce how to assign each MPI rank to a GPU device within the same node. We consider a situation in which the host and the device have a distinct memory. This is followed by a presentation on the hybrid MPI-OpenACC/OpenMP offloading with and without the GPU-awareness MPI. Exercises to help understanding these concepts are provided at the end.</p>
</section>
<section id="assigning-mpi-ranks-to-gpu-devices">
<h3>Assigning MPI-ranks to GPU-devices<a class="headerlink" href="#assigning-mpi-ranks-to-gpu-devices" title="Link to this heading"></a></h3>
<p>Accelerating MPI applications to utilise multiple GPUs on distributed nodes requires as a first step assigning each MPI rank to a GPU device, such that two MPI ranks do not use the same GPU device. This is necessarily in order to prevent the application from a potential crash. This is because GPUs are designed to handle multiple threading tasks, but not multiple MPI ranks.</p>
<p>One of the way to ensure that two MPI ranks do not use the same GPU, is to determine which MPI processes run on the same node, such that each process can be assigned to a GPU device within the same node. This can be done, for instance, by splitting the world communicator into sub-groups of communicators (or sub-communicators) using the routine <cite>MPI_COMM_SPLIT_TYPE()</cite>.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Splitting communicator in MPI (Fortran)</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Splitting communicator in MPI (C++)</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">! Split the world communicator into subgroups of commu, each of which</span>
<span class="w">    </span><span class="c">! contains processes that run on the same node, and which can create a</span>
<span class="w">    </span><span class="c">! shared memory region (via the type MPI_COMM_TYPE_SHARED).</span>
<span class="w">    </span><span class="c">! The call returns a new communicator &quot;host_comm&quot;, which is created by</span>
<span class="w">    </span><span class="c">! each subgroup.        </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_SPLIT_TYPE</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_TYPE_SHARED</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,&amp;</span>
<span class="w">                            </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span><span class="w"> </span><span class="n">host_comm</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_RANK</span><span class="p">(</span><span class="n">host_comm</span><span class="p">,</span><span class="w"> </span><span class="n">host_rank</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="c1">// Split the world communicator into subgroups.</span>
<span class="w">  </span><span class="n">MPI_Comm</span><span class="w"> </span><span class="n">host_comm</span><span class="p">;</span>
<span class="w">  </span><span class="n">MPI_Comm_split_type</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_TYPE_SHARED</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span>
<span class="w">                      </span><span class="o">&amp;</span><span class="n">host_comm</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">host_rank</span><span class="p">;</span>
<span class="w">  </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">host_comm</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">host_rank</span><span class="p">);</span>
</pre></div>
</div>
</div></div>
<p>Here, the size of each sub-communicator corresponds to the number of GPUs per node (which is also the number of tasks per node), and each sub-communicator contains a list of processes indicated by a rank. These processes have a shared-memory region defined by the argument <cite>MPI_COMM_TYPE_SHARED</cite> (see the <a class="reference external" href="https://www.mpi-forum.org/docs/mpi-4.0/mpi40-report.pdf">MPI report</a>) for more details). Calling the routine <cite>MPI_COMM_SPLIT_TYPE()</cite> returns a sub-communicator labelled in the code above <em>”host_comm”</em>, and in which MPI-ranks are ranked from 0 to number of processes per node -1. These MPI ranks are in turn assigned to different GPU devices within the same node. This procedure is done according to which directive-based model is implemented. The retrieved MPI ranks are then stored in the variable <strong>myDevice</strong>. The variable is passed to an OpenACC or OpenMP routine as indicated in the code below.</p>
<div class="admonition-example-assign-device typealong toggle-shown dropdown admonition" id="typealong-0">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">Assign</span> <span class="pre">device</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">Fortran OpenACC</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">Fortran OpenMP</button><button aria-controls="panel-1-1-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-2" name="1-2" role="tab" tabindex="-1">C++ OpenMP</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="n">myDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">host_rank</span>

<span class="w">    </span><span class="c">! Sets the device number and the device type to be used</span>
<span class="w">    </span><span class="k">call </span><span class="n">acc_set_device_num</span><span class="p">(</span><span class="n">myDevice</span><span class="p">,</span><span class="w"> </span><span class="n">acc_get_device_type</span><span class="p">())</span>

<span class="w">    </span><span class="c">! Returns the number of devices available on the host</span>
<span class="w">    </span><span class="n">numDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc_get_num_devices</span><span class="p">(</span><span class="n">acc_get_device_type</span><span class="p">())</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="n">myDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">host_rank</span>

<span class="w">    </span><span class="c">! Sets the device number to use in device constructs by setting the initial value of the default-device-var </span>
<span class="w">    </span><span class="k">call </span><span class="n">omp_set_default_device</span><span class="p">(</span><span class="n">myDevice</span><span class="p">)</span>

<span class="w">    </span><span class="c">! Returns the number of devices available for offloading.</span>
<span class="w">    </span><span class="n">numDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_num_devices</span><span class="p">()</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-2" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-2" name="1-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">myDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">host_rank</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// Set the device number to use in device constructs.</span>
<span class="w">  </span><span class="n">omp_set_default_device</span><span class="p">(</span><span class="n">myDevice</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Return the number of devices available for offloading.</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">numDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_num_devices</span><span class="p">();</span>
</pre></div>
</div>
</div></div>
</div>
<p>Another useful function for retrieving the device number of a specific device, which is useful, e.g., to map data to a specific device is</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">OpenACC</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">OpenMP</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="n">acc_get_device_num</span><span class="p">()</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="n">omp_get_device_num</span><span class="p">()</span>
</pre></div>
</div>
</div></div>
<p>The syntax of assigning MPI ranks to GPU devices is summarised below</p>
<div class="admonition-example-set-device typealong toggle-shown dropdown admonition" id="typealong-1">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">Set</span> <span class="pre">device</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">Fortran OpenACC</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1">Fortran OpenMP</button><button aria-controls="panel-3-3-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-2" name="3-2" role="tab" tabindex="-1">C++ OpenMP</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">! Initialise MPI communication      </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_Init</span><span class="p">(</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="c">! Identify the ID rank (process)        </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_RANK</span><span class="p">(</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">myid</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="c">! Get number of active processes (from 0 to nproc-1)        </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_SIZE</span><span class="p">(</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">nproc</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>

<span class="w">    </span><span class="c">! Split the world communicator into subgroups of commu, each of which</span>
<span class="w">    </span><span class="c">! contains processes that run on the same node, and which can create a</span>
<span class="w">    </span><span class="c">! shared memory region (via the type MPI_COMM_TYPE_SHARED).</span>
<span class="w">    </span><span class="c">! The call returns a new communicator &quot;host_comm&quot;, which is created by</span>
<span class="w">    </span><span class="c">! each subgroup.        </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_SPLIT_TYPE</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_TYPE_SHARED</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,&amp;</span>
<span class="w">                            </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span><span class="w"> </span><span class="n">host_comm</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_RANK</span><span class="p">(</span><span class="n">host_comm</span><span class="p">,</span><span class="w"> </span><span class="n">host_rank</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>

<span class="w">    </span><span class="c">! Gets the node name</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_GET_PROCESSOR_NAME</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">resulten</span><span class="p">,</span><span class="w"> </span><span class="n">ierror</span><span class="p">)</span>

<span class="w">    </span><span class="n">myDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">host_rank</span>

<span class="w">    </span><span class="c">! Sets the device number and the device type to be used</span>
<span class="w">    </span><span class="k">call </span><span class="n">acc_set_device_num</span><span class="p">(</span><span class="n">myDevice</span><span class="p">,</span><span class="w"> </span><span class="n">acc_get_device_type</span><span class="p">())</span>

<span class="w">    </span><span class="c">! Returns the number of devices available on the host</span>
<span class="w">    </span><span class="n">numDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc_get_num_devices</span><span class="p">(</span><span class="n">acc_get_device_type</span><span class="p">())</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">! Initialise MPI communication      </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_Init</span><span class="p">(</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="c">! Identify the ID rank (process)        </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_RANK</span><span class="p">(</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">myid</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="c">! Get number of active processes (from 0 to nproc-1)        </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_SIZE</span><span class="p">(</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">nproc</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>

<span class="w">    </span><span class="c">! Split the world communicator into subgroups of commu, each of which</span>
<span class="w">    </span><span class="c">! contains processes that run on the same node, and which can create a</span>
<span class="w">    </span><span class="c">! shared memory region (via the type MPI_COMM_TYPE_SHARED).</span>
<span class="w">    </span><span class="c">! The call returns a new communicator &quot;host_comm&quot;, which is created by</span>
<span class="w">    </span><span class="c">! each subgroup.        </span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_SPLIT_TYPE</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_TYPE_SHARED</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,&amp;</span>
<span class="w">                            </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span><span class="w"> </span><span class="n">host_comm</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_COMM_RANK</span><span class="p">(</span><span class="n">host_comm</span><span class="p">,</span><span class="w"> </span><span class="n">host_rank</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>

<span class="w">    </span><span class="c">! Gets the node name</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_GET_PROCESSOR_NAME</span><span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">resulten</span><span class="p">,</span><span class="w"> </span><span class="n">ierror</span><span class="p">)</span>

<span class="w">    </span><span class="n">myDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">host_rank</span>

<span class="w">    </span><span class="c">! Sets the device number to use in device constructs by setting the initial value of the default-device-var </span>
<span class="w">    </span><span class="k">call </span><span class="n">omp_set_default_device</span><span class="p">(</span><span class="n">myDevice</span><span class="p">)</span>

<span class="w">    </span><span class="c">! Returns the number of devices available for offloading.</span>
<span class="w">    </span><span class="n">numDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_num_devices</span><span class="p">()</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-2" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-2" name="3-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="c1">// Initialize MPI communication.</span>
<span class="w">  </span><span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Identify the ID rank (process).</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">myid</span><span class="p">,</span><span class="w"> </span><span class="n">nproc</span><span class="p">;</span>
<span class="w">  </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">myid</span><span class="p">);</span>
<span class="w">  </span><span class="c1">// Get number of active processes.</span>
<span class="w">  </span><span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nproc</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Split the world communicator into subgroups.</span>
<span class="w">  </span><span class="n">MPI_Comm</span><span class="w"> </span><span class="n">host_comm</span><span class="p">;</span>
<span class="w">  </span><span class="n">MPI_Comm_split_type</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_TYPE_SHARED</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span>
<span class="w">                      </span><span class="o">&amp;</span><span class="n">host_comm</span><span class="p">);</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">host_rank</span><span class="p">;</span>
<span class="w">  </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">host_comm</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">host_rank</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Get the node name.</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">name_len</span><span class="p">;</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">processor_name</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>
<span class="w">  </span><span class="n">MPI_Get_processor_name</span><span class="p">(</span><span class="n">processor_name</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">name_len</span><span class="p">);</span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">myDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">host_rank</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// Set the device number to use in device constructs.</span>
<span class="w">  </span><span class="n">omp_set_default_device</span><span class="p">(</span><span class="n">myDevice</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Return the number of devices available for offloading.</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">numDevice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_num_devices</span><span class="p">();</span>
</pre></div>
</div>
</div></div>
</div>
</section>
<section id="hybrid-mpi-openacc-openmp-without-gpu-awareness-approach">
<h3>Hybrid MPI-OpenACC/OpenMP without GPU-awareness approach<a class="headerlink" href="#hybrid-mpi-openacc-openmp-without-gpu-awareness-approach" title="Link to this heading"></a></h3>
<p>After covering how to assign each MPI-rank to a GPU device, we now address the concept of combining MPI with either
OpenACC or OpenMP offloading. In this approach, calling an MPI routine from an OpenACC or OpenMP API requires updating the data in the CPU host before and after an MPI call. In this scenario, the data is copied back and forth between the host and the device before and after each MPI call. In the hybrid MPI-OpenACC model, the procedure is defined by specifying the directive <cite>update host()</cite> for copying the data from the device to the host before an MPI call; and by the directive <cite>update device()</cite> specified after an MPI call for copying the data back to the device. Similarly in the hybrid MPI-OpenMP. Here, updating the data in the host can be done by specifying the OpenMP directives <cite>update device() from()</cite> and <cite>update device() to()</cite>, respectively, for copying the data from the device to the host and back to the device.</p>
<p>To illustrate the concept of the hybrid MPI-OpenACC/OpenMP, we show below an example of an implementation that involves the MPI functions <cite>MPI_Send()</cite> and <cite>MPI_Recv()</cite>.</p>
<div class="admonition-example-update-host-device-directives typealong toggle-shown dropdown admonition" id="typealong-2">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">Update</span> <span class="pre">host/device</span> <span class="pre">directives</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">Fortran OpenACC</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1">Fortran OpenMP</button><button aria-controls="panel-4-4-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-2" name="4-2" role="tab" tabindex="-1">C++ OpenMP</button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">!offload f to GPUs</span>
<span class="w">    </span><span class="c">!$acc enter data copyin(f)</span>

<span class="w">    </span><span class="c">!update f: copy f from GPU to CPU</span>
<span class="w">    </span><span class="c">!$acc update host(f)</span>

<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="p">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="k">    if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="w">    </span><span class="c">!update f: copy f from CPU to GPU</span>
<span class="w">    </span><span class="c">!$acc update device(f)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">!offload f to GPUs</span>
<span class="w">    </span><span class="c">!$omp target enter data device(myDevice) map(to:f)</span>

<span class="w">    </span><span class="c">!update f: copy f from GPU to CPU</span>
<span class="w">    </span><span class="c">!$omp target update device(myDevice) from(f)</span>

<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="p">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="k">    if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="w">    </span><span class="c">!update f: copy f from CPU to GPU</span>
<span class="w">    </span><span class="c">!$omp target update device(myDevice) to(f)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-2" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-2" name="4-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Offload f to GPUs</span>
<span class="cp">#pragma omp target enter data map(to : f[0 : np]) device(myDevice)</span>

<span class="w">  </span><span class="c1">// update f: copy f from GPU to CPU</span>
<span class="cp">#pragma omp target update device(myDevice) from(f)</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nproc</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">f</span><span class="p">[</span><span class="n">np</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">myid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myid</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">myid</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span>
<span class="w">             </span><span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="c1">// update f: copy f from CPU to GPU</span>
<span class="cp">#pragma omp target update device(myDevice) to(f)</span>
</pre></div>
</div>
</div></div>
</div>
<p>Here we present a code example that combines MPI with OpenACC/OpenMP API.</p>
<div class="admonition-example-update-host-device-directives typealong toggle-shown dropdown admonition" id="typealong-3">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">Update</span> <span class="pre">host/device</span> <span class="pre">directives</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-5-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-5-5-0" name="5-0" role="tab" tabindex="0">Fortan OpenACC</button><button aria-controls="panel-5-5-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-1" name="5-1" role="tab" tabindex="-1">Fortran OpenMP</button><button aria-controls="panel-5-5-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-2" name="5-2" role="tab" tabindex="-1">C++ OpenMP</button></div><div aria-labelledby="tab-5-5-0" class="sphinx-tabs-panel" id="panel-5-5-0" name="5-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="k">call </span><span class="n">MPI_Scatter</span><span class="p">(</span><span class="n">f_send</span><span class="p">,</span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>

<span class="w">    </span><span class="c">!offload f to GPUs</span>
<span class="w">    </span><span class="c">!$acc enter data copyin(f)</span>

<span class="w">    </span><span class="c">!update f: copy f from GPU to CPU</span>
<span class="w">    </span><span class="c">!$acc update host(f)</span>

<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="p">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="k">    if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="w">    </span><span class="c">!update f: copy f from CPU to GPU</span>
<span class="w">    </span><span class="c">!$acc update device(f)</span>

<span class="w">    </span><span class="c">!do something .e.g.</span>
<span class="w">    </span><span class="c">!$acc kernels</span>
<span class="w">    </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="o">/</span><span class="mf">2.</span>
<span class="w">    </span><span class="c">!$acc end kernels</span>

<span class="w">    </span><span class="n">SumToT</span><span class="o">=</span><span class="mi">0</span><span class="n">d0</span>
<span class="w">    </span><span class="c">!$acc parallel loop reduction(+:SumToT)</span>
<span class="w">    </span><span class="k">do </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span>
<span class="w">        </span><span class="n">SumToT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SumToT</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$acc end parallel loop</span>

<span class="w">    </span><span class="c">!SumToT is by default copied back to the CPU</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_ALLREDUCE</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="n">SumToT</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">MPI_SUM</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>

<span class="w">    </span><span class="c">!$acc exit data delete(f)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-1" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-1" name="5-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="k">call </span><span class="n">MPI_Scatter</span><span class="p">(</span><span class="n">f_send</span><span class="p">,</span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>

<span class="w">    </span><span class="c">!offload f to GPUs</span>
<span class="w">    </span><span class="c">!$omp target enter data device(myDevice) map(to:f)</span>

<span class="w">    </span><span class="c">!update f: copy f from GPU to CPU</span>
<span class="w">    </span><span class="c">!$omp target update device(myDevice) from(f)</span>

<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="p">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="k">    if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="w">    </span><span class="c">!update f: copy f from CPU to GPU</span>
<span class="w">    </span><span class="c">!$omp target update device(myDevice) to(f)</span>

<span class="w">    </span><span class="c">!do something .e.g.</span>
<span class="w">    </span><span class="c">!$omp target teams distribute parallel do</span>
<span class="w">    </span><span class="k">do </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span>
<span class="w">        </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">/</span><span class="mf">2.</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$omp end target teams distribute parallel do</span>

<span class="w">    </span><span class="n">SumToT</span><span class="o">=</span><span class="mi">0</span><span class="n">d0</span>
<span class="w">    </span><span class="c">!$omp target teams distribute parallel do reduction(+:SumToT)</span>
<span class="w">    </span><span class="k">do </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span>
<span class="w">        </span><span class="n">SumToT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SumToT</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$omp end target teams distribute parallel do  </span>

<span class="w">    </span><span class="c">!SumToT is by default copied back to the CPU</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_ALLREDUCE</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="n">SumToT</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">MPI_SUM</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>

<span class="w">    </span><span class="c">!$omp target exit data map(delete:f)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-2" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-2" name="5-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="n">MPI_Scatter</span><span class="p">(</span><span class="n">f_send</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">              </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

<span class="c1">// Offload f to GPUs</span>
<span class="cp">#pragma omp target enter data map(to : f[0 : np]) device(myDevice)</span>

<span class="w">  </span><span class="c1">// update f: copy f from GPU to CPU</span>
<span class="cp">#pragma omp target update device(myDevice) from(f)</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nproc</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">f</span><span class="p">[</span><span class="n">np</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">myid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myid</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">myid</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span>
<span class="w">             </span><span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="c1">// update f: copy f from CPU to GPU</span>
<span class="cp">#pragma omp target update device(myDevice) to(f)</span>

<span class="c1">// Update, operate, and offload data back to GPUs</span>
<span class="cp">#pragma omp target teams distribute parallel for device(myDevice)</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">np</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">f</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="mf">2.0</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">SumToT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>

<span class="cp">#pragma omp target teams distribute parallel for reduction(+ : SumToT)         \</span>
<span class="cp">    device(myDevice)</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">np</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">SumToT</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="p">[</span><span class="n">k</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">MPI_Allreduce</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">SumToT</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_SUM</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

<span class="cp">#pragma omp target exit data map(delete : f[0 : np])</span>
</pre></div>
</div>
</div></div>
</div>
<p>Despite the simplicity of implementing the hybrid MPI-OpenACC/OpenMP offloading, it suffers from a low performance caused by an explicit transfer of data between the host and the device before and after calling an MPI routine. This constitutes a bottleneck in GPU-programming. To improve the performance affected by the host staging during the data transfer, one can implement the GPU-awareness MPI approach as described in the following section.</p>
</section>
<section id="hybrid-mpi-openacc-openmp-with-gpu-awareness-approach">
<h3>Hybrid MPI-OpenACC/OpenMP with GPU-awareness approach<a class="headerlink" href="#hybrid-mpi-openacc-openmp-with-gpu-awareness-approach" title="Link to this heading"></a></h3>
<p>The concept of the GPU-aware MPI enables an MPI library to directly access the GPU-device memory without necessarily using the CPU-host memory as an intermediate buffer (see e.g. <a class="reference external" href="https://docs.open-mpi.org/en/v5.0.1/tuning-apps/networking/cuda.html">OpenMPI documentation</a>). This offers the benefit of transferring data from one GPU to another GPU without the involvement of the CPU-host memory.</p>
<p>To be specific, in the GPU-awareness approach, the device pointers point to the data allocated in the GPU memory space (data should be present in the GPU device). Here, the pointers are passed as arguments to an MPI routine that is supported by the GPU memory. As MPI routines can directly access GPU memory, it offers the possibility of communicating between pairs of GPUs without transferring data back to the host.</p>
<p>In the hybrid MPI-OpenACC model, the concept is defined by combining the directive <cite>host_data</cite> together with the clause
<cite>use_device(list_array)</cite>. This combination enables the access to the arrays listed in the clause <cite>use_device(list_array)</cite> from the host (see <a class="reference external" href="https://www.openacc.org/sites/default/files/inline-images/Specification/OpenACC-3.2-final.pdf">here</a>). The list of arrays, which are already present in the GPU-device memory, are directly passed to an MPI routine without a need of a staging host-memory for copying the data. Note that for initially copying data to GPU, we use unstructured data blocks characterized by the directives <cite>enter data</cite> and <cite>exit data</cite>. The unstructured data has the advantage of allowing to allocate and deallocate arrays within a data region.</p>
<p>To illustrate the concept of the GPU-awareness MPI, we show below two examples that make use of point-to-point and collective operations from OpenACC and OpenMP APIs. In the first code example, the device pointer <strong>f</strong> is passed to the MPI functions <cite>MPI_Send()</cite> and <cite>MPI_Recv()</cite>; and in the second one, the pointer <strong>SumToT</strong> is passed to the MPI function <cite>MPI_Allreduce</cite>. Here, the MPI operations <cite>MPI_Send</cite> and <cite>MPI_Recv</cite> as well as <cite>MPI_Allreduce</cite> are performed between a pair of GPUs without passing through the CPU-host memory.</p>
<div class="admonition-example-gpu-awareness-mpi-send-mpi-recv typealong toggle-shown dropdown admonition" id="typealong-4">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">GPU-awareness:</span> <span class="pre">MPI_Send</span> <span class="pre">&amp;</span> <span class="pre">MPI_Recv</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-6-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-6-6-0" name="6-0" role="tab" tabindex="0">GPU-aware MPI with OpenACC (Fortran)</button><button aria-controls="panel-6-6-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-1" name="6-1" role="tab" tabindex="-1">GPU-aware MPI with OpenMP (Fortran)</button><button aria-controls="panel-6-6-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-2" name="6-2" role="tab" tabindex="-1">GPU-aware MPI with OpenMP (C++)</button></div><div aria-labelledby="tab-6-6-0" class="sphinx-tabs-panel" id="panel-6-6-0" name="6-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">!Device pointer f will be passed to MPI_send &amp; MPI_recv</span>
<span class="w">    </span><span class="c">!$acc host_data use_device(f)</span>
<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="p">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="k">    if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>
<span class="w">    </span><span class="c">!$acc end host_data</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-1" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-1" name="6-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">!Device pointer f will be passed to MPI_send &amp; MPI_recv</span>
<span class="w">    </span><span class="c">!$omp target data use_device_ptr(f)</span>
<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="p">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="k">    if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>
<span class="w">    </span><span class="c">!$omp end target data</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-2" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-2" name="6-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma omp target data use_device_ptr(f)</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nproc</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">f</span><span class="p">[</span><span class="n">np</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">myid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myid</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">myid</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span>
<span class="w">               </span><span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
</pre></div>
</div>
</div></div>
</div>
<div class="admonition-example-gpu-awareness-mpi-allreduce typealong toggle-shown dropdown admonition" id="typealong-5">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">GPU-awareness:</span> <span class="pre">MPI_Allreduce</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-7-7-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-7-7-0" name="7-0" role="tab" tabindex="0">GPU-aware MPI with OpenACC (Fortran)</button><button aria-controls="panel-7-7-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-1" name="7-1" role="tab" tabindex="-1">GPU-aware MPI with OpenMP (Fortran)</button><button aria-controls="panel-7-7-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-2" name="7-2" role="tab" tabindex="-1">GPU-aware MPI with OpenMP (C++)</button></div><div aria-labelledby="tab-7-7-0" class="sphinx-tabs-panel" id="panel-7-7-0" name="7-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">!$acc data copy(SumToT)</span>
<span class="w">    </span><span class="c">!$acc host_data use_device(SumToT)</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_ALLREDUCE</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="n">SumToT</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">MPI_SUM</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="c">!$acc end host_data</span>
<span class="w">    </span><span class="c">!$acc end data</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-1" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-1" name="7-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c">!$omp target enter data device(myDevice) map(to:SumToT)</span>
<span class="w">    </span><span class="c">!$omp target data use_device_ptr(SumToT)</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_ALLREDUCE</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="n">SumToT</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">MPI_SUM</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="c">!$omp end target data</span>
<span class="w">    </span><span class="c">!$omp target exit data map(from:SumToT)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-2" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-2" name="7-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma omp target enter data device(myDevice) map(to : SumToT)</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">SumToTPtr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">SumToT</span><span class="p">;</span>
<span class="cp">#pragma omp target data use_device_ptr(SumToTPtr)</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="n">MPI_Allreduce</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="w"> </span><span class="n">SumToTPtr</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_SUM</span><span class="p">,</span>
<span class="w">                  </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="cp">#pragma omp target exit data map(from : SumToT)</span>
</pre></div>
</div>
</div></div>
</div>
<p>We provide below a code example that illustrates the implementation of the MPI functions <cite>MPI_Send()</cite>, <cite>MPI_Recv()</cite> and <cite>MPI_Allreduce()</cite> within an OpenACC/OpenMP API. This implementation is specifically designed to support GPU-aware MPI operations.</p>
<div class="admonition-example-gpu-awareness-approach typealong toggle-shown dropdown admonition" id="typealong-6">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">GPU-awareness</span> <span class="pre">approach</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-8-8-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-8-8-0" name="8-0" role="tab" tabindex="0">GPU-aware MPI with OpenACC (Fortran)</button><button aria-controls="panel-8-8-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-1" name="8-1" role="tab" tabindex="-1">GPU-aware MPI with OpenMP (Fortran)</button><button aria-controls="panel-8-8-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-2" name="8-2" role="tab" tabindex="-1">GPU-aware MPI with OpenMP (C++)</button></div><div aria-labelledby="tab-8-8-0" class="sphinx-tabs-panel" id="panel-8-8-0" name="8-0" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="k">call </span><span class="n">MPI_Scatter</span><span class="p">(</span><span class="n">f_send</span><span class="p">,</span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>

<span class="w">    </span><span class="c">!offload f to GPUs</span>
<span class="w">    </span><span class="c">!$acc enter data copyin(f)</span>

<span class="w">    </span><span class="c">!Device pointer f will be passed to MPI_send &amp; MPI_recv</span>
<span class="w">    </span><span class="c">!$acc host_data use_device(f)</span>
<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="p">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="k">    if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>
<span class="w">    </span><span class="c">!$acc end host_data</span>

<span class="w">    </span><span class="c">!do something .e.g.</span>
<span class="w">    </span><span class="c">!$acc kernels</span>
<span class="w">    </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="o">/</span><span class="mf">2.</span>
<span class="w">    </span><span class="c">!$acc end kernels</span>

<span class="w">    </span><span class="n">SumToT</span><span class="o">=</span><span class="mi">0</span><span class="n">d0</span>
<span class="w">    </span><span class="c">!$acc parallel loop reduction(+:SumToT)</span>
<span class="w">    </span><span class="k">do </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span>
<span class="w">        </span><span class="n">SumToT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SumToT</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$acc end parallel loop</span>

<span class="w">    </span><span class="c">!SumToT is by default copied back to the CPU</span>

<span class="w">    </span><span class="c">!$acc data copy(SumToT)</span>
<span class="w">    </span><span class="c">!$acc host_data use_device(SumToT)</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_ALLREDUCE</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="n">SumToT</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">MPI_SUM</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="c">!$acc end host_data</span>
<span class="w">    </span><span class="c">!$acc end data</span>

<span class="w">    </span><span class="c">!$acc exit data delete(f)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-1" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-1" name="8-1" role="tabpanel" tabindex="0"><div class="highlight-fortran notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="k">call </span><span class="n">MPI_Scatter</span><span class="p">(</span><span class="n">f_send</span><span class="p">,</span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>

<span class="w">    </span><span class="c">!offload f to GPUs</span>
<span class="w">    </span><span class="c">!$omp target enter data device(myDevice) map(to:f)</span>

<span class="w">    </span><span class="c">!Device pointer f will be passed to MPI_send &amp; MPI_recv</span>
<span class="w">    </span><span class="c">!$omp target data use_device_ptr(f)</span>
<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="p">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>

<span class="k">    if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">        call </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="k">endif</span>
<span class="w">    </span><span class="c">!$omp end target data</span>

<span class="w">    </span><span class="c">!do something .e.g.</span>
<span class="w">    </span><span class="c">!$omp target teams distribute parallel do</span>
<span class="w">    </span><span class="k">do </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span>
<span class="w">        </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">/</span><span class="mf">2.</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$omp end target teams distribute parallel do</span>

<span class="w">    </span><span class="n">SumToT</span><span class="o">=</span><span class="mi">0</span><span class="n">d0</span>
<span class="w">    </span><span class="c">!$omp target teams distribute parallel do reduction(+:SumToT)</span>
<span class="w">    </span><span class="k">do </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span>
<span class="w">        </span><span class="n">SumToT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SumToT</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="w">    </span><span class="k">enddo</span>
<span class="w">    </span><span class="c">!$omp end target teams distribute parallel do  </span>

<span class="w">    </span><span class="c">!SumToT is by default copied back to the CPU</span>

<span class="w">    </span><span class="c">!$omp target enter data device(myDevice) map(to:SumToT)</span>
<span class="w">    </span><span class="c">!$omp target data use_device_ptr(SumToT)</span>
<span class="w">    </span><span class="k">call </span><span class="n">MPI_ALLREDUCE</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="n">SumToT</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">MPI_SUM</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="c">!$omp end target data</span>
<span class="w">    </span><span class="c">!$omp target exit data map(from:SumToT)</span>

<span class="w">    </span><span class="c">!$omp target exit data map(delete:f)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-2" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-2" name="8-2" role="tabpanel" tabindex="0"><div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="n">call</span><span class="w"> </span><span class="n">MPI_Scatter</span><span class="p">(</span><span class="n">f_send</span><span class="p">,</span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>

<span class="w">    </span><span class="o">!</span><span class="n">offload</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">GPUs</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">enter</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">device</span><span class="p">(</span><span class="n">myDevice</span><span class="p">)</span><span class="w"> </span><span class="n">map</span><span class="p">(</span><span class="n">to</span><span class="o">:</span><span class="n">f</span><span class="p">)</span>

<span class="w">    </span><span class="o">!</span><span class="n">Device</span><span class="w"> </span><span class="n">pointer</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">passed</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">MPI_send</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">MPI_recv</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">use_device_ptr</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">lt</span><span class="p">.</span><span class="n">nproc</span><span class="mi">-1</span><span class="p">)</span><span class="w"> </span><span class="n">then</span>
<span class="w">        </span><span class="n">call</span><span class="w"> </span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">:</span><span class="n">np</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="n">endif</span>

<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">myid</span><span class="p">.</span><span class="n">gt</span><span class="mf">.0</span><span class="p">)</span><span class="w"> </span><span class="n">then</span>
<span class="w">        </span><span class="n">call</span><span class="w"> </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">myid</span><span class="mi">-1</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
<span class="w">    </span><span class="n">endif</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">data</span>

<span class="w">    </span><span class="o">!</span><span class="k">do</span><span class="w"> </span><span class="n">something</span><span class="w"> </span><span class="p">.</span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">teams</span><span class="w"> </span><span class="n">distribute</span><span class="w"> </span><span class="n">parallel</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span><span class="k">do</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span>
<span class="w">        </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">/</span><span class="mf">2.</span>
<span class="w">    </span><span class="n">enddo</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">teams</span><span class="w"> </span><span class="n">distribute</span><span class="w"> </span><span class="n">parallel</span><span class="w"> </span><span class="k">do</span>

<span class="w">    </span><span class="n">SumToT</span><span class="o">=</span><span class="mi">0</span><span class="n">d0</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">teams</span><span class="w"> </span><span class="n">distribute</span><span class="w"> </span><span class="n">parallel</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">reduction</span><span class="p">(</span><span class="o">+:</span><span class="n">SumToT</span><span class="p">)</span>
<span class="w">    </span><span class="k">do</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span>
<span class="w">        </span><span class="n">SumToT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SumToT</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="w">    </span><span class="n">enddo</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">teams</span><span class="w"> </span><span class="n">distribute</span><span class="w"> </span><span class="n">parallel</span><span class="w"> </span><span class="k">do</span><span class="w">  </span>

<span class="w">    </span><span class="o">!</span><span class="n">SumToT</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="n">copied</span><span class="w"> </span><span class="n">back</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">CPU</span>

<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">enter</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">device</span><span class="p">(</span><span class="n">myDevice</span><span class="p">)</span><span class="w"> </span><span class="n">map</span><span class="p">(</span><span class="n">to</span><span class="o">:</span><span class="n">SumToT</span><span class="p">)</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">use_device_ptr</span><span class="p">(</span><span class="n">SumToT</span><span class="p">)</span>
<span class="w">    </span><span class="n">call</span><span class="w"> </span><span class="n">MPI_ALLREDUCE</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="n">SumToT</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="n">MPI_SUM</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">data</span>
<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">exit</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">map</span><span class="p">(</span><span class="n">from</span><span class="o">:</span><span class="n">SumToT</span><span class="p">)</span>

<span class="w">    </span><span class="o">!</span><span class="n">$omp</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">exit</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">map</span><span class="p">(</span><span class="k">delete</span><span class="o">:</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
</div>
<p>The GPU-aware MPI with OpenACC/OpenMP APIs has the capability of directly communicating between a pair of GPUs within a single node. However, performing the GPU-to-GPU communication across multiple nodes requires the the GPUDirect RDMA (Remote Direct Memory Access) technology. This technology can further improve performance by reducing latency.</p>
</section>
<section id="compilation-process">
<h3>Compilation process<a class="headerlink" href="#compilation-process" title="Link to this heading"></a></h3>
<p>The compilation process of the hybrid MPI-OpenACC and MPI-OpenMP offloading is described below. This description is given for a Cray compiler of the wrapper <cite>ftn</cite>. On LUMI-G, the following modules may be necessary before compiling (see the <a class="reference external" href="https://docs.lumi-supercomputer.eu/development/compiling/prgenv/">LUMI documentation</a> for further details about the available programming environments):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ml<span class="w"> </span>LUMI/24.03
<span class="gp">$ </span>ml<span class="w"> </span>PrgEnv-cray
<span class="gp">$ </span>ml<span class="w"> </span>cray-mpich
<span class="gp">$ </span>ml<span class="w"> </span>rocm
<span class="gp">$ </span>ml<span class="w"> </span>craype-accel-amd-gfx90a
</pre></div>
</div>
<div class="admonition-example-compilation-process typealong toggle-shown dropdown admonition" id="typealong-7">
<p class="admonition-title">Example: <code class="docutils literal notranslate"><span class="pre">Compilation</span> <span class="pre">process</span></code></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-9-9-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-9-9-0" name="9-0" role="tab" tabindex="0">Compiling MPI-OpenACC (Fortran)</button><button aria-controls="panel-9-9-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-1" name="9-1" role="tab" tabindex="-1">Compiling MPI-OpenMP (Fortran)</button><button aria-controls="panel-9-9-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-2" name="9-2" role="tab" tabindex="-1">Compiling MPI-OpenMP (C++)</button></div><div aria-labelledby="tab-9-9-0" class="sphinx-tabs-panel" id="panel-9-9-0" name="9-0" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ftn<span class="w"> </span>-hacc<span class="w"> </span>-o<span class="w"> </span>mycode.mpiacc.exe<span class="w"> </span>mycode_mpiacc.f90
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-1" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-1" name="9-1" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ftn<span class="w"> </span>-homp<span class="w"> </span>-o<span class="w"> </span>mycode.mpiomp.exe<span class="w"> </span>mycode_mpiomp.f90
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-2" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-2" name="9-2" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>CC<span class="w"> </span>-fopenmp<span class="w"> </span>-fopenmp-targets<span class="o">=</span>amdgcn-amd-amdhsa<span class="w"> </span>-Xopenmp-target<span class="w"> </span>-march<span class="o">=</span>gfx90a<span class="w"> </span>-o<span class="w"> </span>mycode.mpiomp.exe<span class="w"> </span>mycode_mpiomp.cpp
</pre></div>
</div>
</div></div>
</div>
<p>Here, the flags <cite>hacc</cite> and <cite>homp</cite> enable the OpenACC and OpenMP directives in the hybrid MPI-OpenACC and MPI-OpenMP applications, respectively.</p>
<p><strong>Enabling GPU-aware support</strong></p>
<p>To enable the GPU-aware support in MPICH library, one needs to set the following environment variable before running the application.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export MPICH_GPU_SUPPORT_ENABLED=1
</pre></div>
</div>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading"></a></h3>
<p>In conclusion, we have presented an overview of a GPU-hybrid programming by integrating GPU-directive models, specifically OpenACC and OpenMP APIs, with the MPI library. The approach adopted here allows us to utilise multiple GPU-devices not only within a single node but it extends to distributed nodes. In particular, we have addressed GPU-aware MPI approach, which has the advantage of enabling a direct interaction between an MPI library and a GPU-device memory. In other words, it permits performing MPI operations between a pair of GPUs, thus reducing the computing time caused by the data locality.</p>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<p>We consider an MPI fortran code that solves a 2D-Laplace equation, and which is partially accelerated. The focus of the exercises is to complete the acceleration using either OpenACC or OpenMP API by following these steps.</p>
<div class="admonition-access-exercise-material callout admonition" id="callout-0">
<p class="admonition-title">Access exercise material</p>
<p>Code examples for the exercises below can be accessed in the <cite>content/examples/exercise_multipleGPU</cite> subdirectory of this repository. To access them, you need to clone the repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/gpu-programming.git
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>gpu-programming/content/examples/exercise_multipleGPU
<span class="gp">$ </span>ls
</pre></div>
</div>
</div>
<div class="admonition-exercise-i-set-a-gpu-device exercise important admonition" id="exercise-0">
<p class="admonition-title">Exercise I: Set a GPU device</p>
<ol class="arabic simple">
<li><p>Implement OpenACC/OpenMP functions that enable assigning each MPI rank to a GPU device.</p></li>
</ol>
<p>1.1 Compile and run the code on multiple GPUs.</p>
</div>
<div class="admonition-exercise-ii-apply-traditional-mpi-openacc-openmp exercise important admonition" id="exercise-1">
<p class="admonition-title">Exercise II: Apply traditional MPI-OpenACC/OpenMP</p>
<p>2.1 Incorporate the OpenACC directives <cite>*update host()*</cite> and <cite>*update device()*</cite> before and after calling an MPI function, respectively.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The OpenACC directive <cite>*update host()*</cite> is used to transfer data from GPU to CPU within a data region; while the directive <cite>*update device()*</cite> is used to transfer the data from CPU to GPU.</p>
</div>
<p>2.2 Incorporate the OpenMP directives <cite>*update device() from()*</cite> and <cite>*update device() to()*</cite> before and after calling an MPI function, respectively.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The OpenMP directive <cite>*update device() from()*</cite> is used to transfer data from GPU to CPU within a data region; while the directive <cite>*update device() to()*</cite> is used to transfer the data from CPU to GPU.</p>
</div>
<p>2.3 Compile and run the code on multiple GPUs.</p>
</div>
<div class="admonition-exercise-iii-implement-gpu-aware-support exercise important admonition" id="exercise-2">
<p class="admonition-title">Exercise III: Implement GPU-aware support</p>
<p>3.1 Incorporate the OpenACC directive <cite>*host_data use_device()*</cite> to pass a device pointer to an MPI function.</p>
<p>3.2 Incorporate the OpenMP directive <cite>*data use_device_ptr()*</cite> to pass a device pointer to an MPI function.</p>
<p>3.3 Compile and run the code on multiple GPUs.</p>
</div>
<div class="admonition-exercise-iv-evaluate-the-performance exercise important admonition" id="exercise-3">
<p class="admonition-title">Exercise IV: Evaluate the performance</p>
<ol class="arabic simple">
<li><p>Evaluate the execution time of the accelerated codes in the exercises <strong>II</strong> and <strong>III</strong>, and compare it with that of a pure MPI implementation.</p></li>
</ol>
</div>
</section>
<section id="see-also">
<h3>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://documentation.sigma2.no/code_development/guides/gpuaware_mpi.html">GPU-aware MPI</a>.</p></li>
<li><p><a class="reference external" href="https://www.mpi-forum.org/docs/mpi-4.0/mpi40-report.pdf">MPI documentation</a>.</p></li>
<li><p><a class="reference external" href="https://www.openacc.org/sites/default/files/inline-images/Specification/OpenACC-3.2-final.pdf">OpenACC specification</a>.</p></li>
<li><p><a class="reference external" href="https://www.openmp.org/wp-content/uploads/OpenMP-API-Specification-5-2.pdf">OpenMP specification</a>.</p></li>
<li><p><a class="reference external" href="https://docs.lumi-supercomputer.eu/development/compiling/prgenv/">LUMI documentation</a>.</p></li>
<li><p><a class="reference external" href="https://documentation.sigma2.no/code_development/guides/converting_acc2omp/openacc2openmp.html">OpenACC vs OpenMP offloading</a>.</p></li>
<li><p><a class="reference external" href="https://github.com/HichamAgueny/GPU-course">OpenACC course</a>.</p></li>
</ul>
</section>
</section>
<span id="document-11-gpu-porting"></span><section id="preparing-code-for-gpu-porting">
<span id="gpu-porting"></span><h2>Preparing code for GPU porting<a class="headerlink" href="#preparing-code-for-gpu-porting" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What are the key steps involved in porting code to take advantage of GPU parallel processing capability?</p></li>
<li><p>How can I identify the computationally intensive parts of my code that can benefit from GPU acceleration?</p></li>
<li><p>What are the considerations for refactoring loops to suit the GPU architecture and improve memory access patterns?</p></li>
<li><p>Are there any tools that can translate automatically between different frameworks?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Getting familiarized the steps involved in porting code to GPUs to take advantage of parallel processing capabilities.</p></li>
<li><p>Giving some idea about refactoring loops and modifying operations to suit the GPU architecture and improve memory access patterns.</p></li>
<li><p>Learn to use automatic translation tools to port from CUDA to HIP and from OpenACC to OpenMP</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>30 min teaching</p></li>
<li><p>20 min exercises</p></li>
</ul>
</div>
<section id="porting-from-cpu-to-gpu">
<h3>Porting from CPU to GPU<a class="headerlink" href="#porting-from-cpu-to-gpu" title="Link to this heading"></a></h3>
<p>When porting code to take advantage of the parallel processing capability of GPUs, several steps need to be followed and some additional work is required before writing actual parallel code to be executed on the GPUs:</p>
<ul class="simple">
<li><p><strong>Identify Targeted Parts</strong>: Begin by identifying the parts of the code that contribute significantly to the execution time. These are often computationally intensive sections such as loops or matrix operations. The Pareto principle suggests that roughly 10-20% of the code accounts for 80-90% of the execution time.</p></li>
<li><p><strong>Equivalent GPU Libraries</strong>: If the original code uses CPU libraries like BLAS, FFT, etc, it’s crucial to identify the equivalent GPU libraries. For example, <cite>cuBLAS</cite> or <cite>hipBLAS</cite> can replace CPU-based BLAS libraries. Utilizing GPU-specific libraries ensures efficient GPU utilization.</p></li>
<li><p><strong>Refactor Loops</strong>: When porting loops directly to GPUs, some refactoring is necessary to suit the GPU architecture. This typically involves splitting the loop into multiple steps or modifying operations to exploit the independence between iterations and improve memory access patterns. Each step of the original loop can be mapped to a kernel, executed by multiple GPU threads, with each thread corresponding to an iteration.</p></li>
<li><p><strong>Memory Access Optimization</strong>: Consider the memory access patterns in the code. GPUs perform best when memory access is coalesced and aligned. Minimizing global memory accesses and maximizing utilization of shared memory or registers can significantly enhance performance. Review the code to ensure optimal memory access for GPU execution.</p></li>
</ul>
<section id="discussion">
<h4>Discussion<a class="headerlink" href="#discussion" title="Link to this heading"></a></h4>
<blockquote>
<div><div class="admonition-how-would-this-be-ported-n-soap-100-n-sites-10000-k-max-20-n-sites exercise important admonition" id="exercise-0">
<p class="admonition-title">How would this be ported? (n_soap ≈ 100, n_sites ⩾ 10000, k_max ≈ 20*n_sites )</p>
<blockquote>
<div><p>Inspect the following Fortran code (if you don’t read Fortran: do-loops == for-loops)</p>
<div class="highlight-Fortran notranslate"><div class="highlight"><pre><span></span><span class="n">k2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_sites</span>
<span class="w">  </span><span class="k">do </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_neigh</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">    </span><span class="n">k2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="n">counter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="n">counter2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="k">do </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_max</span>
<span class="w">      </span><span class="k">do </span><span class="n">np</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">n_max</span>
<span class="w">        </span><span class="k">do </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">l_max</span>
<span class="w">          </span><span class="k">if</span><span class="p">(</span><span class="w"> </span><span class="n">skip_soap_component</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">)</span><span class="k">cycle</span>

<span class="k">          </span><span class="n">counter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counter</span><span class="o">+</span><span class="mi">1</span>
<span class="w">          </span><span class="k">do </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">l</span>
<span class="w">            </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">l</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">m</span>
<span class="w">            </span><span class="n">counter2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counter2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="w">            </span><span class="n">multiplicity</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">multiplicity_array</span><span class="p">(</span><span class="n">counter2</span><span class="p">)</span>
<span class="w">            </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">multiplicity</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="w"> </span><span class="n">cnk_rad_der</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">cnk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cnk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">cnk_rad_der</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="p">)</span>
<span class="w">            </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">multiplicity</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="w"> </span><span class="n">cnk_azi_der</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">cnk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cnk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">cnk_azi_der</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="p">)</span>
<span class="w">            </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">multiplicity</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="w"> </span><span class="n">cnk_pol_der</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">cnk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cnk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">cnk_pol_der</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="p">)</span>
<span class="w">          </span><span class="k">end do</span>
<span class="k">        end do</span>
<span class="k">      end do</span>
<span class="k">    end do</span>

<span class="k">    </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dot_product</span><span class="p">(</span><span class="w"> </span><span class="n">soap</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">),</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dot_product</span><span class="p">(</span><span class="w"> </span><span class="n">soap</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">),</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dot_product</span><span class="p">(</span><span class="w"> </span><span class="n">soap</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">),</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>

<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">)</span><span class="k">then</span>
<span class="k">      </span><span class="n">k3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k2</span>
<span class="w">    </span><span class="k">else</span>
<span class="k">      </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">      </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">      </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">      </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">      </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">      </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">    </span><span class="k">end if</span>
<span class="k">  end do</span>
<span class="k">end do</span>
</pre></div>
</div>
</div></blockquote>
<p>Some steps at first glance:</p>
<blockquote>
<div><ul class="simple">
<li><p>the code could (has to) be splitted in 3-4 kernels. Why?</p></li>
<li><p>check if there are any variables that could lead to false dependencies between iterations, like the index <cite>k2</cite></p></li>
<li><p>is it efficient for GPUs to split the work over the index <cite>i</cite>? What about the memory access? Note the arrays are <cite>2D</cite> in Fortran</p></li>
<li><p>is it possible to collapse some loops? Combining nested loops can reduce overhead and improve memory access patterns, leading to better GPU performance.</p></li>
<li><p>what is the best memory access in a GPU? Review memory access patterns in the code. Minimize global memory access by utilizing shared memory or registers where appropriate. Ensure memory access is coalesced and aligned, maximizing GPU memory throughput</p></li>
</ul>
</div></blockquote>
</div>
</div></blockquote>
<div class="dropdown admonition">
<p class="admonition-title">Refactored code!</p>
<ul class="simple">
<li><p>Registers are limited and the larger the kernel use more registers registers resulting in less active threads (small occupancy).</p></li>
<li><p>In order to compute <cite>soap_rad_der(is,k2)</cite> the CUDA thread needs access to all the previous values <cite>soap_rad_der(1:nsoap,k2)</cite>.</p></li>
<li><p>In order to compute <cite>soap_cart_der(1, 1:n_soap, k3)</cite> it is required to have access to all values <cite>(k3+1:k2+n_neigh(i))</cite>.</p></li>
<li><p>Note the indices in the first part. The matrices are transposed for better access patterns.</p></li>
</ul>
<blockquote>
<div><div class="highlight-Fortran notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="c">!omp target teams distribute parallel do private (i)</span>
<span class="w">  </span><span class="k">do </span><span class="n">k2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">k2_max</span>
<span class="w">    </span><span class="n">i</span><span class="o">=</span><span class="n">list_of_i</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span>
<span class="w">    </span><span class="n">counter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="n">counter2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="k">do </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_max</span>
<span class="w">      </span><span class="k">do </span><span class="n">np</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">n_max</span>
<span class="w">        </span><span class="k">do </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">l_max</span>
<span class="w">          </span><span class="k">if</span><span class="p">(</span><span class="w"> </span><span class="n">skip_soap_component</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="k">then</span>
<span class="k">            cycle</span>
<span class="k">          endif</span>
<span class="k">          </span><span class="n">counter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counter</span><span class="o">+</span><span class="mi">1</span>
<span class="w">          </span><span class="k">do </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">l</span>
<span class="w">            </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">l</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">m</span>
<span class="w">            </span><span class="n">counter2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counter2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="w">            </span><span class="n">multiplicity</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">multiplicity_array</span><span class="p">(</span><span class="n">counter2</span><span class="p">)</span>
<span class="w">            </span><span class="n">tsoap_rad_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">counter</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tsoap_rad_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">counter</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">multiplicity</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="w"> </span><span class="n">tcnk_rad_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">tcnk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">np</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tcnk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">tcnk_rad_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">np</span><span class="p">))</span><span class="w"> </span><span class="p">)</span>
<span class="w">            </span><span class="n">tsoap_azi_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">counter</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tsoap_azi_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">counter</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">multiplicity</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="w"> </span><span class="n">tcnk_azi_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">tcnk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">np</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tcnk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">tcnk_azi_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">np</span><span class="p">))</span><span class="w"> </span><span class="p">)</span>
<span class="w">            </span><span class="n">tsoap_pol_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">counter</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tsoap_pol_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">counter</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">multiplicity</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="w"> </span><span class="n">tcnk_pol_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">tcnk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">np</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tcnk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">conjg</span><span class="p">(</span><span class="n">tcnk_pol_der</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">np</span><span class="p">))</span><span class="w"> </span><span class="p">)</span>
<span class="w">          </span><span class="k">end do</span>
<span class="k">        end do</span>
<span class="k">      end do</span>
<span class="k">    end do</span>
<span class="k">  end do</span>

<span class="c">! Before the next part the variables are transposed again to their original layout.</span>

<span class="w"> </span><span class="c">!omp target teams  distribute private(i)</span>
<span class="w"> </span><span class="k">do </span><span class="n">k2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">k2_max</span>
<span class="w">   </span><span class="n">i</span><span class="o">=</span><span class="n">list_of_i</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span>
<span class="w">   </span><span class="n">locdot</span><span class="o">=</span><span class="mf">0.d0</span>

<span class="w">   </span><span class="c">!omp parallel do reduction(+:locdot_rad_der,locdot_azi_der,locdot_pol_der)</span>
<span class="w">   </span><span class="k">do is</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nsoap</span>
<span class="w">     </span><span class="n">locdot_rad_der</span><span class="o">=</span><span class="n">locdot_rad_der</span><span class="o">+</span><span class="n">soap</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">     </span><span class="n">locdot_azi_der</span><span class="o">=</span><span class="n">locdot_azi_der</span><span class="o">+</span><span class="n">soap</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">     </span><span class="n">locdot_pol_der</span><span class="o">=</span><span class="n">locdot_pol_der</span><span class="o">+</span><span class="n">soap</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">   </span><span class="k">enddo</span>
<span class="k">   </span><span class="n">dot_soap_rad_der</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="o">=</span><span class="w"> </span><span class="n">locdot_rad_der</span>
<span class="w">   </span><span class="n">dot_soap_azi_der</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="o">=</span><span class="w"> </span><span class="n">locdot_azi_der</span>
<span class="w">   </span><span class="n">dot_soap_pol_der</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="o">=</span><span class="w"> </span><span class="n">locdot_pol_der</span>
<span class="w"> </span><span class="k">end do</span>

<span class="w"> </span><span class="c">!omp target teams distribute</span>
<span class="w"> </span><span class="k">do </span><span class="n">k2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">k2_max</span>
<span class="w">   </span><span class="n">i</span><span class="o">=</span><span class="n">list_of_i</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span>

<span class="w">   </span><span class="c">!omp parallel do</span>
<span class="w">   </span><span class="k">do is</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nsoap</span>
<span class="w">     </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w">   </span><span class="n">soap</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dot_soap_rad_der</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span>
<span class="w">     </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w">   </span><span class="n">soap</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dot_soap_azi_der</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span>
<span class="w">     </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w">   </span><span class="n">soap</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt_dot_p</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dot_soap_pol_der</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span>
<span class="w">   </span><span class="k">end do</span>
<span class="k"> end do</span>

<span class="w"> </span><span class="c">!omp teams distribute private(k3)</span>
<span class="w"> </span><span class="k">do </span><span class="n">k2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">k2_max</span>
<span class="w">   </span><span class="n">k3</span><span class="o">=</span><span class="n">list_k2k3</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span>

<span class="w">   </span><span class="c">!omp parallel do private (is)</span>
<span class="w">   </span><span class="k">do is</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_soap</span>
<span class="w">     </span><span class="k">if</span><span class="p">(</span><span class="w"> </span><span class="n">k3</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="k">then</span>
<span class="k">       </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">       </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="n">n_soap</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">phis</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_azi_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">       </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">dcos</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_rad_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">dsin</span><span class="p">(</span><span class="n">thetas</span><span class="p">(</span><span class="n">k2</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rjs</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">soap_pol_der</span><span class="p">(</span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">     </span><span class="k">end if</span>
<span class="k">   end do</span>
<span class="k"> end do</span>

<span class="w"> </span><span class="c">!omp teams distribute private(k3)</span>
<span class="w"> </span><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_sites</span>
<span class="w">   </span><span class="n">k3</span><span class="o">=</span><span class="n">list_k3</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="w">   </span><span class="c">!omp parallel do private(is, k2)</span>
<span class="w">   </span><span class="k">do is</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_soap</span>
<span class="w">     </span><span class="k">do </span><span class="n">k2</span><span class="o">=</span><span class="n">k3</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">k3</span><span class="o">+</span><span class="n">n_neigh</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="w">       </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">       </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">       </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k3</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">soap_cart_der</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="p">,</span><span class="w"> </span><span class="n">k2</span><span class="p">)</span>
<span class="w">     </span><span class="k">end do</span>
<span class="k">   end do</span>
<span class="k"> end do</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Identify equivalent GPU libraries for CPU-based libraries and utilizing them to ensure efficient GPU utilization.</p></li>
<li><p>Importance of identifying the computationally intensive parts of the code that contribute significantly to the execution time.</p></li>
<li><p>The need to refactor loops to suit the GPU architecture.</p></li>
<li><p>Significance of memory access optimization for efficient GPU execution, including coalesced and aligned memory access patterns.</p></li>
</ul>
</div>
</section>
</section>
<section id="porting-between-different-gpu-frameworks">
<h3>Porting between different GPU frameworks<a class="headerlink" href="#porting-between-different-gpu-frameworks" title="Link to this heading"></a></h3>
<p>You might also find yourself in a situation where you need to port a code from one particular
GPU framework to another. This section gives an overview of different tools that enable converting CUDA and
OpenACC codes to HIP and OpenMP, respectively. This conversion process enables an application to target various
GPU architectures, specifically, NVIDIA and AMD GPUs. Here we focus on
<a class="reference external" href="https://docs.amd.com/en-US/bundle/HIPify-Reference-Guide-v5.1/page/HIPify.html">hipify</a> and
<a class="reference external" href="https://csmd.ornl.gov/project/clacc">clacc</a> tools.
This guide is adapted from the <a class="reference external" href="https://documentation.sigma2.no/code_development/guides/cuda_translating-tools.html">NRIS documentation</a>.</p>
<section id="translating-cuda-to-hip-with-hipify">
<h4>Translating CUDA to HIP with Hipify<a class="headerlink" href="#translating-cuda-to-hip-with-hipify" title="Link to this heading"></a></h4>
<p>In this section, we cover the use of <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> and <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> tools to translate a CUDA code to HIP.</p>
<section id="hipify-perl">
<h5>Hipify-perl<a class="headerlink" href="#hipify-perl" title="Link to this heading"></a></h5>
<p>The <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> tool is a script based on perl that translates CUDA syntax into HIP syntax
(see .e.g. <a class="reference external" href="https://docs.amd.com/en-US/bundle/HIPify-Reference-Guide-v5.1/page/HIPify.html#perl">here</a> for more details).
For instance, in a CUDA code that incorporates the CUDA functions <code class="docutils literal notranslate"><span class="pre">cudaMalloc`</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize</span></code>, the tool will substitute <code class="docutils literal notranslate"><span class="pre">cudaMalloc</span></code> with the HIP function <code class="docutils literal notranslate"><span class="pre">hipMalloc</span></code>. Similarly the CUDA function <code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize</span></code> will be substituted with the HIP function <code class="docutils literal notranslate"><span class="pre">hipDeviceSynchronize</span></code>. We list below the basic steps to run <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> on LUMI-G.</p>
<ul>
<li><p><strong>Step 1</strong>: Generating <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> script</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/5.2.3
<span class="gp">$ </span>hipify-clang<span class="w"> </span>--perl
</pre></div>
</div>
</li>
<li><p><strong>Step 2</strong>: Running the generated <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>hipify-perl<span class="w"> </span>program.cu<span class="w"> </span>&gt;<span class="w"> </span>program.cu.hip
</pre></div>
</div>
</li>
<li><p><strong>Step 3</strong>: Compiling with <code class="docutils literal notranslate"><span class="pre">hipcc</span></code> the generated HIP code</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>hipcc<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a<span class="w"> </span>-o<span class="w"> </span>program.hip.exe<span class="w"> </span>program.cu.hip
</pre></div>
</div>
</li>
</ul>
<p>Despite the simplicity of the use of <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code>, the tool might not be suitable for large applications, as it relies heavily on substituting CUDA strings with HIP strings (e.g. it substitutes <code class="docutils literal notranslate"><span class="pre">*cuda*</span></code> with <code class="docutils literal notranslate"><span class="pre">*hip*</span></code>).
In addition, <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> lacks the ability of <a class="reference external" href="https://docs.amd.com/bundle/HIPify-Reference-Guide-v5.1/page/HIPify.html#perl">distinguishing device/host function calls</a>.
The alternative here is to use the <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> tool as will be described in the next section.</p>
</section>
<section id="hipify-clang">
<h5>Hipify-clang<a class="headerlink" href="#hipify-clang" title="Link to this heading"></a></h5>
<p>As described in the <a class="reference external" href="https://docs.amd.com/en-US/bundle/HIPify-Reference-Guide-v5.1/page/HIPify.html#perl">HIPIFY documentation</a>,
the <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> tool is based on clang for translating CUDA sources into HIP sources.
The tool is more robust for translating CUDA codes compared to the <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> tool.
Furthermore, it facilitates the analysis of the code by providing assistance.</p>
<p>In short, <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> requires <code class="docutils literal notranslate"><span class="pre">LLVM+CLANG</span></code> and <code class="docutils literal notranslate"><span class="pre">CUDA</span></code>. Details about building <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> can be found <a class="reference external" href="https://github.com/ROCm/HIPIFY">here</a>. Note that <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> is available on LUMI-G.
The issue however might be related to the installation of CUDA-toolkit.
To avoid any eventual issues with the installation procedure we opt for CUDA singularity container. Here we present a step-by-step guide for running <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code>:</p>
<ul>
<li><p><strong>Step 1</strong>: Pulling a CUDA singularity container e.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>singularity<span class="w"> </span>pull<span class="w"> </span>docker://nvcr.io/nvidia/cuda:11.4.3-devel-ubuntu20.04
</pre></div>
</div>
</li>
<li><p><strong>Step 2</strong>: Loading a rocm module and launching the CUDA singularity</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>rocm/5.2.3
<span class="gp">$ </span>singularity<span class="w"> </span>shell<span class="w"> </span>-B<span class="w"> </span><span class="nv">$PWD</span>,/opt:/opt<span class="w"> </span>cuda_11.4.0-devel-ubuntu20.04.sif
</pre></div>
</div>
<p>where the current directory <code class="docutils literal notranslate"><span class="pre">$PWD</span></code> in the host is mounted to that of the container, and the directory <code class="docutils literal notranslate"><span class="pre">/opt</span></code> in the host is mounted to the that inside the container.</p>
</li>
<li><p><strong>Step 3</strong>: Setting the environment variable <code class="docutils literal notranslate"><span class="pre">$PATH</span></code>.
In order to run <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> from inside the container, one can set the environment variable <code class="docutils literal notranslate"><span class="pre">$PATH</span></code> that defines the path to look for the binary <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span>/opt/rocm-5.2.3/bin:<span class="nv">$PATH</span>
</pre></div>
</div>
<p>Note that the rocm version we used is <code class="docutils literal notranslate"><span class="pre">rocm-5.2.3</span></code>.</p>
</li>
<li><p><strong>Step 4</strong>: Running <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> from inside the singularity container</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>hipify-clang<span class="w"> </span>program.cu<span class="w"> </span>-o<span class="w"> </span>hip_program.cu.hip<span class="w"> </span>--cuda-path<span class="o">=</span>/usr/local/cuda-11.4<span class="w"> </span>-I<span class="w"> </span>/usr/local/cuda-11.4/include
</pre></div>
</div>
<p>Here the cuda path and the path to the <code class="docutils literal notranslate"><span class="pre">*includes*</span></code> and <code class="docutils literal notranslate"><span class="pre">*defines*</span></code> files should be specified. The CUDA source code and the generated output code are <cite>program.cu</cite> and <cite>hip_program.cu.hip</cite>, respectively.</p>
<p>The syntax for the compilation process of the generated hip code is similar to the one described in the previous section (see the <strong>Step 3</strong> in the hipify-perl section).</p>
</li>
</ul>
<p>Code examples for the <code class="docutils literal notranslate"><span class="pre">Hipify</span></code> exercises can be accessed in the <cite>content/examples/exercise_hipify</cite> subdirectory by cloning this repository:</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/gpu-programming.git
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>gpu-programming/content/examples/exercise_hipify
<span class="gp">$ </span>ls
</pre></div>
</div>
</div></blockquote>
<div class="admonition-exercise-i-translate-an-cuda-code-to-hip-with-hipify-perl exercise important admonition" id="exercise-1">
<p class="admonition-title">Exercise I : Translate an CUDA code to HIP with <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code></p>
<p>1.1 Generate the <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> tool.</p>
<p>1.2 Convert the CUDA code <code class="docutils literal notranslate"><span class="pre">vec_add_cuda.cu</span></code> located in <code class="docutils literal notranslate"><span class="pre">/exercise_hipify/Hipify_perl</span></code> with the <code class="docutils literal notranslate"><span class="pre">Hipify-perl</span></code> tool to HIP.</p>
<p>1.3 Compile the generated HIP code with the <code class="docutils literal notranslate"><span class="pre">hipcc</span></code> compiler wrapper and run it.</p>
</div>
<div class="admonition-exercise-ii-translate-an-cuda-code-to-hip-with-hipify-clang exercise important admonition" id="exercise-2">
<p class="admonition-title">Exercise II : Translate an CUDA code to HIP with <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code></p>
<p>2.1 Convert the CUDA code <code class="docutils literal notranslate"><span class="pre">vec_add_cuda.cu</span></code> located in <code class="docutils literal notranslate"><span class="pre">/exercise_hipify/Hipify_clang</span></code> with the <code class="docutils literal notranslate"><span class="pre">Hipify-clang</span></code> tool to HIP.</p>
<p>2.2 Compile the generated HIP code with the <code class="docutils literal notranslate"><span class="pre">hipcc</span></code> compiler wrapper and run it.</p>
</div>
</section>
</section>
<section id="translating-openacc-to-openmp-with-clacc">
<h4>Translating OpenACC to OpenMP with Clacc<a class="headerlink" href="#translating-openacc-to-openmp-with-clacc" title="Link to this heading"></a></h4>
<p><a class="reference external" href="https://github.com/llvm-doe-org/llvm-project/tree/clacc/main">Clacc</a> is a tool to translate an OpenACC
application to OpenMP offloading with the Clang/LLVM compiler environment.
Note that the tool is specific to OpenACC C, while OpenACC Fortran is already supported on AMD GPU.
As indicated in the <a class="reference external" href="https://github.com/llvm-doe-org/llvm-project/tree/clacc/main">GitHub repository</a> the compiler <code class="docutils literal notranslate"><span class="pre">Clacc</span></code> is the <code class="docutils literal notranslate"><span class="pre">Clang</span></code>’s executable in the subdirectory <code class="docutils literal notranslate"><span class="pre">\bin</span></code> of the <code class="docutils literal notranslate"><span class="pre">\install</span></code> directory as described below.</p>
<p>In the following we present a step-by-step guide for building and using <cite>Clacc</cite>:</p>
<ul>
<li><p><strong>Step 1</strong>: Building and installing <a class="reference external" href="https://github.com/llvm-doe-org/llvm-project/tree/clacc/main">Clacc</a>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>-b<span class="w"> </span>clacc/main<span class="w"> </span>https://github.com/llvm-doe-org/llvm-project.git
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>llvm-project
<span class="gp">$ </span>mkdir<span class="w"> </span>build<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build
<span class="gp">$ </span>cmake<span class="w"> </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span>../install<span class="w">     </span><span class="se">\</span>
<span class="w">   </span>-DCMAKE_BUILD_TYPE<span class="o">=</span>Release<span class="w">            </span><span class="se">\</span>
<span class="w">   </span>-DLLVM_ENABLE_PROJECTS<span class="o">=</span><span class="s2">&quot;clang;lld&quot;</span><span class="w">    </span><span class="se">\</span>
<span class="w">   </span>-DLLVM_ENABLE_RUNTIMES<span class="o">=</span>openmp<span class="w">         </span><span class="se">\</span>
<span class="w">   </span>-DLLVM_TARGETS_TO_BUILD<span class="o">=</span><span class="s2">&quot;host;AMDGPU&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>-DCMAKE_C_COMPILER<span class="o">=</span>gcc<span class="w">                </span><span class="se">\</span>
<span class="w">   </span>-DCMAKE_CXX_COMPILER<span class="o">=</span>g++<span class="w">              </span><span class="se">\</span>
<span class="w">   </span>../llvm
<span class="gp">$ </span>make
<span class="gp">$ </span>make<span class="w"> </span>install
</pre></div>
</div>
</li>
<li><p><strong>Step 2</strong>: Setting up environment variables to be able to work from the <code class="docutils literal notranslate"><span class="pre">/install</span></code> directory, which is the simplest way. We assume that the <code class="docutils literal notranslate"><span class="pre">/install</span></code> directory is located in the path <code class="docutils literal notranslate"><span class="pre">/project/project_xxxxxx/Clacc/llvm-project</span></code>.</p></li>
</ul>
<p>For more advanced usage, which includes for instance modifying <code class="docutils literal notranslate"><span class="pre">Clacc</span></code>, we refer readers to <a class="reference external" href="https://github.com/llvm-doe-org/llvm-project/blob/clacc/main/README.md">“Usage from Build directory”</a></p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span>/project/project_xxxxxx/Clacc/llvm-project/install/bin:<span class="nv">$PATH</span>
<span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/project/project_xxxxxx/Clacc/llvm-project/install/lib:<span class="nv">$LD_LIBRARY_PATH</span>
</pre></div>
</div>
</div></blockquote>
<ul>
<li><p><strong>Step 3</strong>: Source to source conversion of the <cite>openACC_code.c</cite> code to be printed out to the file <cite>openMP_code.c</cite>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>clang<span class="w"> </span>-fopenacc-print<span class="o">=</span>omp<span class="w"> </span>-fopenacc-structured-ref-count-omp<span class="o">=</span>no-ompx-hold<span class="w"> </span>openACC_code.c<span class="w"> </span>&gt;<span class="w"> </span>openMP_code.c
</pre></div>
</div>
<p>Here the flag <code class="docutils literal notranslate"><span class="pre">-fopenacc-structured-ref-count-omp=no-ompx-hold</span></code> is introduced to disable the <code class="docutils literal notranslate"><span class="pre">ompx_hold</span></code> map type modifier, which is used by the OpenACC <code class="docutils literal notranslate"><span class="pre">copy</span></code> clause translation. The <code class="docutils literal notranslate"><span class="pre">ompx_hold</span></code> is an OpenMP extension that might not be supported yet by other compilers.</p>
</li>
<li><p><strong>Step 4</strong> Compiling the code with the <a class="reference external" href="https://docs.lumi-supercomputer.eu/development/compiling/prgenv/">cc compiler wrapper</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">CrayEnv</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">PrgEnv</span><span class="o">-</span><span class="n">cray</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">craype</span><span class="o">-</span><span class="n">accel</span><span class="o">-</span><span class="n">amd</span><span class="o">-</span><span class="n">gfx90a</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">rocm</span><span class="o">/</span><span class="mf">5.2.3</span>

<span class="n">cc</span> <span class="o">-</span><span class="n">fopenmp</span> <span class="o">-</span><span class="n">o</span> <span class="n">executable</span> <span class="n">openMP_code</span><span class="o">.</span><span class="n">c</span>
</pre></div>
</div>
</li>
</ul>
<div class="admonition-access-exercise-material callout admonition" id="callout-0">
<p class="admonition-title">Access exercise material</p>
<p>Code examples for the <code class="docutils literal notranslate"><span class="pre">Clacc</span></code> exercise can be accessed in the <cite>content/examples/exercise_clacc</cite> subdirectory by cloning this repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/gpu-programming.git
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>gpu-programming/content/examples/exercise_clacc
<span class="gp">$ </span>ls
</pre></div>
</div>
</div>
<div class="admonition-exercise-translate-an-openacc-code-to-openmp exercise important admonition" id="exercise-3">
<p class="admonition-title">Exercise : Translate an OpenACC code to OpenMP</p>
<ol class="arabic simple">
<li><p>Convert the OpenACC code <code class="docutils literal notranslate"><span class="pre">openACC_code.c</span></code> located in <code class="docutils literal notranslate"><span class="pre">/exercise_clacc</span></code> with the <code class="docutils literal notranslate"><span class="pre">Clacc</span></code> compiler.</p></li>
<li><p>Compile the generated OpenMP code with the <code class="docutils literal notranslate"><span class="pre">cc</span></code> compiler wrapper and run it.</p></li>
</ol>
</div>
</section>
<section id="translating-cuda-to-sycl-dpc-with-syclomatic">
<h4>Translating CUDA to SYCL/DPC++ with SYCLomatic<a class="headerlink" href="#translating-cuda-to-sycl-dpc-with-syclomatic" title="Link to this heading"></a></h4>
<p>Intel offers a tool for CUDA-to-SYCL code migration, included in the Intel oneAPI Basekit.</p>
<p>It is not installed on LUMI, but the general workflow is similar to the HIPify Clang and also requires an existing CUDA installation:</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>dpct<span class="w"> </span>program.cu
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>dpct_output/
<span class="gp">$ </span>icpx<span class="w"> </span>-fsycl<span class="w"> </span>program.dp.cpp
</pre></div>
</div>
</div></blockquote>
<p>SYCLomatic can migrate larger projects by using <code class="docutils literal notranslate"><span class="pre">-in-root</span></code> and <code class="docutils literal notranslate"><span class="pre">-out-root</span></code> flags to process directories recursively. It can also
use compilation database (supported by CMake and other build systems) to deal with more complex project layouts.</p>
<p>Please note that the code generated by SYCLomatic relies on oneAPI-specific extensions, and thus cannot be directly used with other
SYCL implementations, such as AdaptiveCpp (hipSYCL). The <code class="docutils literal notranslate"><span class="pre">--no-incremental-migration</span></code> flag can be added to <code class="docutils literal notranslate"><span class="pre">dpct</span></code> command to minimize, but not
completely avoid, the use of this compatibility layer. That would require manual effort, since some CUDA concepts cannot be directly
mapped to SYCL.</p>
<p>Additionally, CUDA applications might assume certain hardware behavior, such as 32-wide warps. If the target hardware is different
(e.g., AMD MI250 GPUs, used in LUMI, have warp size of 64), the algorithms might need to be adjusted manually.</p>
</section>
<section id="conclusion">
<h4>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading"></a></h4>
<p>This concludes a brief overview of the usage of available tools to convert CUDA codes to HIP and SYCL, and OpenACC codes to OpenMP offloading. In general the translation process for large applications might be incomplete and thus requires manual modification to complete the porting process. It is however worth noting that the accuracy of the translation process requires that applications are written correctly according to the CUDA and OpenACC syntaxes.</p>
</section>
</section>
<section id="see-also">
<h3>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/ROCm/HIPIFY">Hipify GitHub</a></p></li>
<li><p><a class="reference external" href="https://docs.amd.com/en-US/bundle/HIPify-Reference-Guide-v5.1/page/HIPify.html">HIPify Reference Guide v5.1</a></p></li>
<li><p><a class="reference external" href="https://github.com/olcf-tutorials/simple_HIP_examples/tree/master/vector_addition">HIP example</a></p></li>
<li><p><a class="reference external" href="https://www.admin-magazine.com/HPC/Articles/Porting-CUDA-to-HIP">Porting CUDA to HIP</a></p></li>
<li><p><a class="reference external" href="https://github.com/llvm-doe-org/llvm-project/blob/clacc/main/README.md">Clacc Main repository README</a></p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/articles/technical/syclomatic-new-cuda-to-sycl-code-migration-tool.html">SYCLomatic main mage</a></p></li>
<li><p><a class="reference external" href="https://oneapi-src.github.io/SYCLomatic/get_started/index.html">SYCLomatic documentation</a></p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-1">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Useful tools exist to automatically translate tools from CUDA to HIP and SYCL and from OpenACC to OpenMP, but they may require manual modifications.</p></li>
</ul>
</div>
</section>
</section>
<span id="document-12-recommendations"></span><section id="recommendations">
<h2>Recommendations<a class="headerlink" href="#recommendations" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>Which GPU programming framework is right for me and my project?</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>30 min teaching</p></li>
<li><p>15 min exercises</p></li>
</ul>
</div>
<section id="portability">
<h3>Portability<a class="headerlink" href="#portability" title="Link to this heading"></a></h3>
<p>One of the critical factors when diving into GPU programming is the portability of the chosen framework.
It’s crucial to ensure that the framework you decide to utilize is compatible with the GPU or GPUs you intend
to use. This might seem like a basic step, but it’s essential to avoid unnecessary hardware-software mismatches
that could lead to performance bottlenecks or, worse, a complete failure of the system.</p>
<p>Moreover, if you’re targeting multiple platforms or GPUs, it’s wise to consider using frameworks that support
portable kernel-based models or those that come with high-level language support.
The benefit of these frameworks is that they allow for efficient execution of your code on a variety of
hardware configurations without needing significant alterations.</p>
</section>
<section id="programming-effort">
<h3>Programming Effort<a class="headerlink" href="#programming-effort" title="Link to this heading"></a></h3>
<p>The amount of programming effort required is another factor to consider when choosing a GPU programming framework.
It’s advisable to select a framework that supports the programming language you’re comfortable with.
This consideration will ensure a smoother learning curve and a more efficient development process.</p>
<p>Furthermore, it’s important to check the availability of supportive resources for the chosen framework.
Comprehensive documentation, illustrative examples, and an active community are important when learning
a new framework or troubleshooting issues. They not only minimize the time spent on resolving bugs but also
foster continuous learning and mastery of the framework.</p>
</section>
<section id="performance-requirements">
<h3>Performance Requirements<a class="headerlink" href="#performance-requirements" title="Link to this heading"></a></h3>
<p>Every application or project has unique performance requirements. Therefore, it’s crucial to evaluate the
performance characteristics and optimization capabilities of the potential frameworks before choosing one.
Some frameworks offer extensive optimization features and can automatically tune your code to maximize its
performance. Knowing how well a framework can handle your specific workload requirements can save you
considerable time and resources in the long run.</p>
</section>
<section id="cost-benefit-analysis">
<h3>Cost-benefit Analysis<a class="headerlink" href="#cost-benefit-analysis" title="Link to this heading"></a></h3>
<p>Before finalizing your choice of a GPU programming framework, it’s recommended to perform a cost-benefit analysis.
Consider the specific requirements of your project, like the processing power needed, the complexity of the tasks,
the amount of data to be processed, and the cost associated with the potential framework.
Understanding these factors will help you determine the most suitable and cost-effective framework for your needs.</p>
</section>
<section id="choosing-between-frameworks">
<h3>Choosing Between Frameworks<a class="headerlink" href="#choosing-between-frameworks" title="Link to this heading"></a></h3>
<p>The decision of choosing between different GPU programming frameworks often depends on several factors, including:</p>
<ul class="simple">
<li><p><strong>The specifics of the problem</strong>: Different problems might need different computational capabilities.
Understand your problem thoroughly and evaluate which framework is best equipped to handle it.</p></li>
<li><p><strong>Starting point</strong>: If you’re starting from scratch, you might have more flexibility in choosing your framework than
if you’re building on top of existing code.</p></li>
<li><p><strong>Background knowledge of the programmer</strong>: The familiarity of the programmer with certain programming languages or
frameworks plays a big role in the decision-making process.</p></li>
<li><p><strong>Time investment</strong>: Some frameworks may have a steeper learning curve but offer more extensive capabilities,
while others might be easier to grasp but provide limited features.</p></li>
<li><p><strong>Performance needs</strong>: Some applications require maximum computational power, while others might not.
The performance capabilities of the framework should align with the needs of your project.</p></li>
</ul>
<p>By keeping these considerations in mind, you can make a more informed decision and choose a GPU programming
framework that best suits your needs.</p>
<div class="admonition-question-and-discussion-time discussion important admonition" id="discussion-0">
<p class="admonition-title">Question and discussion time</p>
<ul class="simple">
<li><p>Has your mental model of how GPUs work and how they are programmed changed?</p></li>
<li><p>Do you have a better idea about what framework is right for your code?</p></li>
<li><p>What questions do you have? Ask us anything!</p></li>
</ul>
</div>
</section>
</section>
<span id="document-13-examples"></span><section id="gpu-programming-example-stencil-computation">
<span id="example-heat"></span><h2>GPU programming example: stencil computation<a class="headerlink" href="#gpu-programming-example-stencil-computation" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>How do I compile and run code developed using different programming models and frameworks?</p></li>
<li><p>What can I expect from the GPU-ported programs in terms of performance gains / trends and how do I estimate this?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>To show a self-contained example of parallel computation executed on CPU and GPU using different programming models</p></li>
<li><p>To show differences and consequences of implementing the same algorithm in natural “style” of different models/ frameworks</p></li>
<li><p>To discuss how to assess theoretical and practical performance scaling of GPU codes</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>35 min teaching</p></li>
<li><p>30 min exercises</p></li>
</ul>
</div>
<section id="problem-heat-flow-in-two-dimensional-area">
<h3>Problem: heat flow in two-dimensional area<a class="headerlink" href="#problem-heat-flow-in-two-dimensional-area" title="Link to this heading"></a></h3>
<p>Heat flows in objects according to local temperature differences, as if seeking local equilibrium. The following example defines a rectangular area with two always-warm sides (temperature 70 and 85), two cold sides (temperature 20 and 5) and a cold disk at the center. Because of heat diffusion, temperature of neighboring patches of the area is bound to equalize, changing the overall distribution:</p>
<figure class="align-center" id="id1">
<img alt="_images/heat_montage.png" src="_images/heat_montage.png" />
<figcaption>
<p><span class="caption-text">Over time, the temperature distribution progresses from the initial state toward an end state where upper triangle is warm and lower is cold. The average temperature tends to (70 + 85 + 20 + 5) / 4 = 45.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="technique-stencil-computation">
<h3>Technique: stencil computation<a class="headerlink" href="#technique-stencil-computation" title="Link to this heading"></a></h3>
<p>Heat transfer in the system above is governed by the partial differential equation(s) describing local variation of the temperature field in time and space. That is, the rate of change of the temperature field <span class="math notranslate nohighlight">\(u(x, y, t)\)</span> over two spatial dimensions <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> and time <span class="math notranslate nohighlight">\(t\)</span> (with rate coefficient <span class="math notranslate nohighlight">\(\alpha\)</span>) can be modelled via the equation</p>
<div class="math notranslate nohighlight">
\[\frac{\partial u}{\partial t} = \alpha \left( \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2}\right)\]</div>
<p>The standard way to numerically solve differential equations is to <em>discretize</em> them, i. e. to consider only a set/ grid of specific area points at specific moments in time. That way, partial derivatives <span class="math notranslate nohighlight">\({\partial u}\)</span> are converted into differences between adjacent grid points <span class="math notranslate nohighlight">\(u^{m}(i,j)\)</span>, with <span class="math notranslate nohighlight">\(m, i, j\)</span> denoting time and spatial grid points, respectively. Temperature change in time at a certain point can now be computed from the values of neighboring points at earlier time; the same expression, called <em>stencil</em>, is applied to every point on the grid.</p>
<figure class="align-center" id="id2">
<img alt="_images/stencil.svg" src="_images/stencil.svg" />
<figcaption>
<p><span class="caption-text">This simplified model uses an 8x8 grid of data in light blue in state <span class="math notranslate nohighlight">\(m\)</span>, each location of which has to be updated based on the indicated 5-point stencil in yellow to move to the next time point <span class="math notranslate nohighlight">\(m+1\)</span>.</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<div class="admonition-question-stencil-applications exercise important admonition" id="exercise-0">
<p class="admonition-title">Question: stencil applications</p>
<p>Stencil computation is a common occurrence in solving numerical problems. Have you already encountered it? Can you think of a problem that could be formulated this way in your field / area of expertise?</p>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<p>One obvious choice is <em>convolution</em> operation, used in image processing to apply various filter kernels; in some contexts, “convolution” and “stencil” are used almost interchangeably. Other related use is for averaging/ pooling adjacent values.</p>
</div>
</div>
<section id="technical-considerations">
<h4>Technical considerations<a class="headerlink" href="#technical-considerations" title="Link to this heading"></a></h4>
<p><strong>1. How fast and/ or accurate can the solution be?</strong></p>
<p>Spatial resolution of the temperature field is controlled by the number/ density of the grid points. As the full grid update is required to proceed from one time point to the next, stencil computation is the main target of parallelization (on CPU or GPU).</p>
<p>Moreover, in many cases the chosen time step cannot be arbitrarily large, otherwise the numerical differentiation will fail, and dense/ accurate grids imply small time steps (see inset below), which makes efficient spatial update even more important.</p>
<div class="admonition-optional-stencil-expression-and-time-step-limit solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Optional: stencil expression and time-step limit</p>
<p>Differential equation shown above can be discretized using different schemes. For this example, temperature values at each grid point <span class="math notranslate nohighlight">\(u^{m}(i,j)\)</span> are updated from one time point (<span class="math notranslate nohighlight">\(m\)</span>) to the next (<span class="math notranslate nohighlight">\(m+1\)</span>), using the following expressions:</p>
<div class="math notranslate nohighlight">
\[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}\nabla^2 u  &amp;= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2} \\
    &amp;+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]</div>
<p>and <span class="math notranslate nohighlight">\(\Delta x\)</span>, <span class="math notranslate nohighlight">\(\Delta y\)</span>, <span class="math notranslate nohighlight">\(\Delta t\)</span> are step sizes in space and time, respectively.</p>
<p>Time-update schemes often have a limit on the maximum allowed time step <span class="math notranslate nohighlight">\(\Delta t\)</span>. For the current scheme, it is equal to</p>
<div class="math notranslate nohighlight">
\[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 + (\Delta y)^2)}\]</div>
</div>
<p><strong>2. What to do with area boundaries?</strong></p>
<p>Naturally, stencil expression can’t be applied directly to the outermost grid points that have no outer neighbors. This can be solved by either changing the expression for those points or by adding an additional layer of grid that is used in computing update, but not updated itself – points of fixed temperature for the sides are being used in this example.</p>
<p><strong>3. How could the algorithm be optimized further?</strong></p>
<p>In <a class="reference external" href="https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations">an earlier episode</a>, importance of efficient memory access was already stressed. In the following examples, each grid point (and its neighbors) is treated mostly independently; however, this also means that for 5-point stencil each value of the grid point may be read up to 5 times from memory (even if it’s the fast GPU memory). By rearranging the order of mathematical operations, it may be possible to reuse these values in a more efficient way.</p>
<p>Another point to note is that even if the solution is propagated in small time steps, not every step might actually be needed for output. Once some <em>local</em> region of the field is updated, mathematically nothing prevents it from being updated for the second time step – even if the rest of the field is still being recalculated – as long as <span class="math notranslate nohighlight">\(t = m-1\)</span> values for the region boundary are there when needed. (Of course, this is more complicated to implement and would only give benefits in certain cases.)</p>
<div class="admonition-poll-which-programming-model-framework-are-you-most-interested-in-today exercise important admonition" id="exercise-1">
<p class="admonition-title">Poll: which programming model/ framework are you most interested in today?</p>
<ul class="simple">
<li><p>OpenMP offloading (C++)</p></li>
<li><p>SYCL (C++)</p></li>
<li><p><em>Python</em> (<code class="docutils literal notranslate"><span class="pre">numba</span></code>/CUDA)</p></li>
<li><p>Julia</p></li>
</ul>
</div>
<p>The following table will aid you in navigating the rest of this section:</p>
<div class="admonition-episode-guide admonition">
<p class="admonition-title">Episode guide</p>
<ul class="simple">
<li><p><a class="reference external" href="https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c">Sequential and OpenMP-threaded code</a> in C++, including compilation/ running instructions</p></li>
<li><p><a class="reference external" href="https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps">Naive GPU parallelization</a>, including SYCL compilation instructions</p></li>
<li><p><a class="reference external" href="https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement">GPU code with device data management</a> (OpenMP, SYCL)</p></li>
<li><p><a class="reference external" href="https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration">Python implementation</a>, including running instructions on <a class="reference external" href="https://colab.research.google.com/">Google Colab</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration">Julia implementation</a>, including running instructions</p></li>
</ul>
</div>
</section>
</section>
<section id="sequential-and-thread-parallel-program-in-c">
<h3>Sequential and thread-parallel program in C++<a class="headerlink" href="#sequential-and-thread-parallel-program-in-c" title="Link to this heading"></a></h3>
<div class="admonition-trying-out-code-examples callout admonition" id="callout-0">
<p class="admonition-title">Trying out code examples</p>
<p>Source files of the examples presented for the rest of this episode are available in the <a class="reference external" href="https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/">content/examples/stencil/</a> directory.
To download them to your preferred directory on the cluster (f.e. <code class="docutils literal notranslate"><span class="pre">/scratch/project_&lt;#&gt;/&lt;your_folder&gt;/</span></code>), you can use Git:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/gpu-programming.git
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>gpu-programming/content/examples/stencil/
<span class="gp">$ </span>ls
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Don’t forget to <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">pull</span></code> for the latest updates if you already have the content from the first day of the workshop!</p>
</div>
</div>
<p>If we assume the grid point values to be truly independent <em>for a single time step</em>, stencil application procedure may be straightforwardly written as a loop over the grid points, as shown below in tab “Stencil update”. (General structure of the program and the default parameter values for the problem model are also provided for reference.) CPU-thread parallelism can then be enabled by a single OpenMP <code class="docutils literal notranslate"><span class="pre">#pragma</span></code>:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Stencil update</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Main function</button><button aria-controls="panel-0-0-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-2" name="0-2" role="tab" tabindex="-1">Default params</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// (c) 2023 ENCCS, CSC and the contributors</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;heat.h&quot;</span>

<span class="c1">// Update the temperature values using five-point stencil</span>
<span class="c1">// Arguments:</span>
<span class="c1">//   curr: current temperature values</span>
<span class="c1">//   prev: temperature values from previous time step</span>
<span class="c1">//   a: diffusivity</span>
<span class="c1">//   dt: time step</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">evolve</span><span class="p">(</span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="c1">// Help the compiler avoid being confused by the structs</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">currdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">prevdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">nx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">ny</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Determine the temperature field at next time step</span>
<span class="w">  </span><span class="c1">// As we have fixed boundary conditions, the outermost gridpoints</span>
<span class="w">  </span><span class="c1">// are not updated.</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Use OpenMP threads for parallel update of grid values</span>
<span class="hll"><span class="w">  </span><span class="cp">#pragma omp parallel for</span>
</span><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">ind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">ip</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">im</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">jp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">jm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="n">currdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="o">*</span><span class="n">dt</span><span class="o">*</span>
<span class="w">	    </span><span class="p">((</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ip</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">im</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">+</span>
<span class="w">	     </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">jp</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">jm</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dy2</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Main routine for heat equation solver in 2D.</span>
<span class="c1">// (c) 2023 ENCCS, CSC and the contributors</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdio&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;omp.h&gt;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;heat.h&quot;</span>

<span class="kt">double</span><span class="w"> </span><span class="nf">start_time</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">omp_get_wtime</span><span class="p">();</span><span class="w"> </span><span class="p">}</span>
<span class="kt">double</span><span class="w"> </span><span class="nf">stop_time</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">omp_get_wtime</span><span class="p">();</span><span class="w"> </span><span class="p">}</span>


<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Set up the solver</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">nsteps</span><span class="p">;</span>
<span class="w">    </span><span class="n">field</span><span class="w"> </span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="n">previous</span><span class="p">;</span>
<span class="w">    </span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">previous</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nsteps</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Output the initial field and its temperature</span>
<span class="w">    </span><span class="n">field_write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">average_temp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">field_average</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Average temperature, start: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">average_temp</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Set diffusivity constant</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// Compute the largest stable time step</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">current</span><span class="p">.</span><span class="n">dx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">current</span><span class="p">.</span><span class="n">dx</span><span class="p">;</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">current</span><span class="p">.</span><span class="n">dy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">current</span><span class="p">.</span><span class="n">dy</span><span class="p">;</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">dt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">dx2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dy2</span><span class="p">));</span>
<span class="w">    </span><span class="c1">// Set output interval</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">output_interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1500</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Start timer</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">start_clock</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">start_time</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// Time evolution</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">nsteps</span><span class="p">;</span><span class="w"> </span><span class="n">iter</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="hll"><span class="w">        </span><span class="n">evolve</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">previous</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">);</span>
</span><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">iter</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">output_interval</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">field_write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="n">iter</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="c1">// Swap current and previous fields for next iteration step</span>
<span class="w">        </span><span class="n">field_swap</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">previous</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// Stop timer</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">stop_clock</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_time</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Output the final field and its temperature</span>
<span class="w">    </span><span class="n">average_temp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">field_average</span><span class="p">(</span><span class="o">&amp;</span><span class="n">previous</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Average temperature at end: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">average_temp</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// Compare temperature for reference</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">argc</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Control temperature at end: 59.281239</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">field_write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">previous</span><span class="p">,</span><span class="w"> </span><span class="n">nsteps</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Determine the computation time used for all the iterations</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Iterations took %.3f seconds.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">stop_clock</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_clock</span><span class="p">));</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-2" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-2" name="0-2" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Datatype for temperature field</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">field</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// nx and ny are the dimensions of the field. The array data</span>
<span class="w">    </span><span class="c1">// contains also ghost layers, so it will have dimensions nx+2 x ny+2</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// Size of the grid cells</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">dx</span><span class="p">;</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">dy</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// The temperature values in the 2D grid</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>
<span class="p">};</span>

<span class="c1">// CONSTANTS</span>
<span class="c1">// Fixed grid spacing</span>
<span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">DX</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.01</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">DY</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.01</span><span class="p">;</span>
<span class="c1">// Default temperatures</span>
<span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">T_DISC</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">5.0</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">T_AREA</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">65.0</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">T_UPPER</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">85.0</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">T_LOWER</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">5.0</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">T_LEFT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">20.0</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">T_RIGHT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">70.0</span><span class="p">;</span>
<span class="c1">// Default problem size</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">ROWS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2000</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">COLS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2000</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">NSTEPS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">500</span><span class="p">;</span>
</pre></div>
</div>
</div></div>
<div class="admonition-optional-compiling-the-executables solution important dropdown admonition" id="solution-2">
<p class="admonition-title">Optional: compiling the executables</p>
<blockquote>
<div><p>To compile executable files for the OpenMP-based variants, follow the instructions below:</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">salloc -A project_465002387 -p small-g -N 1 -c 8 -n 1 --gpus-per-node=1 -t 1:00:00</span>

<span class="go">module load LUMI/24.03</span>
<span class="go">module load partition/G</span>
<span class="go">module load rocm/6.0.3</span>
<span class="go">module load PrgEnv-cray/8.5.0</span>

<span class="go">cd base/</span>
<span class="go">make all</span>
</pre></div>
</div>
<p>Afterwards login into a compute node and test the executables (or just <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">&lt;executable&gt;</span></code> directly):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>--pty<span class="w"> </span>bash

<span class="gp">$ </span>./stencil
<span class="gp">$ </span>./stencil_off
<span class="gp">$ </span>./stencil_data

<span class="gp">$ </span><span class="nb">exit</span>
</pre></div>
</div>
<p>If everything works well, the output should look similar to this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>./stencil
<span class="go">Average temperature, start: 59.763305</span>
<span class="go">Average temperature at end: 59.281239</span>
<span class="go">Control temperature at end: 59.281239</span>
<span class="go">Iterations took 0.566 seconds.</span>
<span class="gp">$ </span>./stencil_off
<span class="go">Average temperature, start: 59.763305</span>
<span class="go">Average temperature at end: 59.281239</span>
<span class="go">Control temperature at end: 59.281239</span>
<span class="go">Iterations took 3.792 seconds.</span>
<span class="gp">$ </span>./stencil_data
<span class="go">Average temperature, start: 59.763305</span>
<span class="go">Average temperature at end: 59.281239</span>
<span class="go">Control temperature at end: 59.281239</span>
<span class="go">Iterations took 1.211 seconds.</span>
<span class="gp">$</span>
</pre></div>
</div>
</div>
<section id="cpu-parallelization-timings">
<h4>CPU parallelization: timings<a class="headerlink" href="#cpu-parallelization-timings" title="Link to this heading"></a></h4>
<p>(<strong>NOTE</strong>: for thread-parallel runs it is necessary to request multiple CPU cores. In LUMI-G partitions, this can be done by asking for multiple GPUs; an alternative is to use -C partitions.)</p>
<p>For later comparison, some benchmarks of the OpenMP thread-parallel implementation are provided below:</p>
<table class="docutils align-default" id="id3">
<caption><span class="caption-text">Run times of OpenMP-enabled executable, s</span><a class="headerlink" href="#id3" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 33.3%" />
<col style="width: 33.3%" />
<col style="width: 33.3%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Job size</p></th>
<th class="head"><p>1 CPU core</p></th>
<th class="head"><p>32 CPU cores</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>S:2000 T:500</p></td>
<td><p>1.402</p></td>
<td><p>0.064</p></td>
</tr>
<tr class="row-odd"><td><p>S:2000 T:5000</p></td>
<td><p>13.895</p></td>
<td><p>0.538</p></td>
</tr>
<tr class="row-even"><td><p>S:2000 T:10000</p></td>
<td><p>27.753</p></td>
<td><p>1.071</p></td>
</tr>
<tr class="row-odd"><td><p>S:4000 T:500</p></td>
<td><p>5.727</p></td>
<td><p>0.633</p></td>
</tr>
<tr class="row-even"><td><p>S:8000 T:500</p></td>
<td><p>24.130</p></td>
<td><p>16.616</p></td>
</tr>
</tbody>
</table>
<p>A closer look reveals that the computation time scales very nicely with increasing <strong>time steps</strong>:</p>
<figure class="align-center">
<img alt="_images/omp-cpu-scaling-step.png" src="_images/omp-cpu-scaling-step.png" />
</figure>
<p>However, for larger <strong>grid sizes</strong> the parallelization becomes inefficient – as the individual chunks of the grid get too large to fit into CPU cache, threads become bound by the speed of RAM reads/writes:</p>
<figure class="align-center">
<img alt="_images/omp-cpu-scaling-grid.png" src="_images/omp-cpu-scaling-grid.png" />
</figure>
<div class="admonition-discussion-heat-flow-computation-scaling exercise important admonition" id="exercise-2">
<p class="admonition-title">Discussion: heat flow computation scaling</p>
<ol class="arabic simple">
<li><p>How is heat flow computation <strong>expected</strong> to scale with respect to the number of time steps?</p>
<ol class="loweralpha simple">
<li><p>Linearly</p></li>
<li><p>Quadratically</p></li>
<li><p>Exponentially</p></li>
</ol>
</li>
<li><p>How is stencil application (grid update) <strong>expected</strong> to scale with respect to the size of the grid side?</p>
<ol class="loweralpha simple">
<li><p>Linearly</p></li>
<li><p>Quadratically</p></li>
<li><p>Exponentially</p></li>
</ol>
</li>
<li><p>(Optional) Do you expect GPU-accelerated computations to follow the above-mentioned trends? Why/ why not?</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-3">
<p class="admonition-title">Solution</p>
<ol class="arabic simple">
<li><p>The answer is a: since each time-step follows the previous one and involves a similar number of operations, then the update time per step will be more or less constant.</p></li>
<li><p>The answer is b: since stencil application is independent for every grid point, the update time will be proportional to the number of points, i.e. side * side.</p></li>
</ol>
</div>
</div>
</section>
</section>
<section id="gpu-parallelization-first-steps">
<h3>GPU parallelization: first steps<a class="headerlink" href="#gpu-parallelization-first-steps" title="Link to this heading"></a></h3>
<p>Let’s apply several techniques presented in previous episodes to make stencil update run on GPU.</p>
<p>OpenMP (or OpenACC) offloading requires to define a region to be executed in parallel as well as data that shall be copied over/ used in GPU memory.
Similarly, SYCL programming model offers convenient ways to define execution kernels, as well as context to run them in (called queue).</p>
<p>Changes of stencil update code for OpenMP and SYCL are shown in the tabs below:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">OpenMP (naive)</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">SYCL (naive)</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// (c) 2023 ENCCS, CSC and the contributors</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;heat.h&quot;</span>

<span class="c1">// Update the temperature values using five-point stencil</span>
<span class="c1">// Arguments:</span>
<span class="c1">//   curr: current temperature values</span>
<span class="c1">//   prev: temperature values from previous time step</span>
<span class="c1">//   a: diffusivity</span>
<span class="c1">//   dt: time step</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">evolve</span><span class="p">(</span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="c1">// Help the compiler avoid being confused by the structs</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">currdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">prevdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">nx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">ny</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Determine the temperature field at next time step</span>
<span class="w">  </span><span class="c1">// As we have fixed boundary conditions, the outermost gridpoints</span>
<span class="w">  </span><span class="c1">// are not updated.</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="p">;</span>
<span class="w">  </span>
<span class="w">  </span><span class="c1">// Offload value update to GPU target (fallback to CPU is possible)</span>
<span class="hll"><span class="w">  </span><span class="cp">#pragma omp target teams distribute parallel for \</span>
</span><span class="hll"><span class="cp">  map(currdata[0:(nx+2)*(ny+2)],prevdata[0:(nx+2)*(ny+2)])</span>
</span><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">ind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">ip</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">im</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">jp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">jm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="n">currdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="o">*</span><span class="n">dt</span><span class="o">*</span>
<span class="w">	    </span><span class="p">((</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ip</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">im</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">+</span>
<span class="w">	     </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">jp</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">jm</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dy2</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// (c) 2023 ENCCS, CSC and the contributors</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;heat.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="c1">// Update the temperature values using five-point stencil</span>
<span class="c1">// Arguments:</span>
<span class="c1">//   queue: SYCL queue</span>
<span class="c1">//   curr: current temperature values</span>
<span class="c1">//   prev: temperature values from previous time step</span>
<span class="c1">//   a: diffusivity</span>
<span class="c1">//   dt: time step</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">evolve</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Help the compiler avoid being confused by the structs</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">nx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">ny</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Determine the temperature field at next time step</span>
<span class="w">  </span><span class="c1">// As we have fixed boundary conditions, the outermost gridpoints</span>
<span class="w">  </span><span class="c1">// are not updated.</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="p">;</span>

<span class="hll"><span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">currdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">Q</span><span class="p">);</span>
</span><span class="hll"><span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">prevdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">Q</span><span class="p">);</span>
</span><span class="hll"><span class="w">  </span><span class="n">Q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">curr</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">currdata</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
</span><span class="hll"><span class="w">  </span><span class="n">Q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">prevdata</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
</span>
<span class="hll"><span class="w">  </span><span class="n">Q</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">ny</span><span class="p">),</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">id</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">id</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">id</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ip</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">im</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">jp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">jm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">currdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="o">*</span><span class="n">dt</span><span class="o">*</span>
<span class="w">      </span><span class="p">((</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ip</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">im</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">+</span>
<span class="w">       </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">jp</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">jm</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dy2</span><span class="p">);</span>
<span class="w">  </span><span class="p">});</span>

<span class="hll"><span class="w">  </span><span class="n">Q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">currdata</span><span class="p">,</span><span class="w"> </span><span class="n">curr</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">size</span><span class="p">).</span><span class="n">wait</span><span class="p">();</span>
</span><span class="hll"><span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">currdata</span><span class="p">,</span><span class="w"> </span><span class="n">Q</span><span class="p">);</span>
</span><span class="hll"><span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">prevdata</span><span class="p">,</span><span class="w"> </span><span class="n">Q</span><span class="p">);</span>
</span><span class="p">}</span>
</pre></div>
</div>
</div></div>
<div class="admonition-loading-sycl-modules-on-lumi callout admonition" id="callout-1">
<p class="admonition-title">Loading SYCL modules on LUMI</p>
<p>As SYCL is placed on top of ROCm/HIP (or CUDA) software stack, running SYCL executables may require respective modules to be loaded. On current nodes, it can be done as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>salloc<span class="w"> </span>-A<span class="w"> </span>project_465002387<span class="w"> </span>-p<span class="w"> </span>small-g<span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>-c<span class="w"> </span><span class="m">8</span><span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>-t<span class="w"> </span><span class="m">1</span>:00:00

<span class="go">module load LUMI/24.03</span>
<span class="go">module load partition/G</span>
<span class="go">module load rocm/6.0.3</span>
<span class="go">module use  /appl/local/csc/modulefiles</span>
<span class="go">module load acpp/24.06.0</span>
</pre></div>
</div>
</div>
<div class="admonition-optional-compiling-the-sycl-executables solution important dropdown admonition" id="solution-4">
<p class="admonition-title">Optional: compiling the SYCL executables</p>
<p>As previously, you are welcome to generate your own executables:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>../sycl/
<span class="gp gp-VirtualEnv">(give the following lines some time, probably a couple of min)</span>
<span class="gp">$ </span>acpp<span class="w"> </span>-O2<span class="w"> </span>-o<span class="w"> </span>stencil_naive<span class="w"> </span>core-naive.cpp<span class="w"> </span>io.cpp<span class="w"> </span>main-naive.cpp<span class="w"> </span>pngwriter.c<span class="w"> </span>setup.cpp<span class="w"> </span>utilities.cpp
<span class="gp">$ </span>acpp<span class="w"> </span>-O2<span class="w"> </span>-o<span class="w"> </span>stencil<span class="w"> </span>core.cpp<span class="w"> </span>io.cpp<span class="w"> </span>main.cpp<span class="w"> </span>pngwriter.c<span class="w"> </span>setup.cpp<span class="w"> </span>utilities.cpp

<span class="gp">$ </span>srun<span class="w"> </span>stencil_naive
<span class="gp">$ </span>srun<span class="w"> </span>stencil
</pre></div>
</div>
<p>If everything works well, the output should look similar to this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>stencil_naive
<span class="go">Average temperature, start: 59.763305</span>
<span class="go">Average temperature at end: 59.281239</span>
<span class="go">Control temperature at end: 59.281239</span>
<span class="go">Iterations took 2.086 seconds.</span>
<span class="gp">$ </span>srun<span class="w"> </span>stencil
<span class="go">Average temperature, start: 59.763305</span>
<span class="go">Average temperature at end: 59.281239</span>
<span class="go">Control temperature at end: 59.281239</span>
<span class="go">Iterations took 0.052 seconds.</span>
</pre></div>
</div>
</div>
<div class="admonition-exercise-naive-gpu-ports exercise important admonition" id="exercise-3">
<p class="admonition-title">Exercise: naive GPU ports</p>
<p>Test your compiled executables <code class="docutils literal notranslate"><span class="pre">base/stencil</span></code>, <code class="docutils literal notranslate"><span class="pre">base/stencil_off</span></code> and <code class="docutils literal notranslate"><span class="pre">sycl/stencil_naive</span></code>. Try changing problem size parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">stencil_naive</span> <span class="pre">2000</span> <span class="pre">2000</span> <span class="pre">5000</span></code></p></li>
</ul>
<p>Things to look for:</p>
<ul class="simple">
<li><p>How computation times change?</p></li>
<li><p>Do the results align to your expectations?</p></li>
</ul>
<div class="admonition-solution solution important dropdown admonition" id="solution-5">
<p class="admonition-title">Solution</p>
<p>You might notice that the GPU-“ported” versions actually run slower than the single-CPU-core version! In fact, the scaling behavior of all three variants is similar and expected, which is a good sign; only the “computation unit cost” is different. You can compare benchmark summaries in the tabs below:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">Sequential</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">OpenMP (naive)</button><button aria-controls="panel-2-2-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-2" name="2-2" role="tab" tabindex="-1">SYCL (naive)</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><figure class="align-center">
<img alt="_images/cpu-seq-scaling.png" src="_images/cpu-seq-scaling.png" />
</figure>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><figure class="align-center">
<img alt="_images/omp-gpu-naive-scaling.png" src="_images/omp-gpu-naive-scaling.png" />
</figure>
</div><div aria-labelledby="tab-2-2-2" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-2" name="2-2" role="tabpanel" tabindex="0"><figure class="align-center">
<img alt="_images/omp-sycl-naive-scaling-new.png" src="_images/omp-sycl-naive-scaling-new.png" />
</figure>
</div></div>
</div>
</div>
</section>
<section id="gpu-parallelization-data-movement">
<h3>GPU parallelization: data movement<a class="headerlink" href="#gpu-parallelization-data-movement" title="Link to this heading"></a></h3>
<p>Why the porting approach above seems to be quite inefficient?</p>
<p>On each step, we:</p>
<ul class="simple">
<li><p>re-allocate GPU memory,</p></li>
<li><p>copy the data from CPU to GPU,</p></li>
<li><p>perform the computation,</p></li>
<li><p>then copy the data back.</p></li>
</ul>
<p>But overhead can be reduced by taking care to minimize data transfers between <em>host</em> and <em>device</em> memory:</p>
<ul class="simple">
<li><p>allocate GPU memory once at the start of the program,</p></li>
<li><p>only copy the data from GPU to CPU when we need it,</p></li>
<li><p>swap the GPU buffers between timesteps, like we do with CPU buffers. (OpenMP does this automatically.)</p></li>
</ul>
<p>Changes of stencil update code as well as the main program are shown in tabs below.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">OpenMP</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1">SYCL</button><button aria-controls="panel-3-3-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-2" name="3-2" role="tab" tabindex="-1">Python</button><button aria-controls="panel-3-3-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-3" name="3-3" role="tab" tabindex="-1">main() (SYCL)</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// (c) 2023 ENCCS, CSC and the contributors</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;heat.h&quot;</span>

<span class="c1">// Update the temperature values using five-point stencil</span>
<span class="c1">// Arguments:</span>
<span class="c1">//   curr: current temperature values</span>
<span class="c1">//   prev: temperature values from previous time step</span>
<span class="c1">//   a: diffusivity</span>
<span class="c1">//   dt: time step</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">evolve</span><span class="p">(</span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="c1">// Help the compiler avoid being confused by the structs</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">currdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">prevdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">nx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">ny</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Determine the temperature field at next time step</span>
<span class="w">  </span><span class="c1">// As we have fixed boundary conditions, the outermost gridpoints</span>
<span class="w">  </span><span class="c1">// are not updated.</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="p">;</span>
<span class="w">  </span>
<span class="w">  </span><span class="c1">// Offload value update to GPU target (fallback to CPU is possible)</span>
<span class="hll"><span class="w">  </span><span class="cp">#pragma omp target teams distribute parallel for</span>
</span><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">ind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">ip</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">im</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">jp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="kt">int</span><span class="w"> </span><span class="n">jm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="n">currdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="o">*</span><span class="n">dt</span><span class="o">*</span>
<span class="w">	    </span><span class="p">((</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ip</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">im</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">+</span>
<span class="w">	     </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">jp</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">jm</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dy2</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="hll"><span class="c1">// Start a data region and copy temperature fields to the device</span>
</span><span class="hll"><span class="kt">void</span><span class="w"> </span><span class="nf">enter_data</span><span class="p">(</span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">prev</span><span class="p">)</span>
</span><span class="hll"><span class="p">{</span>
</span><span class="hll"><span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">currdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
</span><span class="hll"><span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">prevdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
</span><span class="hll"><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">nx</span><span class="p">;</span>
</span><span class="hll"><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">ny</span><span class="p">;</span>
</span><span class="hll">
</span><span class="hll"><span class="w">  </span><span class="c1">// adding data mapping here</span>
</span><span class="hll"><span class="w">  </span><span class="cp">#pragma omp target enter data \</span>
</span><span class="hll"><span class="cp">  map(to: currdata[0:(nx+2)*(ny+2)], prevdata[0:(nx+2)*(ny+2)])</span>
</span><span class="hll"><span class="p">}</span>
</span><span class="hll">
</span><span class="hll"><span class="c1">// End a data region and copy temperature fields back to the host</span>
</span><span class="hll"><span class="kt">void</span><span class="w"> </span><span class="nf">exit_data</span><span class="p">(</span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">prev</span><span class="p">)</span>
</span><span class="hll"><span class="p">{</span>
</span><span class="hll"><span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">currdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
</span><span class="hll"><span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">prevdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
</span><span class="hll"><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">nx</span><span class="p">;</span>
</span><span class="hll"><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">ny</span><span class="p">;</span>
</span><span class="hll">
</span><span class="hll"><span class="w">  </span><span class="c1">// adding data mapping here</span>
</span><span class="hll"><span class="w">  </span><span class="cp">#pragma omp target exit data \</span>
</span><span class="hll"><span class="cp">  map(from: currdata[0:(nx+2)*(ny+2)], prevdata[0:(nx+2)*(ny+2)])</span>
</span><span class="hll"><span class="p">}</span>
</span><span class="hll">
</span><span class="hll"><span class="c1">// Copy a temperature field from the device to the host</span>
</span><span class="hll"><span class="kt">void</span><span class="w"> </span><span class="nf">update_host</span><span class="p">(</span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">heat</span><span class="p">)</span>
</span><span class="hll"><span class="p">{</span>
</span><span class="hll"><span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">heat</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
</span><span class="hll"><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">heat</span><span class="o">-&gt;</span><span class="n">nx</span><span class="p">;</span>
</span><span class="hll"><span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">heat</span><span class="o">-&gt;</span><span class="n">ny</span><span class="p">;</span>
</span><span class="hll">
</span><span class="hll"><span class="w">  </span><span class="c1">// adding data mapping here</span>
</span><span class="hll"><span class="w">  </span><span class="cp">#pragma omp target update from(data[0:(nx+2)*(ny+2)])</span>
</span><span class="hll"><span class="p">}</span>
</span></pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// (c) 2023 ENCCS, CSC and the contributors</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;heat.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="c1">// Update the temperature values using five-point stencil</span>
<span class="c1">// Arguments:</span>
<span class="c1">//   queue: SYCL queue</span>
<span class="c1">//   currdata: current temperature values (device pointer)</span>
<span class="c1">//   prevdata: temperature values from previous time step (device pointer)</span>
<span class="c1">//   prev: description of the grid parameters</span>
<span class="c1">//   a: diffusivity</span>
<span class="c1">//   dt: time step</span>
<span class="hll"><span class="kt">void</span><span class="w"> </span><span class="nf">evolve</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="o">*</span><span class="w"> </span><span class="n">currdata</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="o">*</span><span class="w"> </span><span class="n">prevdata</span><span class="p">,</span>
</span><span class="hll"><span class="w">            </span><span class="k">const</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
</span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">nx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">ny</span><span class="p">;</span>
<span class="w">  </span>
<span class="w">  </span><span class="c1">// Determine the temperature field at next time step</span>
<span class="w">  </span><span class="c1">// As we have fixed boundary conditions, the outermost gridpoints</span>
<span class="w">  </span><span class="c1">// are not updated.</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dx</span><span class="p">;</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">dy</span><span class="p">;</span>

<span class="hll"><span class="w">  </span><span class="n">Q</span><span class="p">.</span><span class="n">parallel_for</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">ny</span><span class="p">),</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">id</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">id</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">id</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ip</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">im</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">jp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">jm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">currdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="o">*</span><span class="n">dt</span><span class="o">*</span>
<span class="w">      </span><span class="p">((</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ip</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">im</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">+</span>
<span class="w">       </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">jp</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="n">prevdata</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">jm</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dy2</span><span class="p">);</span>
<span class="w">  </span><span class="p">});</span>
<span class="p">}</span>

<span class="hll"><span class="kt">void</span><span class="w"> </span><span class="nf">copy_to_buffer</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="o">*</span><span class="w"> </span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">field</span><span class="o">*</span><span class="w"> </span><span class="n">f</span><span class="p">)</span>
</span><span class="hll"><span class="p">{</span>
</span><span class="hll"><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">f</span><span class="o">-&gt;</span><span class="n">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">f</span><span class="o">-&gt;</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">);</span>
</span><span class="hll"><span class="w">    </span><span class="n">Q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">f</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
</span><span class="hll"><span class="p">}</span>
</span><span class="hll">
</span><span class="hll"><span class="kt">void</span><span class="w"> </span><span class="nf">copy_from_buffer</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="o">*</span><span class="w"> </span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="o">*</span><span class="n">f</span><span class="p">)</span>
</span><span class="hll"><span class="p">{</span>
</span><span class="hll"><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">f</span><span class="o">-&gt;</span><span class="n">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">f</span><span class="o">-&gt;</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">);</span>
</span><span class="hll"><span class="w">    </span><span class="n">Q</span><span class="p">.</span><span class="n">copy</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">size</span><span class="p">).</span><span class="n">wait</span><span class="p">();</span>
</span><span class="hll"><span class="p">}</span>
</span></pre></div>
</div>
</div><div aria-labelledby="tab-3-3-2" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-2" name="3-2" role="tabpanel" tabindex="0"><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numba</span><span class="w"> </span><span class="kn">import</span> <span class="n">cuda</span>

<span class="c1"># Update the temperature values using five-point stencil</span>
<span class="c1"># Arguments:</span>
<span class="c1">#   curr: current temperature field object</span>
<span class="c1">#   prev: temperature field from previous time step</span>
<span class="c1">#   a: diffusivity</span>
<span class="c1">#   dt: time step</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evolve</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="n">previous</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">dt</span><span class="p">):</span>
    <span class="n">dx2</span><span class="p">,</span> <span class="n">dy2</span> <span class="o">=</span> <span class="n">previous</span><span class="o">.</span><span class="n">dx</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">previous</span><span class="o">.</span><span class="n">dy</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">curr</span><span class="p">,</span> <span class="n">prev</span> <span class="o">=</span> <span class="n">current</span><span class="o">.</span><span class="n">dev</span><span class="p">,</span> <span class="n">previous</span><span class="o">.</span><span class="n">dev</span>
    <span class="c1"># Set thread and block sizes</span>
<span class="hll">    <span class="n">nx</span><span class="p">,</span> <span class="n">ny</span> <span class="o">=</span> <span class="n">prev</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># These are the FULL dims, rows+2 / cols+2</span>
</span><span class="hll">    <span class="n">tx</span><span class="p">,</span> <span class="n">ty</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>   <span class="c1"># Arbitrary choice</span>
</span><span class="hll">    <span class="n">bx</span><span class="p">,</span> <span class="n">by</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">nx</span> <span class="o">/</span> <span class="n">tx</span><span class="p">),</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ny</span> <span class="o">/</span> <span class="n">ty</span><span class="p">)</span>
</span>    <span class="c1"># Run numba (CUDA) kernel</span>
<span class="hll">    <span class="n">_evolve_kernel</span><span class="p">[(</span><span class="n">bx</span><span class="p">,</span> <span class="n">by</span><span class="p">),</span> <span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">)](</span><span class="n">curr</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">dx2</span><span class="p">,</span> <span class="n">dy2</span><span class="p">)</span>
</span>

<span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_evolve_kernel</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">dx2</span><span class="p">,</span> <span class="n">dy2</span><span class="p">):</span>
    <span class="n">nx</span><span class="p">,</span> <span class="n">ny</span> <span class="o">=</span> <span class="n">prev</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># These are the FULL dims, rows+2 / cols+2</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">nx</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> 
        <span class="ow">and</span> <span class="p">(</span><span class="n">j</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">j</span> <span class="o">&lt;</span> <span class="n">ny</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
        <span class="n">curr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span> \
            <span class="p">(</span><span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">/</span> <span class="n">dx2</span> <span class="o">+</span> \
            <span class="p">(</span><span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">dy2</span> <span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-3" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-3" name="3-3" role="tabpanel" tabindex="0"><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Main routine for heat equation solver in 2D.</span>
<span class="c1">// (c) 2023 ENCCS, CSC and the contributors</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdio&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;chrono&gt;</span>
<span class="k">using</span><span class="w"> </span><span class="n">wall_clock_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="p">;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;heat.h&quot;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">start_time</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">wall_clock_t</span><span class="o">::</span><span class="n">now</span><span class="p">();</span><span class="w"> </span><span class="p">}</span>
<span class="k">auto</span><span class="w"> </span><span class="n">stop_time</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">wall_clock_t</span><span class="o">::</span><span class="n">now</span><span class="p">();</span><span class="w"> </span><span class="p">}</span>


<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Set up the solver</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">nsteps</span><span class="p">;</span>
<span class="w">    </span><span class="n">field</span><span class="w"> </span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="n">previous</span><span class="p">;</span>
<span class="w">    </span><span class="n">initialize</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">previous</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nsteps</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Output the initial field and its temperature</span>
<span class="w">    </span><span class="n">field_write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">average_temp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">field_average</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Average temperature, start: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">average_temp</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Set diffusivity constant</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// Compute the largest stable time step</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">current</span><span class="p">.</span><span class="n">dx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">current</span><span class="p">.</span><span class="n">dx</span><span class="p">;</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">current</span><span class="p">.</span><span class="n">dy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">current</span><span class="p">.</span><span class="n">dy</span><span class="p">;</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">dt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dx2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dy2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">dx2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dy2</span><span class="p">));</span>
<span class="w">    </span><span class="c1">// Set output interval</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">output_interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1500</span><span class="p">;</span>

<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">Q</span><span class="p">{</span><span class="n">sycl</span><span class="o">::</span><span class="n">property</span><span class="o">::</span><span class="n">queue</span><span class="o">::</span><span class="n">in_order</span><span class="p">()};</span>

<span class="w">    </span><span class="c1">// Create two identical device buffers</span>
<span class="hll"><span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">d_current</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">((</span><span class="n">current</span><span class="p">.</span><span class="n">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">current</span><span class="p">.</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">),</span><span class="w"> </span><span class="n">Q</span><span class="p">);</span>
</span><span class="hll"><span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">d_previous</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">malloc_device</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">((</span><span class="n">current</span><span class="p">.</span><span class="n">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">current</span><span class="p">.</span><span class="n">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">),</span><span class="w"> </span><span class="n">Q</span><span class="p">);</span>
</span>
<span class="w">    </span><span class="c1">// Start timer</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">start_clock</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">start_time</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// Copy fields to device</span>
<span class="hll"><span class="w">    </span><span class="n">copy_to_buffer</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="n">d_previous</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">previous</span><span class="p">);</span>
</span><span class="hll"><span class="w">    </span><span class="n">copy_to_buffer</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="n">d_current</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">current</span><span class="p">);</span>
</span><span class="w">    </span><span class="c1">// Time evolution</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">nsteps</span><span class="p">;</span><span class="w"> </span><span class="n">iter</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">evolve</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="n">d_current</span><span class="p">,</span><span class="w"> </span><span class="n">d_previous</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">previous</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">);</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">iter</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">output_interval</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// Update data on host for output</span>
<span class="hll"><span class="w">            </span><span class="n">copy_from_buffer</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="n">d_current</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">current</span><span class="p">);</span>
</span><span class="w">            </span><span class="n">field_write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="n">iter</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="c1">// Swap current and previous fields for next iteration step</span>
<span class="w">        </span><span class="n">field_swap</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">previous</span><span class="p">);</span>
<span class="hll"><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">swap</span><span class="p">(</span><span class="n">d_current</span><span class="p">,</span><span class="w"> </span><span class="n">d_previous</span><span class="p">);</span>
</span><span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// Copy data back to host</span>
<span class="hll"><span class="w">    </span><span class="n">copy_from_buffer</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="n">d_previous</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">previous</span><span class="p">);</span>
</span><span class="w">    </span><span class="c1">// Stop timer</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">stop_clock</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_time</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Output the final field and its temperature</span>
<span class="w">    </span><span class="n">average_temp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">field_average</span><span class="p">(</span><span class="o">&amp;</span><span class="n">previous</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Average temperature at end: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">average_temp</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// Compare temperature for reference</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">argc</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Control temperature at end: 59.281239</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">field_write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">previous</span><span class="p">,</span><span class="w"> </span><span class="n">nsteps</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Determine the computation time used for all the iterations</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">elapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_clock</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_clock</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Iterations took %.3f seconds.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">elapsed</span><span class="p">.</span><span class="n">count</span><span class="p">());</span>
<span class="hll"><span class="w">    </span><span class="n">Q</span><span class="p">.</span><span class="n">wait_and_throw</span><span class="p">();</span>
</span><span class="hll"><span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">d_previous</span><span class="p">,</span><span class="w"> </span><span class="n">Q</span><span class="p">);</span>
</span><span class="hll"><span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">free</span><span class="p">(</span><span class="n">d_current</span><span class="p">,</span><span class="w"> </span><span class="n">Q</span><span class="p">);</span>
</span><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></div>
<div class="admonition-exercise-updated-gpu-ports exercise important admonition" id="exercise-4">
<p class="admonition-title">Exercise: updated GPU ports</p>
<p>Test your compiled executables <code class="docutils literal notranslate"><span class="pre">base/stencil_data</span></code> and <code class="docutils literal notranslate"><span class="pre">sycl/stencil</span></code>. Try changing problem size parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">stencil</span> <span class="pre">2000</span> <span class="pre">2000</span> <span class="pre">5000</span></code></p></li>
</ul>
<p>Things to look for:</p>
<ul class="simple">
<li><p>How computation times change this time around?</p></li>
<li><p>What largest grid and/or longest propagation time can you get in 10 s on your machine?</p></li>
</ul>
<div class="admonition-solution solution important dropdown admonition" id="solution-6">
<p class="admonition-title">Solution</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">OpenMP data mapping</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1">SYCL device buffers</button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><p>Using GPU offloading with mapped device data, it is possible to achieve performance gains compared to thread-parallel version for larger grid sizes, due to the fact that the latter version becomes essentially RAM-bound, but the former does not.</p>
<figure class="align-center">
<img alt="_images/omp-cpu-vs-gpu.png" src="_images/omp-cpu-vs-gpu.png" />
</figure>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><p>Below you can find the summary graphs for step- and grid- scaling of the stencil update task. Because of the more explicit programming approach, SYCL GPU port is much faster than OpenMP-offloaded version, comparable with thread-parallel CPU version running on all cores of a single node.</p>
<figure class="align-center">
<img alt="_images/summary-scaling-step-new.png" src="_images/summary-scaling-step-new.png" />
</figure>
<figure class="align-center">
<img alt="_images/summary-scaling-grid-new.png" src="_images/summary-scaling-grid-new.png" />
</figure>
</div></div>
</div>
</div>
</section>
<section id="python-jit-and-gpu-acceleration">
<h3>Python: JIT and GPU acceleration<a class="headerlink" href="#python-jit-and-gpu-acceleration" title="Link to this heading"></a></h3>
<p>As mentioned <a class="reference external" href="https://enccs.github.io/gpu-programming/9-language-support/#numba">previously</a>, Numba package allows developers to just-in-time (JIT) compile Python code to run fast on CPUs, but can also be used for JIT compiling for (NVIDIA) GPUs. JIT seems to work well on loop-based, computationally heavy functions, so trying it out is a nice choice for initial source version:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-5-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-5-5-0" name="5-0" role="tab" tabindex="0">Stencil update</button><button aria-controls="panel-5-5-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-1" name="5-1" role="tab" tabindex="-1">Data generation</button></div><div aria-labelledby="tab-5-5-0" class="sphinx-tabs-panel" id="panel-5-5-0" name="5-0" role="tabpanel" tabindex="0"><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">numba</span><span class="w"> </span><span class="kn">import</span> <span class="n">jit</span>


<span class="c1"># Update the temperature values using five-point stencil</span>
<span class="c1"># Arguments:</span>
<span class="c1">#   curr: current temperature field object</span>
<span class="c1">#   prev: temperature field from previous time step</span>
<span class="c1">#   a: diffusivity</span>
<span class="c1">#   dt: time step</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evolve</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="n">previous</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">dt</span><span class="p">):</span>
    <span class="n">dx2</span><span class="p">,</span> <span class="n">dy2</span> <span class="o">=</span> <span class="n">previous</span><span class="o">.</span><span class="n">dx</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">previous</span><span class="o">.</span><span class="n">dy</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">curr</span><span class="p">,</span> <span class="n">prev</span> <span class="o">=</span> <span class="n">current</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">previous</span><span class="o">.</span><span class="n">data</span>
    <span class="c1"># Run (possibly accelerated) update</span>
    <span class="n">_evolve</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">dx2</span><span class="p">,</span> <span class="n">dy2</span><span class="p">)</span>


<span class="hll"><span class="nd">@jit</span><span class="p">(</span><span class="n">nopython</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span class="k">def</span><span class="w"> </span><span class="nf">_evolve</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">dx2</span><span class="p">,</span> <span class="n">dy2</span><span class="p">):</span>
    <span class="n">nx</span><span class="p">,</span> <span class="n">ny</span> <span class="o">=</span> <span class="n">prev</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># These are the FULL dims, rows+2 / cols+2</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nx</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ny</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">curr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span> \
              <span class="p">(</span><span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">/</span> <span class="n">dx2</span> <span class="o">+</span> \
              <span class="p">(</span><span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">dy2</span> <span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-1" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-1" name="5-1" role="tabpanel" tabindex="0"><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="nd">@jit</span><span class="p">(</span><span class="n">nopython</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span class="k">def</span><span class="w"> </span><span class="nf">_generate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="n">ny</span><span class="p">):</span>
    <span class="c1"># Radius of the source disc</span>
    <span class="n">radius</span> <span class="o">=</span> <span class="n">nx</span> <span class="o">/</span> <span class="mf">6.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nx</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ny</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span>
            <span class="c1"># Distance of point i, j from the origin</span>
            <span class="n">dx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="n">nx</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">dy</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">ny</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">dx</span> <span class="o">*</span> <span class="n">dx</span> <span class="o">+</span> <span class="n">dy</span> <span class="o">*</span> <span class="n">dy</span> <span class="o">&lt;</span> <span class="n">radius</span> <span class="o">*</span> <span class="n">radius</span><span class="p">):</span>
                <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T_DISC</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T_AREA</span>

    <span class="c1"># Boundary conditions</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nx</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">T_LEFT</span>
        <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">ny</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">T_RIGHT</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ny</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T_UPPER</span>
        <span class="n">data</span><span class="p">[</span><span class="n">nx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T_LOWER</span>
</pre></div>
</div>
</div></div>
<p>The alternative approach would be to rewrite stencil update code in NumPy style, exploiting loop vectorization.</p>
<div class="admonition-trying-out-python-examples callout admonition" id="callout-2">
<p class="admonition-title">Trying out Python examples</p>
<p>You can run provided code examples on Google Colab using instructions provided in the <a class="reference external" href="https://enccs.github.io/gpu-programming/0-setup/#running-on-google-colab">Setup</a>, your local machine, or LUMI node (non-GPU variants). On LUMI, you can set up Python distribution as following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>cray-python/3.9.13.1
<span class="gp gp-VirtualEnv">(install needed dependencies locally)</span>
<span class="gp">$ </span>pip3<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>numba<span class="w"> </span>matplotlib
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>../python/
<span class="gp gp-VirtualEnv">(make sure you have active allocation)</span>
<span class="gp">$ </span>srun<span class="w"> </span>python3<span class="w"> </span>main.py
</pre></div>
</div>
</div>
<p>Short summary of a typical Colab run is provided below:</p>
<table class="docutils align-default" id="id4">
<caption><span class="caption-text">Run times of Numba JIT-enabled Python program, s</span><a class="headerlink" href="#id4" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Job size</p></th>
<th class="head"><p>JIT (LUMI)</p></th>
<th class="head"><p>JIT (Colab)</p></th>
<th class="head"><p>Job size</p></th>
<th class="head"><p>no JIT (Colab)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>S:2000 T:500</p></td>
<td><p>1.648</p></td>
<td><p>8.495</p></td>
<td><p>S:200 T:50</p></td>
<td><p>5.318</p></td>
</tr>
<tr class="row-odd"><td><p>S:2000 T:200</p></td>
<td><p>0.787</p></td>
<td><p>3.524</p></td>
<td><p>S:200 T:20</p></td>
<td><p>1.859</p></td>
</tr>
<tr class="row-even"><td><p>S:1000 T:500</p></td>
<td><p>0.547</p></td>
<td><p>2.230</p></td>
<td><p>S:100 T:50</p></td>
<td><p>1.156</p></td>
</tr>
</tbody>
</table>
<p>Numba’s <code class="docutils literal notranslate"><span class="pre">&#64;vectorize</span></code> and <code class="docutils literal notranslate"><span class="pre">&#64;guvectorize</span></code> decorators offer an interface to create CPU- (or GPU-) accelerated <em>Python</em> functions without explicit implementation details. However, such functions become increasingly complicated to write (and optimize by the compiler) with increasing complexity of the computations within.</p>
<p>Numba also offers direct CUDA-based kernel programming, which can be the best choice for those already familiar with CUDA. Example for stencil update written in Numba CUDA is shown in the <a class="reference external" href="https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement">data movement section</a>, tab “Python”. In this case, data transfer functions <code class="docutils literal notranslate"><span class="pre">devdata</span> <span class="pre">=</span> <span class="pre">cuda.to_device(data)</span></code> and <code class="docutils literal notranslate"><span class="pre">devdata.copy_to_host(data)</span></code> (see <code class="docutils literal notranslate"><span class="pre">main_cuda.py</span></code>) are already provided by Numba package.</p>
<div class="admonition-exercise-cuda-acceleration-in-python exercise important admonition" id="exercise-5">
<p class="admonition-title">Exercise: CUDA acceleration in Python</p>
<p>Using Google Colab (or your own machine), run provided Numba-CUDA Python program. Try changing problem size parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">args.rows,</span> <span class="pre">args.cols,</span> <span class="pre">args.nsteps</span> <span class="pre">=</span> <span class="pre">2000,</span> <span class="pre">2000,</span> <span class="pre">5000</span></code> for notebooks,</p></li>
<li><p>[<code class="docutils literal notranslate"><span class="pre">srun</span></code>] <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">main.py</span> <span class="pre">2000</span> <span class="pre">2000</span> <span class="pre">5000</span></code> for command line.</p></li>
</ul>
<p>Things to look for:</p>
<ul class="simple">
<li><p>How computation times change?</p></li>
<li><p>Do you get better performance than from JIT-compiled CPU version? How far can you push the problem size?</p></li>
<li><p>Are you able to monitor the GPU usage?</p></li>
</ul>
<div class="admonition-solution solution important dropdown admonition" id="solution-7">
<p class="admonition-title">Solution</p>
<p>Some numbers from Colab:</p>
<table class="docutils align-default" id="id5">
<caption><span class="caption-text">Run times of Numba CUDA Python program, s</span><a class="headerlink" href="#id5" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Job size</p></th>
<th class="head"><p>JIT (LUMI)</p></th>
<th class="head"><p>JIT (Colab)</p></th>
<th class="head"><p>CUDA (Colab)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>S:2000 T:500</p></td>
<td><p>1.648</p></td>
<td><p>8.495</p></td>
<td><p>1.079</p></td>
</tr>
<tr class="row-odd"><td><p>S:2000 T:2000</p></td>
<td><p>6.133</p></td>
<td><p>36.61</p></td>
<td><p>3.931</p></td>
</tr>
<tr class="row-even"><td><p>S:5000 T:500</p></td>
<td><p>9.478</p></td>
<td><p>57.19</p></td>
<td><p>6.448</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="julia-gpu-acceleration">
<h3>Julia GPU acceleration<a class="headerlink" href="#julia-gpu-acceleration" title="Link to this heading"></a></h3>
<p>A Julia version of the stencil example above can be found below (a simplified version of the HeatEquation module at <a class="reference external" href="https://github.com/ENCCS/HeatEquation.jl">https://github.com/ENCCS/HeatEquation.jl</a>).
The source files are also available in the <a class="reference external" href="https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/julia">content/examples/stencil/julia</a> directory of this repository.</p>
<p>To run the example on LUMI CPU partition, type:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># interactive CPU node</span>
<span class="gp">$ </span>srun<span class="w"> </span>--account<span class="o">=</span>project_465002387<span class="w"> </span>--partition<span class="o">=</span>standard<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">32</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--time<span class="o">=</span><span class="m">01</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>bash
<span class="gp">$ </span><span class="c1"># load Julia env</span>
<span class="gp">$ </span>module<span class="w"> </span>purge
<span class="gp">$ </span>module<span class="w"> </span>use<span class="w"> </span>/appl/local/csc/modulefiles
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>julia
<span class="gp">$ </span>module<span class="w"> </span>load<span class="w"> </span>julia-amdgpu
<span class="gp">$ </span><span class="c1"># in directory with Project.toml and source files, instantiate an environment to install packages</span>
<span class="gp">$ </span>julia<span class="w"> </span>--project<span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;using Pkg ; Pkg.instantiate()&quot;</span>
<span class="gp">$ </span><span class="c1"># finally run</span>
<span class="gp">$ </span>julia<span class="w"> </span>--project<span class="w"> </span>main.jl
</pre></div>
</div>
<p>To run on the GPU partition, use instead the <code class="docutils literal notranslate"><span class="pre">srun</span></code> command</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>--account<span class="o">=</span>project_465002387<span class="w"> </span>--partition<span class="o">=</span>standard-g<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--time<span class="o">=</span><span class="m">1</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>bash
</pre></div>
</div>
<div class="admonition-optional-dependency callout admonition" id="callout-3">
<p class="admonition-title">Optional dependency</p>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">Plots.jl</span></code> dependency is commented out in <code class="docutils literal notranslate"><span class="pre">main.jl</span></code> and <code class="docutils literal notranslate"><span class="pre">Project.toml</span></code>. This saves ~2 minute precompilation time when you first instantiate the Julia environment. To generate plots, just uncomment the commented <code class="docutils literal notranslate"><span class="pre">Plots.jl</span></code> dependency in <code class="docutils literal notranslate"><span class="pre">Project.toml</span></code>, instantiate again, and import and use <code class="docutils literal notranslate"><span class="pre">Plots</span></code> in <code class="docutils literal notranslate"><span class="pre">main.jl</span></code>.</p>
</div>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-6-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-6-6-0" name="6-0" role="tab" tabindex="0">main.jl</button><button aria-controls="panel-6-6-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-1" name="6-1" role="tab" tabindex="-1">core.jl</button><button aria-controls="panel-6-6-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-2" name="6-2" role="tab" tabindex="-1">heat.jl</button><button aria-controls="panel-6-6-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-3" name="6-3" role="tab" tabindex="-1">Project.toml</button></div><div aria-labelledby="tab-6-6-0" class="sphinx-tabs-panel" id="panel-6-6-0" name="6-0" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c">#using Plots</span>
<span class="k">using</span><span class="w"> </span><span class="n">BenchmarkTools</span>

<span class="n">include</span><span class="p">(</span><span class="s">&quot;heat.jl&quot;</span><span class="p">)</span>
<span class="n">include</span><span class="p">(</span><span class="s">&quot;core.jl&quot;</span><span class="p">)</span>


<span class="s">&quot;&quot;&quot;</span>
<span class="s">    visualize(curr::Field, filename=:none)</span>

<span class="s">Create a heatmap of a temperature field. Optionally write png file. </span>
<span class="s">&quot;&quot;&quot;</span><span class="w">    </span>
<span class="k">function</span><span class="w"> </span><span class="n">visualize</span><span class="p">(</span><span class="n">curr</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">filename</span><span class="o">=</span><span class="ss">:none</span><span class="p">)</span>
<span class="w">    </span><span class="n">background_color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">:white</span>
<span class="w">    </span><span class="n">plot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">heatmap</span><span class="p">(</span>
<span class="w">        </span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
<span class="w">        </span><span class="n">colorbar_title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Temperature (C)&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="n">background_color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">background_color</span>
<span class="w">    </span><span class="p">)</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">filename</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="ss">:none</span>
<span class="w">        </span><span class="n">savefig</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="w">    </span><span class="k">else</span>
<span class="w">        </span><span class="n">display</span><span class="p">(</span><span class="n">plot</span><span class="p">)</span>
<span class="w">    </span><span class="k">end</span>
<span class="k">end</span>


<span class="n">ncols</span><span class="p">,</span><span class="w"> </span><span class="n">nrows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2048</span><span class="p">,</span><span class="w"> </span><span class="mi">2048</span>
<span class="n">nsteps</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">500</span>

<span class="c"># initialize current and previous states to the same state</span>
<span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initialize</span><span class="p">(</span><span class="n">ncols</span><span class="p">,</span><span class="w"> </span><span class="n">nrows</span><span class="p">)</span>

<span class="c"># visualize initial field, requires Plots.jl</span>
<span class="c">#visualize(curr, &quot;initial.png&quot;)</span>

<span class="c"># simulate temperature evolution for nsteps</span>
<span class="n">simulate!</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="n">nsteps</span><span class="p">)</span>

<span class="c"># visualize final field, requires Plots.jl</span>
<span class="c">#visualize(curr, &quot;final.png&quot;)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-1" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-1" name="6-1" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">ProgressMeter</span>

<span class="s">&quot;&quot;&quot;</span>
<span class="s">    evolve!(curr::Field, prev::Field, a, dt)</span>

<span class="s">Calculate a new temperature field curr based on the previous </span>
<span class="s">field prev. a is the diffusion constant and dt is the largest </span>
<span class="s">stable time step.    </span>
<span class="s">&quot;&quot;&quot;</span>
<span class="k">function</span><span class="w"> </span><span class="n">evolve!</span><span class="p">(</span><span class="n">curr</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="w">    </span><span class="n">Threads</span><span class="o">.</span><span class="nd">@threads</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="n">curr</span><span class="o">.</span><span class="n">ny</span><span class="o">+</span><span class="mi">1</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="n">curr</span><span class="o">.</span><span class="n">nx</span><span class="o">+</span><span class="mi">1</span>
<span class="w">            </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">xderiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dx</span><span class="o">^</span><span class="mi">2</span>
<span class="w">            </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">yderiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dy</span><span class="o">^</span><span class="mi">2</span>
<span class="w">            </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">xderiv</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">yderiv</span><span class="p">)</span>
<span class="w">        </span><span class="k">end</span><span class="w"> </span>
<span class="w">    </span><span class="k">end</span>
<span class="k">end</span>



<span class="s">&quot;&quot;&quot;</span>
<span class="s">    swap_fields!(curr::Field, prev::Field)</span>

<span class="s">Swap the data of two fields curr and prev.    </span>
<span class="s">&quot;&quot;&quot;</span><span class="w">    </span>
<span class="k">function</span><span class="w"> </span><span class="n">swap_fields!</span><span class="p">(</span><span class="n">curr</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="o">::</span><span class="kt">Field</span><span class="p">)</span>
<span class="w">    </span><span class="n">tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">data</span>
<span class="w">    </span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span>
<span class="w">    </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp</span>
<span class="k">end</span>

<span class="s">&quot;&quot;&quot; </span>
<span class="s">    average_temperature(f::Field)</span>

<span class="s">Calculate average temperature of a temperature field.        </span>
<span class="s">&quot;&quot;&quot;</span>
<span class="n">average_temperature</span><span class="p">(</span><span class="n">f</span><span class="o">::</span><span class="kt">Field</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="n">f</span><span class="o">.</span><span class="n">nx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="n">f</span><span class="o">.</span><span class="n">ny</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">nx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">ny</span><span class="p">)</span>

<span class="s">&quot;&quot;&quot;</span>
<span class="s">    simulate!(current, previous, nsteps)</span>

<span class="s">Run the heat equation solver on fields curr and prev for nsteps.</span>
<span class="s">&quot;&quot;&quot;</span>
<span class="k">function</span><span class="w"> </span><span class="n">simulate!</span><span class="p">(</span><span class="n">curr</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">nsteps</span><span class="p">)</span>

<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;Initial average temperature: </span><span class="si">$</span><span class="p">(</span><span class="n">average_temperature</span><span class="p">(</span><span class="n">curr</span><span class="p">))</span><span class="s">&quot;</span><span class="p">)</span>

<span class="w">    </span><span class="c"># Diffusion constant</span>
<span class="w">    </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span>
<span class="w">    </span><span class="c"># Largest stable time step</span>
<span class="w">    </span><span class="n">dt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dx</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dy</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">curr</span><span class="o">.</span><span class="n">dx</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dy</span><span class="o">^</span><span class="mi">2</span><span class="p">))</span>
<span class="w">    </span>
<span class="w">    </span><span class="c"># display a nice progress bar</span>
<span class="w">    </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Progress</span><span class="p">(</span><span class="n">nsteps</span><span class="p">)</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="n">nsteps</span>
<span class="w">        </span><span class="c"># calculate new state based on previous state</span>
<span class="w">        </span><span class="n">evolve!</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>

<span class="w">        </span><span class="c"># swap current and previous fields</span>
<span class="w">        </span><span class="n">swap_fields!</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="p">)</span>

<span class="w">        </span><span class="c"># increment the progress bar</span>
<span class="w">        </span><span class="n">next!</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span>

<span class="w">    </span><span class="c"># print final average temperature</span>
<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;Final average temperature: </span><span class="si">$</span><span class="p">(</span><span class="n">average_temperature</span><span class="p">(</span><span class="n">curr</span><span class="p">))</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-2" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-2" name="6-2" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># Fixed grid spacing</span>
<span class="k">const</span><span class="w"> </span><span class="n">DX</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.01</span>
<span class="k">const</span><span class="w"> </span><span class="n">DY</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.01</span>
<span class="c"># Default temperatures</span>
<span class="k">const</span><span class="w"> </span><span class="n">T_DISC</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">5.0</span>
<span class="k">const</span><span class="w"> </span><span class="n">T_AREA</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">65.0</span>
<span class="k">const</span><span class="w"> </span><span class="n">T_UPPER</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">85.0</span>
<span class="k">const</span><span class="w"> </span><span class="n">T_LOWER</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">5.0</span>
<span class="k">const</span><span class="w"> </span><span class="n">T_LEFT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">20.0</span>
<span class="k">const</span><span class="w"> </span><span class="n">T_RIGHT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">70.0</span>
<span class="c"># Default problem size</span>
<span class="k">const</span><span class="w"> </span><span class="n">ROWS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2000</span>
<span class="k">const</span><span class="w"> </span><span class="n">COLS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2000</span>
<span class="k">const</span><span class="w"> </span><span class="n">NSTEPS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">500</span>


<span class="s">&quot;&quot;&quot;</span>
<span class="s">    Field(nx::Int64, ny::Int64, dx::Float64, dy::Float64, data::Matrix{Float64})</span>

<span class="s">Temperature field type. nx and ny are the dimensions of the field. </span>
<span class="s">The array data contains also ghost layers, so it will have dimensions </span>
<span class="s">[nx+2, ny+2]</span>
<span class="s">&quot;&quot;&quot;</span>
<span class="k">mutable</span><span class="w"> </span><span class="k">struct</span> <span class="kt">Field</span><span class="p">{</span><span class="kt">T</span><span class="o">&lt;:</span><span class="kt">AbstractArray</span><span class="p">}</span>
<span class="w">    </span><span class="n">nx</span><span class="o">::</span><span class="kt">Int64</span>
<span class="w">    </span><span class="n">ny</span><span class="o">::</span><span class="kt">Int64</span>
<span class="w">    </span><span class="c"># Size of the grid cells</span>
<span class="w">    </span><span class="n">dx</span><span class="o">::</span><span class="kt">Float64</span>
<span class="w">    </span><span class="n">dy</span><span class="o">::</span><span class="kt">Float64</span>
<span class="w">    </span><span class="c"># The temperature values in the 2D grid</span>
<span class="w">    </span><span class="n">data</span><span class="o">::</span><span class="kt">T</span>
<span class="k">end</span>

<span class="c"># outer constructor with default cell sizes and initialized data</span>
<span class="n">Field</span><span class="p">(</span><span class="n">nx</span><span class="o">::</span><span class="kt">Int64</span><span class="p">,</span><span class="w"> </span><span class="n">ny</span><span class="o">::</span><span class="kt">Int64</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Field</span><span class="p">{</span><span class="kt">typeof</span><span class="p">(</span><span class="kt">data</span><span class="p">)}(</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">ny</span><span class="p">,</span><span class="w"> </span><span class="mf">0.01</span><span class="p">,</span><span class="w"> </span><span class="mf">0.01</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span>

<span class="c"># extend deepcopy to new type</span>
<span class="n">Base</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">f</span><span class="o">::</span><span class="kt">Field</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Field</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">ny</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">deepcopy</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>

<span class="s">&quot;&quot;&quot;</span>
<span class="s">    initialize(rows::Int, cols::Int, arraytype = Matrix)</span>

<span class="s">Initialize two temperature field with (nrows, ncols) number of </span>
<span class="s">rows and columns. If the arraytype is something else than Matrix,</span>
<span class="s">create data on the CPU first to avoid scalar indexing errors.</span>
<span class="s">&quot;&quot;&quot;</span>
<span class="k">function</span><span class="w"> </span><span class="n">initialize</span><span class="p">(</span><span class="n">nrows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="n">ncols</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="n">arraytype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Matrix</span><span class="p">)</span>
<span class="w">    </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">zeros</span><span class="p">(</span><span class="n">nrows</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncols</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
<span class="w">    </span>
<span class="w">    </span><span class="c"># generate a field with boundary conditions</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">arraytype</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="kt">Matrix</span>
<span class="w">        </span><span class="n">tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Field</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span><span class="w"> </span><span class="n">ncols</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span>
<span class="w">        </span><span class="n">generate_field!</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>
<span class="w">        </span><span class="n">gpudata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">arraytype</span><span class="p">(</span><span class="n">tmp</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="w">        </span><span class="n">previous</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Field</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span><span class="w"> </span><span class="n">ncols</span><span class="p">,</span><span class="w"> </span><span class="n">gpudata</span><span class="p">)</span>
<span class="w">    </span><span class="k">else</span>
<span class="w">        </span><span class="n">previous</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Field</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span><span class="w"> </span><span class="n">ncols</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span>
<span class="w">        </span><span class="n">generate_field!</span><span class="p">(</span><span class="n">previous</span><span class="p">)</span>
<span class="w">    </span><span class="k">end</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">current</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Base</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">previous</span><span class="p">)</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">previous</span><span class="p">,</span><span class="w"> </span><span class="n">current</span>
<span class="k">end</span>


<span class="s">&quot;&quot;&quot;</span>
<span class="s">    generate_field!(field0::Field)</span>

<span class="s">Generate a temperature field.  Pattern is disc with a radius</span>
<span class="s">of nx / 6 in the center of the grid. Boundary conditions are </span>
<span class="s">(different) constant temperatures outside the grid.</span>
<span class="s">&quot;&quot;&quot;</span>
<span class="k">function</span><span class="w"> </span><span class="n">generate_field!</span><span class="p">(</span><span class="n">field</span><span class="o">::</span><span class="kt">Field</span><span class="p">)</span>
<span class="w">    </span><span class="c"># Square of the disk radius</span>
<span class="w">    </span><span class="n">radius2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">6.0</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="n">field</span><span class="o">.</span><span class="n">ny</span><span class="o">+</span><span class="mi">2</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="n">field</span><span class="o">.</span><span class="n">nx</span><span class="o">+</span><span class="mi">2</span>
<span class="w">            </span><span class="n">ds2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">field</span><span class="o">.</span><span class="n">nx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">field</span><span class="o">.</span><span class="n">ny</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">ds2</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">radius2</span><span class="w"> </span>
<span class="w">                </span><span class="n">field</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">T_DISC</span>
<span class="w">            </span><span class="k">else</span>
<span class="w">                </span><span class="n">field</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">T_AREA</span>
<span class="w">            </span><span class="k">end</span>
<span class="w">        </span><span class="k">end</span><span class="w"> </span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span>

<span class="w">    </span><span class="c"># Boundary conditions</span>
<span class="w">    </span><span class="n">field</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="n">T_LEFT</span>
<span class="w">    </span><span class="n">field</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="n">field</span><span class="o">.</span><span class="n">ny</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="n">T_RIGHT</span>
<span class="w">    </span><span class="n">field</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">]</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="n">T_UPPER</span>
<span class="w">    </span><span class="n">field</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">field</span><span class="o">.</span><span class="n">nx</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span><span class="o">:</span><span class="p">]</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="n">T_LOWER</span>
<span class="k">end</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-3" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-3" name="6-3" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">deps</span><span class="p">]</span>
<span class="n">BenchmarkTools</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf&quot;</span>
<span class="c">#Plots = &quot;91a5bcdd-55d7-5caf-9e0b-520d859cae80&quot;</span>
<span class="n">ProgressMeter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;92933f4c-e287-5a05-a399-4b506db050ca&quot;</span>
</pre></div>
</div>
</div></div>
<div class="admonition-exercise-julia-port-to-gpus exercise important admonition" id="exercise-6">
<p class="admonition-title">Exercise: Julia port to GPUs</p>
<p>Carefully inspect all Julia source files and consider the following questions:</p>
<ol class="arabic simple">
<li><p>Which functions should be ported to run on GPU?</p></li>
<li><p>Look at the <code class="xref py py-meth docutils literal notranslate"><span class="pre">initialize!()</span></code> function and how it uses the <code class="docutils literal notranslate"><span class="pre">arraytype</span></code> argument. This could be done more compactly and elegantly, but this solution solves scalar indexing errors. What are scalar indexing errors?</p></li>
<li><p>Try to start sketching GPU-ported versions of the key functions.</p></li>
<li><p>When you have a version running on a GPU (your own or the solution provided below), try benchmarking it by adding <code class="docutils literal notranslate"><span class="pre">&#64;btime</span></code> in front of <code class="xref py py-meth docutils literal notranslate"><span class="pre">simulate!()</span></code> in <code class="docutils literal notranslate"><span class="pre">main.jl</span></code>. Benchmark also the CPU version, and compare.</p></li>
</ol>
<div class="admonition-hints solution important dropdown admonition" id="solution-8">
<p class="admonition-title">Hints</p>
<ul class="simple">
<li><p>create a new function <code class="xref py py-meth docutils literal notranslate"><span class="pre">evolve_gpu!()</span></code> which contains the GPU kernelized version of <code class="xref py py-meth docutils literal notranslate"><span class="pre">evolve!()</span></code></p></li>
<li><p>in the loop over timesteps in <code class="xref py py-meth docutils literal notranslate"><span class="pre">simulate!()</span></code>, you will need a conditional like <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">typeof(curr.data)</span> <span class="pre">&lt;:</span> <span class="pre">ROCArray</span></code> to call your GPU-ported function</p></li>
<li><p>you cannot pass the struct <code class="docutils literal notranslate"><span class="pre">Field</span></code> to the kernel. You will instead need to directly pass the array <code class="docutils literal notranslate"><span class="pre">Field.data</span></code>. This also necessitates passing in other variables like <code class="docutils literal notranslate"><span class="pre">curr.dx^2</span></code>, etc.</p></li>
</ul>
</div>
<div class="admonition-more-hints solution important dropdown admonition" id="solution-9">
<p class="admonition-title">More hints</p>
<ul class="simple">
<li><p>since the data is two-dimensional, you’ll need <code class="docutils literal notranslate"><span class="pre">i</span> <span class="pre">=</span> <span class="pre">(blockIdx().x</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">*</span> <span class="pre">blockDim().x</span> <span class="pre">+</span> <span class="pre">threadIdx().x</span></code> and <code class="docutils literal notranslate"><span class="pre">j</span> <span class="pre">=</span> <span class="pre">(blockIdx().y</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">*</span> <span class="pre">blockDim().y</span> <span class="pre">+</span> <span class="pre">threadIdx().y</span></code></p></li>
<li><p>to not overindex the 2D array, you can use a conditional like <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">i</span> <span class="pre">&gt;</span> <span class="pre">1</span> <span class="pre">&amp;&amp;</span> <span class="pre">j</span> <span class="pre">&gt;</span> <span class="pre">1</span> <span class="pre">&amp;&amp;</span> <span class="pre">i</span> <span class="pre">&lt;</span> <span class="pre">nx+2</span> <span class="pre">&amp;&amp;</span> <span class="pre">j</span> <span class="pre">&lt;</span> <span class="pre">ny+2</span></code></p></li>
<li><p>when calling the kernel, you can set the number of threads and blocks like <code class="docutils literal notranslate"><span class="pre">xthreads</span> <span class="pre">=</span> <span class="pre">ythreads</span> <span class="pre">=</span> <span class="pre">16</span></code> and <code class="docutils literal notranslate"><span class="pre">xblocks,</span> <span class="pre">yblocks</span> <span class="pre">=</span> <span class="pre">cld(curr.nx,</span> <span class="pre">xthreads),</span> <span class="pre">cld(curr.ny,</span> <span class="pre">ythreads)</span></code>, and then call it with, e.g., <code class="docutils literal notranslate"><span class="pre">&#64;roc</span> <span class="pre">threads=(xthreads,</span> <span class="pre">ythreads)</span> <span class="pre">blocks</span> <span class="pre">=</span> <span class="pre">(xblocks,</span> <span class="pre">yblocks)</span> <span class="pre">evolve_rocm!(curr.data,</span> <span class="pre">prev.data,</span> <span class="pre">curr.dx^2,</span> <span class="pre">curr.dy^2,</span> <span class="pre">nx,</span> <span class="pre">ny,</span> <span class="pre">a,</span> <span class="pre">dt)</span></code>.</p></li>
</ul>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-10">
<p class="admonition-title">Solution</p>
<ol class="arabic simple">
<li><p>The <code class="xref py py-meth docutils literal notranslate"><span class="pre">evolve!()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">simulate!()</span></code> functions need to be ported. The <code class="docutils literal notranslate"><span class="pre">main.jl</span></code> file also needs to be updated to work with GPU arrays.</p></li>
<li><p>“Scalar indexing” is where you iterate over a GPU array, which would be excruciatingly slow and is indeed only allowed in interactive REPL sessions. Without the if-statements in the <code class="xref py py-meth docutils literal notranslate"><span class="pre">initialize!()</span></code> function, the <code class="xref py py-meth docutils literal notranslate"><span class="pre">generate_field!()</span></code> method would be doing disallowed scalar indexing if you were running on a GPU.</p></li>
<li><p>The GPU-ported version is found below. Try it out on both CPU and GPU and observe the speedup. Play around with array size to see if the speedup is affected. You can also play around with the <code class="docutils literal notranslate"><span class="pre">xthreads</span></code> and <code class="docutils literal notranslate"><span class="pre">ythreads</span></code> variables to see if it changes anything.</p></li>
</ol>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-7-7-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-7-7-0" name="7-0" role="tab" tabindex="0">main_gpu.jl</button><button aria-controls="panel-7-7-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-1" name="7-1" role="tab" tabindex="-1">core_gpu.jl</button></div><div aria-labelledby="tab-7-7-0" class="sphinx-tabs-panel" id="panel-7-7-0" name="7-0" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c">#using Plots</span>
<span class="k">using</span><span class="w"> </span><span class="n">BenchmarkTools</span>
<span class="k">using</span><span class="w"> </span><span class="n">AMDGPU</span>

<span class="n">include</span><span class="p">(</span><span class="s">&quot;heat.jl&quot;</span><span class="p">)</span>
<span class="n">include</span><span class="p">(</span><span class="s">&quot;core_gpu.jl&quot;</span><span class="p">)</span>


<span class="s">&quot;&quot;&quot;</span>
<span class="s">    visualize(curr::Field, filename=:none)</span>

<span class="s">Create a heatmap of a temperature field. Optionally write png file. </span>
<span class="s">&quot;&quot;&quot;</span><span class="w">    </span>
<span class="k">function</span><span class="w"> </span><span class="n">visualize</span><span class="p">(</span><span class="n">curr</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">filename</span><span class="o">=</span><span class="ss">:none</span><span class="p">)</span>
<span class="w">    </span><span class="n">background_color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">:white</span>
<span class="w">    </span><span class="n">plot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">heatmap</span><span class="p">(</span>
<span class="w">        </span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
<span class="w">        </span><span class="n">colorbar_title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Temperature (C)&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="n">background_color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">background_color</span>
<span class="w">    </span><span class="p">)</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">filename</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="ss">:none</span>
<span class="w">        </span><span class="n">savefig</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="w">    </span><span class="k">else</span>
<span class="w">        </span><span class="n">display</span><span class="p">(</span><span class="n">plot</span><span class="p">)</span>
<span class="w">    </span><span class="k">end</span>
<span class="k">end</span>


<span class="n">ncols</span><span class="p">,</span><span class="w"> </span><span class="n">nrows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2048</span><span class="p">,</span><span class="w"> </span><span class="mi">2048</span>
<span class="n">nsteps</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">500</span>

<span class="c"># initialize data on CPU</span>
<span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initialize</span><span class="p">(</span><span class="n">ncols</span><span class="p">,</span><span class="w"> </span><span class="n">nrows</span><span class="p">,</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">)</span>
<span class="c"># initialize data on CPU</span>
<span class="c">#curr, prev = initialize(ncols, nrows)</span>

<span class="c"># visualize initial field, requires Plots.jl</span>
<span class="c">#visualize(curr, &quot;initial.png&quot;)</span>

<span class="c"># simulate temperature evolution for nsteps</span>
<span class="nd">@btime</span><span class="w"> </span><span class="n">simulate!</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="n">nsteps</span><span class="p">)</span>

<span class="c"># visualize final field, requires Plots.jl</span>
<span class="c">#visualize(curr, &quot;final.png&quot;)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-1" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-1" name="7-1" role="tabpanel" tabindex="0"><div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">ProgressMeter</span>

<span class="s">&quot;&quot;&quot;</span>
<span class="s">    evolve!(curr::Field, prev::Field, a, dt)</span>

<span class="s">Calculate a new temperature field curr based on the previous </span>
<span class="s">field prev. a is the diffusion constant and dt is the largest </span>
<span class="s">stable time step.    </span>
<span class="s">&quot;&quot;&quot;</span>
<span class="k">function</span><span class="w"> </span><span class="n">evolve!</span><span class="p">(</span><span class="n">curr</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="w">    </span><span class="n">Threads</span><span class="o">.</span><span class="nd">@threads</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="n">curr</span><span class="o">.</span><span class="n">ny</span><span class="o">+</span><span class="mi">1</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="n">curr</span><span class="o">.</span><span class="n">nx</span><span class="o">+</span><span class="mi">1</span>
<span class="w">            </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">xderiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dx</span><span class="o">^</span><span class="mi">2</span>
<span class="w">            </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">yderiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dy</span><span class="o">^</span><span class="mi">2</span>
<span class="w">            </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">xderiv</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">yderiv</span><span class="p">)</span>
<span class="w">        </span><span class="k">end</span><span class="w"> </span>
<span class="w">    </span><span class="k">end</span>
<span class="k">end</span>


<span class="k">function</span><span class="w"> </span><span class="n">evolve_cuda!</span><span class="p">(</span><span class="n">currdata</span><span class="p">,</span><span class="w"> </span><span class="n">prevdata</span><span class="p">,</span><span class="w"> </span><span class="n">dx2</span><span class="p">,</span><span class="w"> </span><span class="n">dy2</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">ny</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">blockIdx</span><span class="p">()</span><span class="o">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">()</span><span class="o">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">()</span><span class="o">.</span><span class="n">x</span>
<span class="w">    </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">blockIdx</span><span class="p">()</span><span class="o">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">()</span><span class="o">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">()</span><span class="o">.</span><span class="n">y</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="o">+</span><span class="mi">2</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ny</span><span class="o">+</span><span class="mi">2</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">xderiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dx2</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">yderiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dy2</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">currdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">xderiv</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">yderiv</span><span class="p">)</span>
<span class="w">    </span><span class="k">end</span>
<span class="w">    </span><span class="k">return</span>
<span class="k">end</span>

<span class="k">function</span><span class="w"> </span><span class="n">evolve_rocm!</span><span class="p">(</span><span class="n">currdata</span><span class="p">,</span><span class="w"> </span><span class="n">prevdata</span><span class="p">,</span><span class="w"> </span><span class="n">dx2</span><span class="p">,</span><span class="w"> </span><span class="n">dy2</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">ny</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">workgroupIdx</span><span class="p">()</span><span class="o">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">workgroupDim</span><span class="p">()</span><span class="o">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">workitemIdx</span><span class="p">()</span><span class="o">.</span><span class="n">x</span>
<span class="w">    </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">workgroupIdx</span><span class="p">()</span><span class="o">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">workgroupDim</span><span class="p">()</span><span class="o">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">workitemIdx</span><span class="p">()</span><span class="o">.</span><span class="n">y</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nx</span><span class="o">+</span><span class="mi">2</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">ny</span><span class="o">+</span><span class="mi">2</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">xderiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dx2</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">yderiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">dy2</span>
<span class="w">        </span><span class="nd">@inbounds</span><span class="w"> </span><span class="n">currdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prevdata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">xderiv</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">yderiv</span><span class="p">)</span>
<span class="w">    </span><span class="k">end</span>
<span class="w">    </span><span class="k">return</span>
<span class="k">end</span>


<span class="s">&quot;&quot;&quot;</span>
<span class="s">    swap_fields!(curr::Field, prev::Field)</span>

<span class="s">Swap the data of two fields curr and prev.    </span>
<span class="s">&quot;&quot;&quot;</span><span class="w">    </span>
<span class="k">function</span><span class="w"> </span><span class="n">swap_fields!</span><span class="p">(</span><span class="n">curr</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="o">::</span><span class="kt">Field</span><span class="p">)</span>
<span class="w">    </span><span class="n">tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">data</span>
<span class="w">    </span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span>
<span class="w">    </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp</span>
<span class="k">end</span>

<span class="s">&quot;&quot;&quot; </span>
<span class="s">    average_temperature(f::Field)</span>

<span class="s">Calculate average temperature of a temperature field.        </span>
<span class="s">&quot;&quot;&quot;</span>
<span class="n">average_temperature</span><span class="p">(</span><span class="n">f</span><span class="o">::</span><span class="kt">Field</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="n">f</span><span class="o">.</span><span class="n">nx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="n">f</span><span class="o">.</span><span class="n">ny</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">nx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">f</span><span class="o">.</span><span class="n">ny</span><span class="p">)</span>

<span class="s">&quot;&quot;&quot;</span>
<span class="s">    simulate!(current, previous, nsteps)</span>

<span class="s">Run the heat equation solver on fields curr and prev for nsteps.</span>
<span class="s">&quot;&quot;&quot;</span>
<span class="k">function</span><span class="w"> </span><span class="n">simulate!</span><span class="p">(</span><span class="n">curr</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="o">::</span><span class="kt">Field</span><span class="p">,</span><span class="w"> </span><span class="n">nsteps</span><span class="p">)</span>

<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;Initial average temperature: </span><span class="si">$</span><span class="p">(</span><span class="n">average_temperature</span><span class="p">(</span><span class="n">curr</span><span class="p">))</span><span class="s">&quot;</span><span class="p">)</span>

<span class="w">    </span><span class="c"># Diffusion constant</span>
<span class="w">    </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span>
<span class="w">    </span><span class="c"># Largest stable time step</span>
<span class="w">    </span><span class="n">dt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dx</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dy</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">curr</span><span class="o">.</span><span class="n">dx</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dy</span><span class="o">^</span><span class="mi">2</span><span class="p">))</span>
<span class="w">    </span>
<span class="w">    </span><span class="c"># display a nice progress bar</span>
<span class="w">    </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Progress</span><span class="p">(</span><span class="n">nsteps</span><span class="p">)</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="n">nsteps</span>
<span class="w">        </span><span class="c"># calculate new state based on previous state</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">typeof</span><span class="p">(</span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;:</span><span class="w"> </span><span class="kt">ROCArray</span>
<span class="w">            </span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">(</span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="o">.-</span><span class="w"> </span><span class="mi">2</span><span class="w">   </span>
<span class="w">            </span><span class="n">xthreads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ythreads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span>
<span class="w">            </span><span class="n">xblocks</span><span class="p">,</span><span class="w"> </span><span class="n">yblocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cld</span><span class="p">(</span><span class="n">curr</span><span class="o">.</span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">xthreads</span><span class="p">),</span><span class="w"> </span><span class="n">cld</span><span class="p">(</span><span class="n">curr</span><span class="o">.</span><span class="n">ny</span><span class="p">,</span><span class="w"> </span><span class="n">ythreads</span><span class="p">)</span>
<span class="w">            </span><span class="nd">@roc</span><span class="w"> </span><span class="n">groupsize</span><span class="o">=</span><span class="p">(</span><span class="n">xthreads</span><span class="p">,</span><span class="w"> </span><span class="n">ythreads</span><span class="p">)</span><span class="w"> </span><span class="n">gridsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">xblocks</span><span class="p">,</span><span class="w"> </span><span class="n">yblocks</span><span class="p">)</span><span class="w"> </span><span class="n">evolve_rocm!</span><span class="p">(</span><span class="n">curr</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dx</span><span class="o">^</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">curr</span><span class="o">.</span><span class="n">dy</span><span class="o">^</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">nx</span><span class="p">,</span><span class="w"> </span><span class="n">ny</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="w">        </span><span class="k">else</span>
<span class="w">            </span><span class="n">evolve!</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span>
<span class="w">        </span><span class="k">end</span>

<span class="w">        </span><span class="c"># swap current and previous fields</span>
<span class="w">        </span><span class="n">swap_fields!</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span><span class="w"> </span><span class="n">prev</span><span class="p">)</span>

<span class="w">        </span><span class="c"># increment the progress bar</span>
<span class="w">        </span><span class="n">next!</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span>

<span class="w">    </span><span class="c"># print final average temperature</span>
<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;Final average temperature: </span><span class="si">$</span><span class="p">(</span><span class="n">average_temperature</span><span class="p">(</span><span class="n">curr</span><span class="p">))</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</div></div>
</div>
</div>
</section>
<section id="see-also">
<h3>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h3>
<p>This section leans heavily on source code and material created for several other computing workshops
by <a class="reference external" href="https://enccs.se/">ENCCS</a> and <a class="reference external" href="https://csc.fi/">CSC</a> and adapted for the purposes of this lesson.
If you want to know more about specific programming models / framework, definitely check these out!</p>
<ul class="simple">
<li><p><a class="reference external" href="https://enccs.github.io/openmp-gpu/">OpenMP for GPU offloading</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/sycl-workshop/">Heterogeneous programming with SYCL</a></p></li>
<li><p><a class="reference external" href="https://github.com/cschpc/heat-equation/">Educational implementation of heat flow example (incl. MPI-aware CUDA)</a></p></li>
</ul>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-quick-reference"></span><section id="quick-reference">
<h2>Quick Reference<a class="headerlink" href="#quick-reference" title="Link to this heading"></a></h2>
</section>
<span id="document-glossary"></span><section id="glossary">
<h2>Glossary<a class="headerlink" href="#glossary" title="Link to this heading"></a></h2>
<dl class="simple glossary">
<dt id="term-thread">thread<a class="headerlink" href="#term-thread" title="Link to this term"></a></dt><dd><p>Definition.  otherframework: <a class="reference internal" href="#term-workitem"><span class="xref std std-term">workitem</span></a></p>
</dd>
<dt id="term-workitem">workitem<a class="headerlink" href="#term-workitem" title="Link to this term"></a></dt><dd><p>Definition.  otherframework: <a class="reference internal" href="#term-thread"><span class="xref std std-term">thread</span></a></p>
</dd>
</dl>
<section id="abbreviations">
<h3>Abbreviations<a class="headerlink" href="#abbreviations" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 33.3%" />
<col style="width: 66.7%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Abbreviations</p></th>
<th class="head"><p>Full names</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>CUDA</p></td>
<td><p>compute unified device architecture</p></td>
</tr>
<tr class="row-odd"><td><p>DAG</p></td>
<td><p>directed acyclic graph</p></td>
</tr>
<tr class="row-even"><td><p>FPGAs</p></td>
<td><p>field-programmable gate arrays</p></td>
</tr>
<tr class="row-odd"><td><p>GPU</p></td>
<td><p>graphics processing units</p></td>
</tr>
<tr class="row-even"><td><p>HIP</p></td>
<td><p>heterogeneous-computing interface for portability</p></td>
</tr>
<tr class="row-odd"><td><p>NLP</p></td>
<td><p>natural language processing</p></td>
</tr>
<tr class="row-even"><td><p>SIMD</p></td>
<td><p>single instruction multiple data</p></td>
</tr>
<tr class="row-odd"><td><p>SIMT</p></td>
<td><p>single instruction multiple threads</p></td>
</tr>
<tr class="row-even"><td><p>SP</p></td>
<td><p>streaming processors</p></td>
</tr>
<tr class="row-odd"><td><p>SMP</p></td>
<td><p>streaming multi-processors</p></td>
</tr>
<tr class="row-even"><td><p>SVM</p></td>
<td><p>shared virtual memory</p></td>
</tr>
<tr class="row-odd"><td><p>USM</p></td>
<td><p>unified shared memory</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<span id="document-guide"></span><section id="instructor-s-guide">
<h2>Instructor’s guide<a class="headerlink" href="#instructor-s-guide" title="Link to this heading"></a></h2>
<section id="updated-schedule-for-a-three-day-workshop-2024">
<h3>Updated schedule for a three-day workshop (2024)<a class="headerlink" href="#updated-schedule-for-a-three-day-workshop-2024" title="Link to this heading"></a></h3>
<p><strong>Day 1</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Section</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>9:00-9:15</p></td>
<td><p>Welcome</p></td>
</tr>
<tr class="row-odd"><td><p>9:15-9:40</p></td>
<td><p>Why GPUs?</p></td>
</tr>
<tr class="row-even"><td><p>9:40-10:20</p></td>
<td><p>The GPU hardware and software ecosystem</p></td>
</tr>
<tr class="row-odd"><td><p>10:20-10:30</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>10:30-11:00</p></td>
<td><p>What problems fit to GPU?</p></td>
</tr>
<tr class="row-odd"><td><p>11:00-11:30</p></td>
<td><p>GPU programming concepts</p></td>
</tr>
<tr class="row-even"><td><p>11:30-12:00</p></td>
<td><p>Introduction to GPU programming models</p></td>
</tr>
<tr class="row-odd"><td><p>12:00-13:00</p></td>
<td><p>Lunch break</p></td>
</tr>
<tr class="row-even"><td><p>13:00-14:20</p></td>
<td><p>Directive-based models</p></td>
</tr>
<tr class="row-odd"><td><p>14:20-14:30</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>14:30-16:00</p></td>
<td><p>Non-portable kernel-based models</p></td>
</tr>
</tbody>
</table>
<p><strong>Day 2</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Section</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>9:00-10:30</p></td>
<td><p>Portable kernel-based models</p></td>
</tr>
<tr class="row-odd"><td><p>10:30-10:40</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>10:40-12:00</p></td>
<td><p>Exercises for various programming models</p></td>
</tr>
<tr class="row-odd"><td><p>12:00-13:00</p></td>
<td><p>Lunch break</p></td>
</tr>
<tr class="row-even"><td><p>13:00-14:15</p></td>
<td><p>High-level language support</p></td>
</tr>
<tr class="row-odd"><td><p>14:14-14:30</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>14:30-15:50</p></td>
<td><p>Multi-GPU programming with MPI</p></td>
</tr>
<tr class="row-odd"><td><p>15:50-16:00</p></td>
<td><p>Buffer time</p></td>
</tr>
</tbody>
</table>
<p><strong>Day 3</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Section</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>09:00-10:00</p></td>
<td><p>Preparing code for GPU porting</p></td>
</tr>
<tr class="row-odd"><td><p>10:00-10:30</p></td>
<td><p>Recommendations and discussions</p></td>
</tr>
<tr class="row-even"><td><p>10:30-10:45</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-odd"><td><p>10:45-11:50</p></td>
<td><p>Problem example</p></td>
</tr>
<tr class="row-even"><td><p>11:50-12:00</p></td>
<td><p>Wrap-up</p></td>
</tr>
<tr class="row-odd"><td><p>12:00-13:00</p></td>
<td><p>Lunch break</p></td>
</tr>
<tr class="row-even"><td><p>13:00-15:50</p></td>
<td><p>Bring your code and get expert advice</p></td>
</tr>
<tr class="row-odd"><td><p>15:50-16:00</p></td>
<td><p>Summary of this workshop</p></td>
</tr>
</tbody>
</table>
</section>
<section id="suggested-two-day-schedule-2023">
<h3>Suggested two-day schedule (2023)<a class="headerlink" href="#suggested-two-day-schedule-2023" title="Link to this heading"></a></h3>
<p><strong>Day 1</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Section</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>9:00-9:15</p></td>
<td><p>Welcome</p></td>
</tr>
<tr class="row-odd"><td><p>9:15-9:30</p></td>
<td><p>Why GPUs?</p></td>
</tr>
<tr class="row-even"><td><p>9:30-9:50</p></td>
<td><p>The GPU hardware and software ecosystem</p></td>
</tr>
<tr class="row-odd"><td><p>9:50-10:10</p></td>
<td><p>What problems fit to GPU?</p></td>
</tr>
<tr class="row-even"><td><p>10:10-10:25</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-odd"><td><p>10:25-10:50</p></td>
<td><p>GPU programming concepts</p></td>
</tr>
<tr class="row-even"><td><p>10:50-11:10</p></td>
<td><p>Introduction to GPU programming models</p></td>
</tr>
<tr class="row-odd"><td><p>11:10-11:50</p></td>
<td><p>High-level language support</p></td>
</tr>
<tr class="row-even"><td><p>11:50-12:50</p></td>
<td><p>Lunch break</p></td>
</tr>
<tr class="row-odd"><td><p>12:50-13:40</p></td>
<td><p>Directive-based models</p></td>
</tr>
<tr class="row-even"><td><p>13:40-14:30</p></td>
<td><p>Multi-GPU programming with MPI</p></td>
</tr>
<tr class="row-odd"><td><p>14:30-14:45</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>14:45-16:00</p></td>
<td><p>Non-portable kernel-based models</p></td>
</tr>
</tbody>
</table>
<p><strong>Day 2</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Section</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>9:00-10:15</p></td>
<td><p>Portable kernel-based models</p></td>
</tr>
<tr class="row-odd"><td><p>10:15-10:30</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>10:30-11:20</p></td>
<td><p>Preparing code for GPU porting</p></td>
</tr>
<tr class="row-odd"><td><p>11:20-12:00</p></td>
<td><p>Recommendations and discussions</p></td>
</tr>
<tr class="row-even"><td><p>12:00-13:00</p></td>
<td><p>Lunch break</p></td>
</tr>
<tr class="row-odd"><td><p>13:00-14:30</p></td>
<td><p>Problem example</p></td>
</tr>
<tr class="row-even"><td><p>14:30-14:50</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-odd"><td><p>14:50-16:00</p></td>
<td><p>Buffer time</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
</div>
<section id="who-is-the-course-for">
<span id="learner-personas"></span><h2>Who is the course for?<a class="headerlink" href="#who-is-the-course-for" title="Link to this heading"></a></h2>
<p>This material is most relevant to researchers and engineers who already develop software
which runs on CPUs in workstations or supercomputers, but also to decision makers or
project managers who don’t write code but make strategic decisions in software projects,
whether it’s in academia, industry or the public sector.</p>
</section>
<section id="about-the-course">
<h2>About the course<a class="headerlink" href="#about-the-course" title="Link to this heading"></a></h2>
<p>This training material is the result of a multilateral effort by GPU programming experts from:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.aalto.fi/en">Aalto University in Finland</a></p></li>
<li><p><a class="reference external" href="https://www.au.dk/">Aarhus University in Denmark</a></p></li>
<li><p><a class="reference external" href="https://csc.fi/">CSC in Finland</a></p></li>
<li><p><a class="reference external" href="https://enccs.se/">ENCCS in Sweden</a></p></li>
<li><p><a class="reference external" href="https://www.hpc2n.umu.se/">HPC2N centre in Umeå, Sweden</a></p></li>
<li><p><a class="reference external" href="https://www.kth.se/">KTH Royal Institute for Technology in Sweden</a></p></li>
<li><p><a class="reference external" href="https://www.sigma2.no/nris">NRIS in Norway</a></p></li>
<li><p><a class="reference external" href="https://www.vu.lt/en/">Vilnius University in Lithuania</a> and <a class="reference external" href="https://www.eurocc-lithuania.lt/">NCC Lithuania</a></p></li>
</ul>
</section>
<section id="see-also">
<h2>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h2>
<p>Links to additional resources and tutorials can be found in the lesson episodes.</p>
</section>
<section id="credits">
<h2>Credits<a class="headerlink" href="#credits" title="Link to this heading"></a></h2>
<p>Several sections in this lesson have been adapted from the following sources created by
<a class="reference external" href="https://enccs.se/">ENCCS</a> and <a class="reference external" href="https://csc.fi/">CSC</a>, which are
all distributed under a
<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution license (CC-BY-4.0)</a>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://enccs.github.io/openmp-gpu/">OpenMP for GPU offloading</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/hpda-python/">High Performance Data Analytics in Python</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/julia-for-hpc/">Julia for HPC</a></p></li>
</ul>
<p>The lesson file structure and browsing layout is inspired by and derived from
<a class="reference external" href="https://github.com/coderefinery/sphinx-lesson">work</a> by <a class="reference external" href="https://coderefinery.org/">CodeRefinery</a> licensed under the <a class="reference external" href="http://opensource.org/licenses/mit-license.html">MIT license</a>. We have copied and adapted
most of their license text.</p>
<section id="instructional-material">
<h3>Instructional Material<a class="headerlink" href="#instructional-material" title="Link to this heading"></a></h3>
<p>This instructional material is made available under the
<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution license (CC-BY-4.0)</a>.
The following is a human-readable summary of (and not a substitute for) the
<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/legalcode">full legal text of the CC-BY-4.0 license</a>.
You are free to:</p>
<ul class="simple">
<li><p><strong>share</strong> - copy and redistribute the material in any medium or format</p></li>
<li><p><strong>adapt</strong> - remix, transform, and build upon the material for any purpose, even commercially.</p></li>
</ul>
<p>The licensor cannot revoke these freedoms as long as you follow these license terms:</p>
<ul class="simple">
<li><p><strong>Attribution</strong> - You must give appropriate credit (mentioning that your work is derived from work that is Copyright (c) ENCCS and individual contributors and, where practical, linking to <a class="reference external" href="https://enccs.github.io/sphinx-lesson-template">https://enccs.github.io/sphinx-lesson-template</a>), provide a <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">link to the license</a>, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</p></li>
<li><p><strong>No additional restrictions</strong> - You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</p></li>
</ul>
<p>With the understanding that:</p>
<ul class="simple">
<li><p>You do not have to comply with the license for elements of the material in
the public domain or where your use is permitted by an applicable exception
or limitation.</p></li>
<li><p>No warranties are given. The license may not give you all of the permissions
necessary for your intended use. For example, other rights such as
publicity, privacy, or moral rights may limit how you use the material.</p></li>
</ul>
</section>
<section id="software">
<h3>Software<a class="headerlink" href="#software" title="Link to this heading"></a></h3>
<p>Except where otherwise noted, the example programs and other software provided
with this repository are made available under the <a class="reference external" href="http://opensource.org/">OSI</a>-approved
<a class="reference external" href="https://opensource.org/licenses/mit-license.html">MIT license</a>.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, The contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>